{'dataset_name': 'ogbg-ppa', 'checkpoint_dir': './checkpoint', 'num_workers': 2, 'feature': 'full', 'hyperparams': {'batch_size': 32, 'epochs': 601, 'learning_rate': 0.001, 'step_size': 20, 'decay_rate': 0.6}, 'architecture': {'layers': 4, 'hidden': 256, 'pooling': 'add', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': '7e9542b0240da82fdde9245560aa88b8587e9a98', 'time_stamp': '1603718802', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Epoch 1 training...
Evaluating...
Train: 0.24116368286445014 Validation: 0.21758314855875832 Test: 0.24258620689655172 Train loss: 21.464577267876233 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 2 training...
Evaluating...
Train: 0.37521739130434784 Validation: 0.3077827050997783 Test: 0.35043103448275864 Train loss: 6.507739668635807 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 3 training...
Evaluating...
Train: 0.5541815856777493 Validation: 0.43866962305986695 Test: 0.48591954022988504 Train loss: 3.2024613683723193 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 4 training...
Evaluating...
Train: 0.6575447570332481 Validation: 0.5309534368070954 Test: 0.5686206896551724 Train loss: 1.9877886620949217 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 5 training...
Evaluating...
Train: 0.6369181585677749 Validation: 0.525410199556541 Test: 0.5494252873563218 Train loss: 1.5687546398606511 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 6 training...
Evaluating...
Train: 0.7108695652173913 Validation: 0.5572505543237251 Test: 0.5944252873563218 Train loss: 1.2653512761435806 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 7 training...
Evaluating...
Train: 0.7791432225063939 Validation: 0.5946563192904656 Test: 0.6475574712643678 Train loss: 0.8360107944220451 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 8 training...
Evaluating...
Train: 0.7570460358056266 Validation: 0.5971618625277162 Test: 0.6454885057471265 Train loss: 0.7424382221703638 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 9 training...
Evaluating...
Train: 0.8520971867007673 Validation: 0.621529933481153 Test: 0.6743390804597701 Train loss: 0.7354640732176371 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 10 training...
Evaluating...
Train: 0.825383631713555 Validation: 0.6160532150776054 Test: 0.6554310344827586 Train loss: 0.6582372675294669 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 11 training...
Evaluating...
Train: 0.7914322250639386 Validation: 0.5989356984478935 Test: 0.640316091954023 Train loss: 0.5878623795014258 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 12 training...
Evaluating...
Train: 0.8878388746803069 Validation: 0.6613303769401331 Test: 0.6927873563218391 Train loss: 0.6064968583998674 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 13 training...
Evaluating...
Train: 0.8875319693094629 Validation: 0.6613082039911308 Test: 0.6820689655172414 Train loss: 0.5172919295819662 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 14 training...
Evaluating...
Train: 0.8639514066496163 Validation: 0.6554988913525499 Test: 0.7152298850574713 Train loss: 0.6562559522639613 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 15 training...
Evaluating...
Train: 0.899923273657289 Validation: 0.6713747228381375 Test: 0.6966666666666667 Train loss: 0.5350712222731543 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 16 training...
Evaluating...
Train: 0.9030051150895141 Validation: 0.6655654101995565 Test: 0.7010632183908045 Train loss: 0.5240634685495043 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 17 training...
Evaluating...
Train: 0.8866624040920716 Validation: 0.6530376940133038 Test: 0.7066379310344828 Train loss: 0.5230912945939018 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 18 training...
Evaluating...
Train: 0.8857033248081841 Validation: 0.636119733924612 Test: 0.6695689655172414 Train loss: 0.46526644036246984 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 19 training...
Evaluating...
Train: 0.8887084398976982 Validation: 0.6362305986696231 Test: 0.6977873563218391 Train loss: 0.4575637928294033 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 20 training...
Evaluating...
Train: 0.9310485933503836 Validation: 0.6859645232815964 Test: 0.725632183908046 Train loss: 0.45647937294748137 lr: 0.001
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 21 training...
Evaluating...
Train: 0.9497953964194373 Validation: 0.695210643015521 Test: 0.7341091954022988 Train loss: 0.2606706982859564 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 22 training...
Evaluating...
Train: 0.948925831202046 Validation: 0.6992461197339246 Test: 0.7346551724137931 Train loss: 0.25627811721933064 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 23 training...
Evaluating...
Train: 0.9505882352941176 Validation: 0.6880709534368071 Test: 0.739367816091954 Train loss: 0.254645411330603 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 24 training...
Evaluating...
Train: 0.9475319693094629 Validation: 0.6905986696230598 Test: 0.7288505747126437 Train loss: 0.2405889505145495 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 25 training...
Evaluating...
Train: 0.9553324808184144 Validation: 0.6996230598669623 Test: 0.7439080459770115 Train loss: 0.23899732472804877 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 26 training...
Evaluating...
Train: 0.953772378516624 Validation: 0.6876053215077605 Test: 0.7341954022988506 Train loss: 0.22804196031059942 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 27 training...
Evaluating...
Train: 0.960230179028133 Validation: 0.7081818181818181 Test: 0.7402298850574712 Train loss: 0.22923488012909793 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 28 training...
Evaluating...
Train: 0.9567391304347826 Validation: 0.703569844789357 Test: 0.7321264367816092 Train loss: 0.222943003004365 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 29 training...
Evaluating...
Train: 0.9563427109974425 Validation: 0.6911973392461197 Test: 0.7314655172413793 Train loss: 0.2201347382961728 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 30 training...
Evaluating...
Train: 0.9619437340153453 Validation: 0.7170066518847007 Test: 0.7544252873563219 Train loss: 0.22005150022683284 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 31 training...
Evaluating...
Train: 0.9536572890025575 Validation: 0.6701330376940133 Test: 0.718103448275862 Train loss: 0.21698486871419873 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 32 training...
Evaluating...
Train: 0.9667902813299233 Validation: 0.711840354767184 Test: 0.7589080459770114 Train loss: 0.2043824956253927 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 33 training...
Evaluating...
Train: 0.949616368286445 Validation: 0.682860310421286 Test: 0.7415229885057472 Train loss: 0.2077569665811017 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 34 training...
Evaluating...
Train: 0.9595652173913043 Validation: 0.6976274944567628 Test: 0.7402298850574712 Train loss: 0.2078835132932702 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 35 training...
Evaluating...
Train: 0.9624680306905371 Validation: 0.697760532150776 Test: 0.735316091954023 Train loss: 0.19348307396856834 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 36 training...
Evaluating...
Train: 0.954923273657289 Validation: 0.6945454545454546 Test: 0.734396551724138 Train loss: 0.19242872923319937 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 37 training...
Evaluating...
Train: 0.9580818414322251 Validation: 0.6893348115299335 Test: 0.7325287356321839 Train loss: 0.18766256810795462 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 38 training...
Evaluating...
Train: 0.9597058823529412 Validation: 0.6806873614190687 Test: 0.7300862068965517 Train loss: 0.1892333725183812 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 39 training...
Evaluating...
Train: 0.9463810741687979 Validation: 0.6739911308203991 Test: 0.7175574712643679 Train loss: 0.18182384346020386 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 40 training...
Evaluating...
Train: 0.9639514066496163 Validation: 0.6880931263858093 Test: 0.7249137931034483 Train loss: 0.18706785640244886 lr: 0.0006
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 41 training...
Evaluating...
Train: 0.9773145780051151 Validation: 0.7170509977827051 Test: 0.7637068965517242 Train loss: 0.11402102571389289 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 42 training...
Evaluating...
Train: 0.9819948849104859 Validation: 0.7247006651884701 Test: 0.7593965517241379 Train loss: 0.11502908475379994 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 43 training...
Evaluating...
Train: 0.9811764705882353 Validation: 0.7158980044345898 Test: 0.7613218390804598 Train loss: 0.1101368664658694 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 44 training...
Evaluating...
Train: 0.9824424552429668 Validation: 0.7288691796008869 Test: 0.764080459770115 Train loss: 0.10698493444185503 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 45 training...
Evaluating...
Train: 0.9816879795396419 Validation: 0.728470066518847 Test: 0.7605459770114943 Train loss: 0.10712696257338489 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 46 training...
Evaluating...
Train: 0.9845907928388746 Validation: 0.722749445676275 Test: 0.7693390804597701 Train loss: 0.10173048096085531 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 47 training...
Evaluating...
Train: 0.9814705882352941 Validation: 0.7067849223946785 Test: 0.7454885057471264 Train loss: 0.10146688027292149 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 48 training...
Evaluating...
Train: 0.9806265984654732 Validation: 0.7137028824833703 Test: 0.7605459770114943 Train loss: 0.09735551567934149 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 49 training...
Evaluating...
Train: 0.985460358056266 Validation: 0.721019955654102 Test: 0.7633333333333333 Train loss: 0.09734339402369703 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 50 training...
Evaluating...
Train: 0.9839641943734015 Validation: 0.7160088691796009 Test: 0.7645402298850574 Train loss: 0.10232644240751423 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 51 training...
Evaluating...
Train: 0.9820843989769821 Validation: 0.7043680709534368 Test: 0.7527873563218391 Train loss: 0.09282634666596529 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 52 training...
Evaluating...
Train: 0.9854859335038363 Validation: 0.7179822616407983 Test: 0.7702011494252874 Train loss: 0.09575968730410503 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 53 training...
Evaluating...
Train: 0.9839769820971866 Validation: 0.7146784922394679 Test: 0.765603448275862 Train loss: 0.0930939093902829 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 54 training...
Evaluating...
Train: 0.982838874680307 Validation: 0.714589800443459 Test: 0.761551724137931 Train loss: 0.09445505313965478 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 55 training...
Evaluating...
Train: 0.9872634271099744 Validation: 0.7151884700665189 Test: 0.7616379310344827 Train loss: 0.09157507769169926 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 56 training...
Evaluating...
Train: 0.9853324808184143 Validation: 0.7217738359201774 Test: 0.7655172413793103 Train loss: 0.08893554100123541 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 57 training...
Evaluating...
Train: 0.9833631713554987 Validation: 0.7182926829268292 Test: 0.7480172413793104 Train loss: 0.08981836184176407 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 58 training...
Evaluating...
Train: 0.9854731457800512 Validation: 0.7221507760532151 Test: 0.7557183908045977 Train loss: 0.09339007411194804 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 59 training...
Evaluating...
Train: 0.9857161125319693 Validation: 0.7198891352549889 Test: 0.7583045977011494 Train loss: 0.08812871861713081 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 60 training...
Evaluating...
Train: 0.9849744245524297 Validation: 0.7040354767184035 Test: 0.7510057471264368 Train loss: 0.09561107625728306 lr: 0.00035999999999999997
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 61 training...
Evaluating...
Train: 0.9912148337595907 Validation: 0.724589800443459 Test: 0.7724712643678161 Train loss: 0.058751856658223606 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 62 training...
Evaluating...
Train: 0.991381074168798 Validation: 0.7311973392461197 Test: 0.7787356321839081 Train loss: 0.05143321287298481 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 63 training...
Evaluating...
Train: 0.9898721227621483 Validation: 0.7236585365853658 Test: 0.773132183908046 Train loss: 0.054335997892625984 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 64 training...
Evaluating...
Train: 0.9902557544757034 Validation: 0.7298226164079823 Test: 0.7674137931034483 Train loss: 0.05054287852966356 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 65 training...
Evaluating...
Train: 0.9924680306905371 Validation: 0.7270288248337029 Test: 0.7704310344827586 Train loss: 0.0532047701587995 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 66 training...
Evaluating...
Train: 0.9901918158567775 Validation: 0.7176940133037694 Test: 0.7776724137931035 Train loss: 0.05062670556983854 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 67 training...
Evaluating...
Train: 0.9912659846547315 Validation: 0.718470066518847 Test: 0.7680459770114942 Train loss: 0.04958867144491981 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 68 training...
Evaluating...
Train: 0.9919565217391304 Validation: 0.7290243902439024 Test: 0.7716091954022989 Train loss: 0.047912555111117916 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 69 training...
Evaluating...
Train: 0.9925063938618925 Validation: 0.7238137472283813 Test: 0.7685632183908045 Train loss: 0.049107661976825 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 70 training...
Evaluating...
Train: 0.990997442455243 Validation: 0.7259645232815964 Test: 0.7751436781609196 Train loss: 0.049495693081797444 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 71 training...
Evaluating...
Train: 0.9925959079283887 Validation: 0.7248337028824834 Test: 0.7766954022988506 Train loss: 0.04810353869887803 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 72 training...
Evaluating...
Train: 0.9939769820971867 Validation: 0.7262749445676275 Test: 0.7772413793103449 Train loss: 0.04644176308971635 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 73 training...
Evaluating...
Train: 0.9947186700767263 Validation: 0.7343237250554324 Test: 0.7792528735632184 Train loss: 0.046269532390633895 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 74 training...
Evaluating...
Train: 0.9938618925831202 Validation: 0.7280044345898005 Test: 0.7774137931034483 Train loss: 0.04773185290683918 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 75 training...
Evaluating...
Train: 0.9930818414322251 Validation: 0.727960088691796 Test: 0.7714080459770115 Train loss: 0.04251851434567897 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 76 training...
Evaluating...
Train: 0.9935166240409207 Validation: 0.7237915742793791 Test: 0.7673275862068966 Train loss: 0.0444341822586033 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 77 training...
Evaluating...
Train: 0.9932608695652174 Validation: 0.7321507760532151 Test: 0.7739655172413793 Train loss: 0.04219779159733492 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 78 training...
Evaluating...
Train: 0.9942583120204603 Validation: 0.7314855875831485 Test: 0.7727011494252873 Train loss: 0.045227269967674975 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 79 training...
Evaluating...
Train: 0.9936956521739131 Validation: 0.7229933481152994 Test: 0.7720689655172414 Train loss: 0.04238622114306191 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 80 training...
Evaluating...
Train: 0.9940025575447571 Validation: 0.7333259423503325 Test: 0.7700862068965517 Train loss: 0.04248188872784094 lr: 0.00021599999999999996
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 81 training...
Evaluating...
Train: 0.9951918158567775 Validation: 0.7340576496674057 Test: 0.7797413793103448 Train loss: 0.0326023901229957 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 82 training...
Evaluating...
Train: 0.9951150895140665 Validation: 0.7303547671840355 Test: 0.7705747126436782 Train loss: 0.02741739922393656 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 83 training...
Evaluating...
Train: 0.9953452685421995 Validation: 0.7274722838137472 Test: 0.7780459770114942 Train loss: 0.028570224532519152 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 84 training...
Evaluating...
Train: 0.9960102301790281 Validation: 0.7314190687361419 Test: 0.7781609195402299 Train loss: 0.02843092492920287 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 85 training...
Evaluating...
Train: 0.9952173913043478 Validation: 0.7209534368070953 Test: 0.7721264367816092 Train loss: 0.02552006406982704 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 86 training...
Evaluating...
Train: 0.9953196930946292 Validation: 0.7312195121951219 Test: 0.7776149425287356 Train loss: 0.026773270857467054 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 87 training...
Evaluating...
Train: 0.9961892583120204 Validation: 0.7363414634146341 Test: 0.779971264367816 Train loss: 0.025666480391143796 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 88 training...
Evaluating...
Train: 0.9961636828644501 Validation: 0.7393126385809312 Test: 0.785 Train loss: 0.023386266580386523 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 89 training...
Evaluating...
Train: 0.9955242966751918 Validation: 0.7304656319290466 Test: 0.7830747126436781 Train loss: 0.026046460225113095 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 90 training...
Evaluating...
Train: 0.9956649616368286 Validation: 0.7326385809312639 Test: 0.7761781609195403 Train loss: 0.024607692647535956 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 91 training...
Evaluating...
Train: 0.9947570332480818 Validation: 0.7374722838137472 Test: 0.7810632183908046 Train loss: 0.025265844303309772 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 92 training...
Evaluating...
Train: 0.9956393861892583 Validation: 0.7275609756097561 Test: 0.7763793103448275 Train loss: 0.024045212412800988 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 93 training...
Evaluating...
Train: 0.9959718670076726 Validation: 0.7281152993348116 Test: 0.7802586206896551 Train loss: 0.026562583278630935 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 94 training...
Evaluating...
Train: 0.9957161125319693 Validation: 0.7310421286031042 Test: 0.7831034482758621 Train loss: 0.024644714537794578 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 95 training...
Evaluating...
Train: 0.9967391304347826 Validation: 0.7333037694013304 Test: 0.7843390804597701 Train loss: 0.023902164791206146 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 96 training...
Evaluating...
Train: 0.9962148337595907 Validation: 0.7326607538802661 Test: 0.7832471264367816 Train loss: 0.02330654659102718 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 97 training...
Evaluating...
Train: 0.9959718670076726 Validation: 0.7324390243902439 Test: 0.7795689655172414 Train loss: 0.025009826359182058 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 98 training...
Evaluating...
Train: 0.9968797953964195 Validation: 0.7323281596452328 Test: 0.7835344827586207 Train loss: 0.021922170643354787 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 99 training...
Evaluating...
Train: 0.9964833759590793 Validation: 0.7331042128603105 Test: 0.7805172413793103 Train loss: 0.02367232133879794 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 100 training...
Evaluating...
Train: 0.9963938618925832 Validation: 0.733680709534368 Test: 0.7822988505747126 Train loss: 0.0239766543834362 lr: 0.00012959999999999998
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 101 training...
Evaluating...
Train: 0.9969437340153453 Validation: 0.7354767184035477 Test: 0.7831896551724138 Train loss: 0.015985349635250636 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 102 training...
Evaluating...
Train: 0.9973401534526855 Validation: 0.7376053215077605 Test: 0.7821551724137931 Train loss: 0.01723688727970854 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 103 training...
Evaluating...
Train: 0.9974552429667519 Validation: 0.7382705099778271 Test: 0.7855747126436782 Train loss: 0.014999278114318662 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 104 training...
Evaluating...
Train: 0.9971483375959079 Validation: 0.7398447893569845 Test: 0.7825862068965517 Train loss: 0.015619025233903598 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 105 training...
Evaluating...
Train: 0.9974040920716113 Validation: 0.7382261640798227 Test: 0.7871264367816092 Train loss: 0.014851818630950444 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 106 training...
Evaluating...
Train: 0.9967647058823529 Validation: 0.7386031042128604 Test: 0.7920114942528735 Train loss: 0.014715106401031566 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 107 training...
Evaluating...
Train: 0.9969053708439898 Validation: 0.7390465631929046 Test: 0.7870402298850575 Train loss: 0.014531336558613859 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 108 training...
Evaluating...
Train: 0.9973145780051151 Validation: 0.739490022172949 Test: 0.7851724137931034 Train loss: 0.015710777297666307 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 109 training...
Evaluating...
Train: 0.9973273657289002 Validation: 0.7332372505543238 Test: 0.7819252873563218 Train loss: 0.015818478963330218 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 110 training...
Evaluating...
Train: 0.9972762148337596 Validation: 0.7325720620842572 Test: 0.7788793103448276 Train loss: 0.013064192153769506 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 111 training...
Evaluating...
Train: 0.9973273657289002 Validation: 0.7276940133037694 Test: 0.7765804597701149 Train loss: 0.013725549115230818 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 112 training...
Evaluating...
Train: 0.9973785166240409 Validation: 0.7337250554323725 Test: 0.7788505747126436 Train loss: 0.012579873427916348 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 113 training...
Evaluating...
Train: 0.9969948849104859 Validation: 0.7357427937915743 Test: 0.7833333333333333 Train loss: 0.0138543419907275 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 114 training...
Evaluating...
Train: 0.9972250639386189 Validation: 0.7419512195121951 Test: 0.7849425287356322 Train loss: 0.014147251690964249 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 115 training...
Evaluating...
Train: 0.9972122762148338 Validation: 0.7337250554323725 Test: 0.7821264367816092 Train loss: 0.013444221196964456 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 116 training...
Evaluating...
Train: 0.9974552429667519 Validation: 0.7427716186252772 Test: 0.7874137931034483 Train loss: 0.014679343351231562 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 117 training...
Evaluating...
Train: 0.9967135549872123 Validation: 0.7363414634146341 Test: 0.7850862068965517 Train loss: 0.01297566229126945 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 118 training...
Evaluating...
Train: 0.9969053708439898 Validation: 0.7311529933481153 Test: 0.7789655172413793 Train loss: 0.014362231397669024 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 119 training...
Evaluating...
Train: 0.9967391304347826 Validation: 0.7357206208425721 Test: 0.7837068965517241 Train loss: 0.011976392545409657 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 120 training...
Evaluating...
Train: 0.9967007672634272 Validation: 0.7351884700665189 Test: 0.7815229885057471 Train loss: 0.013412061629569864 lr: 7.775999999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 121 training...
Evaluating...
Train: 0.9958951406649617 Validation: 0.742749445676275 Test: 0.7850574712643679 Train loss: 0.01171260499846992 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 122 training...
Evaluating...
Train: 0.9968925831202046 Validation: 0.7399113082039911 Test: 0.7830459770114943 Train loss: 0.010598615355533967 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 123 training...
Evaluating...
Train: 0.9964833759590793 Validation: 0.7397117516629712 Test: 0.7838793103448276 Train loss: 0.010489334534717282 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 124 training...
Evaluating...
Train: 0.9976726342710998 Validation: 0.7414634146341463 Test: 0.7866379310344828 Train loss: 0.01073458577992483 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 125 training...
Evaluating...
Train: 0.9966879795396419 Validation: 0.7382705099778271 Test: 0.7836494252873564 Train loss: 0.008799984816419122 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 126 training...
Evaluating...
Train: 0.9964833759590793 Validation: 0.7408869179600887 Test: 0.7822701149425287 Train loss: 0.010731123678438804 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 127 training...
Evaluating...
Train: 0.996457800511509 Validation: 0.7394678492239468 Test: 0.7835057471264368 Train loss: 0.00965089974665798 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 128 training...
Evaluating...
Train: 0.9971483375959079 Validation: 0.7368292682926829 Test: 0.7830747126436781 Train loss: 0.008901413044380609 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 129 training...
Evaluating...
Train: 0.9968542199488492 Validation: 0.7384478935698447 Test: 0.7812931034482758 Train loss: 0.008411038337723518 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 130 training...
Evaluating...
Train: 0.9967007672634272 Validation: 0.7378713968957872 Test: 0.7837356321839081 Train loss: 0.008520778122246752 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 131 training...
Evaluating...
Train: 0.9973913043478261 Validation: 0.7389356984478935 Test: 0.7826149425287356 Train loss: 0.008946826001674962 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 132 training...
Evaluating...
Train: 0.9954475703324808 Validation: 0.7368070953436807 Test: 0.7866954022988506 Train loss: 0.009553427736858595 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 133 training...
Evaluating...
Train: 0.9970076726342711 Validation: 0.7370288248337029 Test: 0.7833333333333333 Train loss: 0.008528359206896367 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 134 training...
Evaluating...
Train: 0.9972634271099744 Validation: 0.7376053215077605 Test: 0.784712643678161 Train loss: 0.008664305716655453 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 135 training...
Evaluating...
Train: 0.9968925831202046 Validation: 0.7384478935698447 Test: 0.7880459770114943 Train loss: 0.0097090471200584 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 136 training...
Evaluating...
Train: 0.9969181585677749 Validation: 0.7370953436807095 Test: 0.7869827586206897 Train loss: 0.008868151228007113 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 137 training...
Evaluating...
Train: 0.9969693094629156 Validation: 0.7405986696230599 Test: 0.7889080459770115 Train loss: 0.007990902362912649 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 138 training...
Evaluating...
Train: 0.9970716112531969 Validation: 0.7393569844789357 Test: 0.7856609195402299 Train loss: 0.00890425141861147 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 139 training...
Evaluating...
Train: 0.9976086956521739 Validation: 0.7382926829268293 Test: 0.7889367816091954 Train loss: 0.007659710916262211 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 140 training...
Evaluating...
Train: 0.9971994884910486 Validation: 0.7384035476718404 Test: 0.7859770114942529 Train loss: 0.007856043860462606 lr: 4.665599999999999e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 141 training...
Evaluating...
Train: 0.9970588235294118 Validation: 0.738780487804878 Test: 0.785948275862069 Train loss: 0.007312111699810395 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 142 training...
Evaluating...
Train: 0.9981202046035805 Validation: 0.7382483370288249 Test: 0.7853735632183908 Train loss: 0.006278347528849023 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 143 training...
Evaluating...
Train: 0.9981841432225064 Validation: 0.7423946784922395 Test: 0.7900862068965517 Train loss: 0.007619487316806461 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 144 training...
Evaluating...
Train: 0.9970843989769821 Validation: 0.7390687361419068 Test: 0.7878448275862069 Train loss: 0.00742027631656453 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 145 training...
Evaluating...
Train: 0.9963427109974424 Validation: 0.7391352549889135 Test: 0.7858620689655172 Train loss: 0.007352363810032374 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 146 training...
Evaluating...
Train: 0.9979028132992327 Validation: 0.7377383592017739 Test: 0.7819827586206897 Train loss: 0.006874373100344366 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 147 training...
Evaluating...
Train: 0.9976598465473145 Validation: 0.7385144124168515 Test: 0.7877586206896552 Train loss: 0.006109159323958445 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 148 training...
Evaluating...
Train: 0.9977621483375959 Validation: 0.7382039911308204 Test: 0.7825 Train loss: 0.006662943516786472 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 149 training...
Evaluating...
Train: 0.9975575447570333 Validation: 0.7388248337028824 Test: 0.7833333333333333 Train loss: 0.005974399752049126 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 150 training...
Evaluating...
Train: 0.9970843989769821 Validation: 0.7355875831485588 Test: 0.7846264367816091 Train loss: 0.006618143811789544 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 151 training...
Evaluating...
Train: 0.9981969309462916 Validation: 0.7408869179600887 Test: 0.7872701149425287 Train loss: 0.006528648719307395 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 152 training...
Evaluating...
Train: 0.9976982097186701 Validation: 0.7396230598669623 Test: 0.785632183908046 Train loss: 0.006569829523010591 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 153 training...
Evaluating...
Train: 0.9975575447570333 Validation: 0.737649667405765 Test: 0.7866379310344828 Train loss: 0.0063956147928626176 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 154 training...
Evaluating...
Train: 0.9977877237851662 Validation: 0.7344567627494457 Test: 0.7802873563218391 Train loss: 0.006318518802508347 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 155 training...
Evaluating...
Train: 0.9976598465473145 Validation: 0.7390243902439024 Test: 0.7844252873563219 Train loss: 0.006350829534019411 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 156 training...
Evaluating...
Train: 0.9979156010230179 Validation: 0.7417738359201774 Test: 0.7867816091954023 Train loss: 0.005775995483439998 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 157 training...
Evaluating...
Train: 0.9975063938618925 Validation: 0.738159645232816 Test: 0.7842816091954024 Train loss: 0.006145744453920572 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 158 training...
Evaluating...
Train: 0.9974296675191816 Validation: 0.7364966740576496 Test: 0.7836206896551724 Train loss: 0.005361594601173057 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 159 training...
Evaluating...
Train: 0.9973529411764706 Validation: 0.7346341463414634 Test: 0.7831034482758621 Train loss: 0.006384868128039439 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 160 training...
Evaluating...
Train: 0.9975575447570333 Validation: 0.7408647450110865 Test: 0.7873850574712644 Train loss: 0.006152455100988582 lr: 2.7993599999999992e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 161 training...
Evaluating...
Train: 0.9971867007672635 Validation: 0.7404434589800444 Test: 0.7856609195402299 Train loss: 0.0051128529804818175 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 162 training...
Evaluating...
Train: 0.9972506393861893 Validation: 0.7382039911308204 Test: 0.7881034482758621 Train loss: 0.0053821991828379625 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 163 training...
Evaluating...
Train: 0.9971355498721227 Validation: 0.7399334811529934 Test: 0.7892241379310345 Train loss: 0.004861993613549712 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 164 training...
Evaluating...
Train: 0.9977237851662404 Validation: 0.7414412416851441 Test: 0.7873275862068966 Train loss: 0.0045248446249353735 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 165 training...
Evaluating...
Train: 0.9969309462915601 Validation: 0.7396452328159645 Test: 0.7852011494252874 Train loss: 0.004876935916539738 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 166 training...
Evaluating...
Train: 0.9975447570332481 Validation: 0.7392682926829268 Test: 0.7854022988505747 Train loss: 0.00464124201029255 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 167 training...
Evaluating...
Train: 0.9976982097186701 Validation: 0.7416629711751663 Test: 0.7877298850574712 Train loss: 0.004810463201175345 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 168 training...
Evaluating...
Train: 0.9971867007672635 Validation: 0.7429046563192905 Test: 0.7878735632183909 Train loss: 0.004503816795528811 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 169 training...
Evaluating...
Train: 0.9977621483375959 Validation: 0.7432150776053215 Test: 0.7863218390804597 Train loss: 0.005076475167089125 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 170 training...
Evaluating...
Train: 0.9977493606138107 Validation: 0.7392461197339246 Test: 0.7850287356321839 Train loss: 0.004940226092828679 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 171 training...
Evaluating...
Train: 0.9973913043478261 Validation: 0.7414412416851441 Test: 0.7870402298850575 Train loss: 0.0043026328726279905 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 172 training...
Evaluating...
Train: 0.9975447570332481 Validation: 0.7409534368070954 Test: 0.7882183908045977 Train loss: 0.004903650754199969 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 173 training...
Evaluating...
Train: 0.9972122762148338 Validation: 0.7396674057649667 Test: 0.7891091954022988 Train loss: 0.004890043719326428 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 174 training...
Evaluating...
Train: 0.9971611253196931 Validation: 0.7432815964523282 Test: 0.7877298850574712 Train loss: 0.0048170183575415035 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 175 training...
Evaluating...
Train: 0.9974040920716113 Validation: 0.7391352549889135 Test: 0.7889080459770115 Train loss: 0.0053348411250589275 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 176 training...
Evaluating...
Train: 0.9970716112531969 Validation: 0.7388913525498891 Test: 0.7892241379310345 Train loss: 0.005044199980027252 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 177 training...
Evaluating...
Train: 0.9970971867007673 Validation: 0.7405321507760532 Test: 0.7860919540229885 Train loss: 0.00442663034291861 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_1.tar... Model saved.
Epoch 178 training...
Evaluating...
Train: 0.9971867007672635 Validation: 0.739290465631929 Test: 0.7854022988505747 Train loss: 0.0047722251311481095 lr: 1.6796159999999994e-05
Saving model as 7e9542b_1603718802_ogbg-ppa_0.tar... Model saved.
Epoch 179 training...
Evaluating...
