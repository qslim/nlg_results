{'dataset_name': 'ogbg-ppa', 'checkpoint_dir': './checkpoint', 'num_workers': 2, 'hyperparams': {'batch_size': 32, 'epochs': 801, 'learning_rate': 0.0005, 'step_size': 20, 'decay_rate': 0.8}, 'architecture': {'layers': 4, 'hidden': 256, 'pooling': 'add', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.5, 'variants': {'BN': 'Y'}}, 'commit_id': 'a03e366fc3f6733f587bcc6da510e66ad9013d35', 'time_stamp': '1604838730', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Epoch 1 training...
Evaluating...
Train: 0.21066496163682866 Validation: 0.18257206208425722 Test: 0.19425287356321838 Train loss: 17.58460745581238 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 2 training...
Evaluating...
Train: 0.42434782608695654 Validation: 0.3609090909090909 Test: 0.380948275862069 Train loss: 7.969476884349864 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 3 training...
Evaluating...
Train: 0.5850511508951407 Validation: 0.476119733924612 Test: 0.5336206896551724 Train loss: 4.65072638798755 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 4 training...
Evaluating...
Train: 0.6484782608695652 Validation: 0.5045454545454545 Test: 0.5612068965517242 Train loss: 4.159948826567827 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 5 training...
Evaluating...
Train: 0.7110613810741688 Validation: 0.5500221729490022 Test: 0.596580459770115 Train loss: 3.702608158613773 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 6 training...
Evaluating...
Train: 0.6878900255754475 Validation: 0.5415964523281597 Test: 0.5724425287356322 Train loss: 3.1988190337161972 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 7 training...
Evaluating...
Train: 0.768235294117647 Validation: 0.5951884700665189 Test: 0.6355747126436782 Train loss: 2.6387645943782334 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 8 training...
Evaluating...
Train: 0.7886700767263427 Validation: 0.614079822616408 Test: 0.651264367816092 Train loss: 2.010110295571253 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 9 training...
Evaluating...
Train: 0.7973913043478261 Validation: 0.6077383592017739 Test: 0.6478735632183908 Train loss: 1.8113817278777422 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 10 training...
Evaluating...
Train: 0.8221483375959079 Validation: 0.6205764966740577 Test: 0.6670114942528735 Train loss: 1.6090680875506027 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 11 training...
Evaluating...
Train: 0.820230179028133 Validation: 0.6165188470066519 Test: 0.6550862068965517 Train loss: 1.437682151227409 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 12 training...
Evaluating...
Train: 0.82923273657289 Validation: 0.6111086474501108 Test: 0.6531034482758621 Train loss: 1.2928039265061848 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 13 training...
Evaluating...
Train: 0.8292583120204604 Validation: 0.6237915742793791 Test: 0.6629022988505747 Train loss: 1.1315714709168077 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 14 training...
Evaluating...
Train: 0.844539641943734 Validation: 0.6243015521064301 Test: 0.6645977011494253 Train loss: 0.9966952330973944 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 15 training...
Evaluating...
Train: 0.8606265984654732 Validation: 0.6370731707317073 Test: 0.679683908045977 Train loss: 1.0399634957789106 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 16 training...
Evaluating...
Train: 0.886227621483376 Validation: 0.6606430155210643 Test: 0.7010057471264368 Train loss: 0.8803056302174024 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 17 training...
Evaluating...
Train: 0.8657161125319693 Validation: 0.6465188470066519 Test: 0.6726149425287357 Train loss: 0.8955340989043786 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 18 training...
Evaluating...
Train: 0.8740920716112532 Validation: 0.6404434589800444 Test: 0.6696551724137931 Train loss: 0.796844715066559 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 19 training...
Evaluating...
Train: 0.8851406649616368 Validation: 0.6481374722838138 Test: 0.6874712643678161 Train loss: 0.7089978740070436 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 20 training...
Evaluating...
Train: 0.885230179028133 Validation: 0.6668957871396896 Test: 0.7019252873563219 Train loss: 0.6945426373265428 lr: 0.0005
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 21 training...
Evaluating...
Train: 0.9138363171355499 Validation: 0.6721951219512196 Test: 0.7140229885057471 Train loss: 0.5583083752615898 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 22 training...
Evaluating...
Train: 0.911841432225064 Validation: 0.6663858093126386 Test: 0.7108333333333333 Train loss: 0.5076745153723342 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 23 training...
Evaluating...
Train: 0.9214322250639386 Validation: 0.6875388026607538 Test: 0.721867816091954 Train loss: 0.4649122191529032 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 24 training...
Evaluating...
Train: 0.9162787723785166 Validation: 0.6687804878048781 Test: 0.7125 Train loss: 0.4457600806243779 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 25 training...
Evaluating...
Train: 0.9261381074168797 Validation: 0.6732150776053215 Test: 0.7158333333333333 Train loss: 0.41791527225664904 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 26 training...
Evaluating...
Train: 0.9225831202046035 Validation: 0.6800221729490022 Test: 0.7212356321839081 Train loss: 0.41233319112095135 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 27 training...
Evaluating...
Train: 0.9229923273657289 Validation: 0.6788470066518847 Test: 0.7140804597701149 Train loss: 0.39405466139670187 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 28 training...
Evaluating...
Train: 0.9286189258312021 Validation: 0.6887139689578714 Test: 0.7191954022988506 Train loss: 0.37664853525386116 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 29 training...
Evaluating...
Train: 0.9207161125319693 Validation: 0.6861640798226164 Test: 0.7158620689655173 Train loss: 0.36770064840718203 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 30 training...
Evaluating...
Train: 0.9172890025575448 Validation: 0.6637250554323725 Test: 0.7167528735632184 Train loss: 0.3614606473491254 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 31 training...
Evaluating...
Train: 0.9319181585677749 Validation: 0.697649667405765 Test: 0.7349712643678161 Train loss: 0.34985708380072283 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 32 training...
Evaluating...
Train: 0.9244117647058824 Validation: 0.6759645232815965 Test: 0.703132183908046 Train loss: 0.34970642971377913 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 33 training...
Evaluating...
Train: 0.9323145780051151 Validation: 0.686430155210643 Test: 0.7329885057471265 Train loss: 0.36094793905968947 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 34 training...
Evaluating...
Train: 0.9320843989769821 Validation: 0.6791352549889135 Test: 0.7336781609195402 Train loss: 0.33773636310353705 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 35 training...
Evaluating...
Train: 0.9411764705882353 Validation: 0.711019955654102 Test: 0.7335057471264368 Train loss: 0.33579090170550074 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 36 training...
Evaluating...
Train: 0.9447826086956522 Validation: 0.6986252771618625 Test: 0.7366954022988506 Train loss: 0.3209834937158661 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 37 training...
Evaluating...
Train: 0.9401278772378516 Validation: 0.7003769401330376 Test: 0.7310632183908046 Train loss: 0.30835327878746827 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 38 training...
Evaluating...
Train: 0.9439002557544757 Validation: 0.6929933481152993 Test: 0.7328735632183908 Train loss: 0.30898237161326136 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 39 training...
Evaluating...
Train: 0.9445524296675192 Validation: 0.6917738359201774 Test: 0.7242528735632184 Train loss: 0.3136904362601315 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 40 training...
Evaluating...
Train: 0.9415601023017903 Validation: 0.6898447893569845 Test: 0.7371264367816092 Train loss: 0.29987097185245315 lr: 0.0004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 41 training...
Evaluating...
Train: 0.9524680306905371 Validation: 0.7021729490022173 Test: 0.7365229885057472 Train loss: 0.2683923583685035 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 42 training...
Evaluating...
Train: 0.9534398976982097 Validation: 0.6968292682926829 Test: 0.7411781609195403 Train loss: 0.25623540175734194 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 43 training...
Evaluating...
Train: 0.95269820971867 Validation: 0.7023946784922395 Test: 0.7320402298850575 Train loss: 0.2597737697466793 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 44 training...
Evaluating...
Train: 0.9507672634271099 Validation: 0.6933924611973392 Test: 0.7355747126436781 Train loss: 0.2549771106239475 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 45 training...
Evaluating...
Train: 0.955843989769821 Validation: 0.7032372505543237 Test: 0.7417241379310345 Train loss: 0.24524190947535385 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 46 training...
Evaluating...
Train: 0.9573273657289002 Validation: 0.7140576496674058 Test: 0.7450574712643678 Train loss: 0.2508530875000304 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 47 training...
Evaluating...
Train: 0.9493734015345269 Validation: 0.690110864745011 Test: 0.737212643678161 Train loss: 0.24450982673590585 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 48 training...
Evaluating...
Train: 0.9611381074168798 Validation: 0.7116186252771619 Test: 0.7530747126436782 Train loss: 0.24298323593338655 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 49 training...
Evaluating...
Train: 0.9621867007672634 Validation: 0.7073835920177384 Test: 0.7467241379310345 Train loss: 0.23587212724681278 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 50 training...
Evaluating...
Train: 0.9566624040920716 Validation: 0.7086696230598669 Test: 0.740948275862069 Train loss: 0.23607291659239663 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 51 training...
Evaluating...
Train: 0.9606265984654732 Validation: 0.7168957871396896 Test: 0.7468390804597701 Train loss: 0.23169829162926017 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 52 training...
Evaluating...
Train: 0.9564066496163682 Validation: 0.6966962305986696 Test: 0.7455459770114943 Train loss: 0.23145737157564505 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 53 training...
Evaluating...
Train: 0.959693094629156 Validation: 0.7071618625277162 Test: 0.7448563218390805 Train loss: 0.2328942435109186 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 54 training...
Evaluating...
Train: 0.949693094629156 Validation: 0.7041463414634146 Test: 0.7411494252873563 Train loss: 0.22456117965732192 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 55 training...
Evaluating...
Train: 0.9601278772378516 Validation: 0.7149445676274945 Test: 0.743132183908046 Train loss: 0.23954144654012058 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 56 training...
Evaluating...
Train: 0.9615601023017902 Validation: 0.7141685144124168 Test: 0.7498563218390805 Train loss: 0.23193199787770571 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 57 training...
Evaluating...
Train: 0.9584143222506394 Validation: 0.7052549889135254 Test: 0.7475574712643678 Train loss: 0.2274031881608813 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 58 training...
Evaluating...
Train: 0.958849104859335 Validation: 0.6949445676274945 Test: 0.7381896551724138 Train loss: 0.23072392706273034 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 59 training...
Evaluating...
Train: 0.9622122762148337 Validation: 0.7078270509977828 Test: 0.7502298850574712 Train loss: 0.22311587835343497 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 60 training...
Evaluating...
Train: 0.9650127877237852 Validation: 0.717450110864745 Test: 0.7602873563218391 Train loss: 0.22382282201999434 lr: 0.00032
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 61 training...
Evaluating...
Train: 0.966457800511509 Validation: 0.7117738359201774 Test: 0.7533908045977011 Train loss: 0.19665510471416378 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 62 training...
Evaluating...
Train: 0.9698081841432225 Validation: 0.7174057649667406 Test: 0.7556034482758621 Train loss: 0.19632022391010912 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 63 training...
Evaluating...
Train: 0.9667391304347827 Validation: 0.7170288248337029 Test: 0.7555172413793103 Train loss: 0.1915229540531647 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 64 training...
Evaluating...
Train: 0.9675191815856777 Validation: 0.7106430155210643 Test: 0.7448850574712643 Train loss: 0.19351805421697515 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 65 training...
Evaluating...
Train: 0.966611253196931 Validation: 0.7163636363636363 Test: 0.7495977011494253 Train loss: 0.19392288013920797 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 66 training...
Evaluating...
Train: 0.9667902813299233 Validation: 0.7161640798226164 Test: 0.7514080459770115 Train loss: 0.19360045599103365 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 67 training...
Evaluating...
Train: 0.9704092071611253 Validation: 0.7162527716186253 Test: 0.7539942528735633 Train loss: 0.19061866078873313 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 68 training...
Evaluating...
Train: 0.9641815856777494 Validation: 0.7136585365853658 Test: 0.7499712643678161 Train loss: 0.18699662308719273 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 69 training...
Evaluating...
Train: 0.9708567774936061 Validation: 0.7227716186252772 Test: 0.7527586206896552 Train loss: 0.18290265048389154 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 70 training...
Evaluating...
Train: 0.9729028132992328 Validation: 0.7192682926829268 Test: 0.7593103448275862 Train loss: 0.18348601683303592 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 71 training...
Evaluating...
Train: 0.9713938618925831 Validation: 0.7164745011086474 Test: 0.7498275862068966 Train loss: 0.1826352754145946 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 72 training...
Evaluating...
Train: 0.9731713554987212 Validation: 0.7219290465631929 Test: 0.757183908045977 Train loss: 0.1832410958084947 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 73 training...
Evaluating...
Train: 0.970920716112532 Validation: 0.7208425720620842 Test: 0.755 Train loss: 0.17581442644767792 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 74 training...
Evaluating...
Train: 0.9661125319693095 Validation: 0.7114634146341463 Test: 0.7546264367816092 Train loss: 0.17996234271474146 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 75 training...
Evaluating...
Train: 0.9707800511508952 Validation: 0.7195565410199557 Test: 0.7486781609195402 Train loss: 0.17441851604857928 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 76 training...
Evaluating...
Train: 0.9714322250639387 Validation: 0.716430155210643 Test: 0.7585919540229885 Train loss: 0.1747519682525808 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 77 training...
Evaluating...
Train: 0.9718797953964194 Validation: 0.7214412416851441 Test: 0.7489367816091954 Train loss: 0.1730994097431192 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 78 training...
Evaluating...
Train: 0.9702429667519181 Validation: 0.7173170731707317 Test: 0.7575287356321839 Train loss: 0.17397292072346676 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 79 training...
Evaluating...
Train: 0.9750127877237852 Validation: 0.723370288248337 Test: 0.7571551724137932 Train loss: 0.17296593908716676 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 80 training...
Evaluating...
Train: 0.973925831202046 Validation: 0.7253880266075388 Test: 0.7674137931034483 Train loss: 0.17245954941842345 lr: 0.00025600000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 81 training...
Evaluating...
Train: 0.9751662404092072 Validation: 0.7194678492239468 Test: 0.7679597701149425 Train loss: 0.15679688242747283 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 82 training...
Evaluating...
Train: 0.9774424552429668 Validation: 0.7241906873614191 Test: 0.7656609195402299 Train loss: 0.15367399003667645 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 83 training...
Evaluating...
Train: 0.9749104859335038 Validation: 0.727849223946785 Test: 0.7610057471264368 Train loss: 0.15689402858920262 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 84 training...
Evaluating...
Train: 0.9771611253196931 Validation: 0.7179600886917961 Test: 0.7582758620689655 Train loss: 0.15302630155705488 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 85 training...
Evaluating...
Train: 0.9754987212276215 Validation: 0.7272283813747228 Test: 0.7646551724137931 Train loss: 0.15216337853155532 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 86 training...
Evaluating...
Train: 0.9762659846547315 Validation: 0.7234368070953436 Test: 0.7563218390804598 Train loss: 0.14863005852396866 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 87 training...
Evaluating...
Train: 0.974386189258312 Validation: 0.7195121951219512 Test: 0.756264367816092 Train loss: 0.14900937325087926 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 88 training...
Evaluating...
Train: 0.9790153452685422 Validation: 0.7246784922394679 Test: 0.7591379310344828 Train loss: 0.14913787141384377 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 89 training...
Evaluating...
Train: 0.9798081841432225 Validation: 0.7214634146341463 Test: 0.7565229885057472 Train loss: 0.14599980961580178 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 90 training...
Evaluating...
Train: 0.9772762148337596 Validation: 0.728470066518847 Test: 0.7587643678160919 Train loss: 0.1470085995030969 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 91 training...
Evaluating...
Train: 0.9798721227621483 Validation: 0.7317073170731707 Test: 0.7636781609195402 Train loss: 0.14497343475477686 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 92 training...
Evaluating...
Train: 0.97923273657289 Validation: 0.725920177383592 Test: 0.7639655172413793 Train loss: 0.14935443494560383 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 93 training...
Evaluating...
Train: 0.9792838874680307 Validation: 0.7200665188470067 Test: 0.7610632183908046 Train loss: 0.14716203255295363 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 94 training...
Evaluating...
Train: 0.9766751918158568 Validation: 0.7204434589800444 Test: 0.7593965517241379 Train loss: 0.14549045008454783 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 95 training...
Evaluating...
Train: 0.9768925831202045 Validation: 0.7265188470066519 Test: 0.7581034482758621 Train loss: 0.13862187805419418 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 96 training...
Evaluating...
Train: 0.9776214833759591 Validation: 0.7284922394678492 Test: 0.7545689655172414 Train loss: 0.14220550226172624 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 97 training...
Evaluating...
Train: 0.9800639386189258 Validation: 0.729290465631929 Test: 0.763735632183908 Train loss: 0.14332248639687287 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 98 training...
Evaluating...
Train: 0.9795907928388747 Validation: 0.7219068736141907 Test: 0.762816091954023 Train loss: 0.14774757212732115 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 99 training...
Evaluating...
Train: 0.9714066496163682 Validation: 0.7276053215077606 Test: 0.7402011494252874 Train loss: 0.14739901218837684 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 100 training...
Evaluating...
Train: 0.979616368286445 Validation: 0.72529933481153 Test: 0.7591666666666667 Train loss: 0.1478484560173072 lr: 0.00020480000000000004
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 101 training...
Evaluating...
Train: 0.9814961636828644 Validation: 0.7318181818181818 Test: 0.7664655172413793 Train loss: 0.13241982518553538 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 102 training...
Evaluating...
Train: 0.9820460358056265 Validation: 0.7347450110864745 Test: 0.7698275862068965 Train loss: 0.1311804333643808 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 103 training...
Evaluating...
Train: 0.9830179028132993 Validation: 0.7287361419068736 Test: 0.7655459770114943 Train loss: 0.12981004757218295 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 104 training...
Evaluating...
Train: 0.982531969309463 Validation: 0.7301552106430155 Test: 0.7728448275862069 Train loss: 0.12745320669538457 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 105 training...
Evaluating...
Train: 0.9816624040920716 Validation: 0.7242572062084257 Test: 0.7567816091954023 Train loss: 0.12930480534372374 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 106 training...
Evaluating...
Train: 0.9822634271099744 Validation: 0.7361197339246119 Test: 0.7710632183908046 Train loss: 0.12829594133473604 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 107 training...
Evaluating...
Train: 0.9818797953964195 Validation: 0.7386696230598669 Test: 0.7713218390804598 Train loss: 0.127133569831056 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 108 training...
Evaluating...
Train: 0.9837595907928389 Validation: 0.7363858093126385 Test: 0.7712931034482758 Train loss: 0.1299443523934547 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 109 training...
Evaluating...
Train: 0.9590664961636829 Validation: 0.6904878048780487 Test: 0.7383908045977011 Train loss: 0.12617658167153767 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 110 training...
Evaluating...
Train: 0.9825703324808184 Validation: 0.7323725055432373 Test: 0.7674712643678161 Train loss: 0.12425061092641869 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 111 training...
Evaluating...
Train: 0.9844117647058823 Validation: 0.7307982261640799 Test: 0.7689655172413793 Train loss: 0.12669692597002913 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 112 training...
Evaluating...
Train: 0.9824424552429668 Validation: 0.725521064301552 Test: 0.7739080459770115 Train loss: 0.12416374917353966 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 113 training...
Evaluating...
Train: 0.9837851662404092 Validation: 0.7389135254988913 Test: 0.7667816091954023 Train loss: 0.11987662678752126 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 114 training...
Evaluating...
Train: 0.9843350383631714 Validation: 0.7298891352549889 Test: 0.7629597701149425 Train loss: 0.12422471231614803 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 115 training...
Evaluating...
Train: 0.9849360613810741 Validation: 0.7391796008869179 Test: 0.7726724137931035 Train loss: 0.12402480408707832 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 116 training...
Evaluating...
Train: 0.984616368286445 Validation: 0.7356319290465632 Test: 0.7674712643678161 Train loss: 0.11972552911876114 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_0.tar... Model saved.
Epoch 117 training...
Evaluating...
Train: 0.9852429667519181 Validation: 0.7342572062084257 Test: 0.7629885057471264 Train loss: 0.12284523528831387 lr: 0.00016384000000000006
Saving model as a03e366_1604838730_ogbg-ppa_1.tar... Model saved.
Epoch 118 training...
Evaluating...
