{'dataset_name': 'ogbg-ppa', 'checkpoint_dir': './checkpoint', 'num_workers': 2, 'feature': 'full', 'hyperparams': {'batch_size': 32, 'epochs': 801, 'learning_rate': 0.0005, 'step_size': 20, 'decay_rate': 0.8}, 'architecture': {'layers': 5, 'hidden': 256, 'pooling': 'add', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': '7e9542b0240da82fdde9245560aa88b8587e9a98', 'time_stamp': '1604036902', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Epoch 1 training...
Evaluating...
Train: 0.11465473145780052 Validation: 0.09463414634146342 Test: 0.0964080459770115 Train loss: 25.4938703592007 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 2 training...
Evaluating...
Train: 0.3023913043478261 Validation: 0.25490022172949 Test: 0.2757471264367816 Train loss: 10.625842709978356 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 3 training...
Evaluating...
Train: 0.2578772378516624 Validation: 0.21842572062084256 Test: 0.23882183908045976 Train loss: 5.614946723862287 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 4 training...
Evaluating...
Train: 0.30429667519181586 Validation: 0.27337028824833703 Test: 0.2898275862068965 Train loss: 4.818731437923475 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 5 training...
Evaluating...
Train: 0.5932864450127877 Validation: 0.4825277161862528 Test: 0.5236494252873564 Train loss: 3.17054793394724 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 6 training...
Evaluating...
Train: 0.6620076726342711 Validation: 0.5287804878048781 Test: 0.5738793103448275 Train loss: 2.429367032188636 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 7 training...
Evaluating...
Train: 0.7112276214833759 Validation: 0.5486252771618625 Test: 0.6037931034482759 Train loss: 1.8424085573995952 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 8 training...
Evaluating...
Train: 0.7326598465473145 Validation: 0.5590022172949002 Test: 0.5962356321839081 Train loss: 1.465131569092822 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 9 training...
Evaluating...
Train: 0.7803708439897699 Validation: 0.6031042128603105 Test: 0.6352586206896552 Train loss: 1.2027033288611035 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 10 training...
Evaluating...
Train: 0.7670460358056266 Validation: 0.5682039911308204 Test: 0.6182758620689656 Train loss: 1.0103518736599022 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 11 training...
Evaluating...
Train: 0.852378516624041 Validation: 0.6317294900221729 Test: 0.703764367816092 Train loss: 0.8816134317087562 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 12 training...
Evaluating...
Train: 0.8623273657289002 Validation: 0.6413303769401331 Test: 0.6941379310344827 Train loss: 0.7454668597459988 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 13 training...
Evaluating...
Train: 0.8623145780051151 Validation: 0.6382926829268293 Test: 0.7008045977011494 Train loss: 0.6606975054450687 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 14 training...
Evaluating...
Train: 0.8524296675191816 Validation: 0.6227937915742794 Test: 0.6814942528735632 Train loss: 0.5840325151949682 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 15 training...
Evaluating...
Train: 0.8692838874680306 Validation: 0.640709534368071 Test: 0.6845402298850575 Train loss: 0.5352697112153966 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 16 training...
Evaluating...
Train: 0.8748721227621483 Validation: 0.6305543237250555 Test: 0.6920977011494253 Train loss: 0.5468403594034881 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 17 training...
Evaluating...
Train: 0.9042966751918159 Validation: 0.6705986696230599 Test: 0.6993103448275862 Train loss: 0.4866099521097058 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 18 training...
Evaluating...
Train: 0.9098849104859335 Validation: 0.6702439024390244 Test: 0.7183620689655172 Train loss: 0.4535452708230032 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 19 training...
Evaluating...
Train: 0.9093989769820972 Validation: 0.644190687361419 Test: 0.703132183908046 Train loss: 0.41495213013465493 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 20 training...
Evaluating...
Train: 0.9179923273657289 Validation: 0.672660753880266 Test: 0.7281609195402299 Train loss: 0.39740235817888464 lr: 0.0005
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 21 training...
Evaluating...
Train: 0.9286445012787724 Validation: 0.6608869179600887 Test: 0.7008333333333333 Train loss: 0.31784513700942457 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 22 training...
Evaluating...
Train: 0.9393734015345269 Validation: 0.6803991130820399 Test: 0.7184770114942529 Train loss: 0.29902972763559726 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 23 training...
Evaluating...
Train: 0.9428132992327366 Validation: 0.6779822616407982 Test: 0.7176436781609196 Train loss: 0.2839330376206658 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 24 training...
Evaluating...
Train: 0.9514450127877238 Validation: 0.6819068736141907 Test: 0.7333908045977011 Train loss: 0.2758598531064396 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 25 training...
Evaluating...
Train: 0.9463299232736573 Validation: 0.6850332594235033 Test: 0.739396551724138 Train loss: 0.2772255389449688 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 26 training...
Evaluating...
Train: 0.9462659846547314 Validation: 0.6788691796008869 Test: 0.7295402298850575 Train loss: 0.26967352792108507 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 27 training...
Evaluating...
Train: 0.9410102301790282 Validation: 0.6776940133037694 Test: 0.7247126436781609 Train loss: 0.2557886382884997 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 28 training...
Evaluating...
Train: 0.9485805626598466 Validation: 0.6852549889135255 Test: 0.7342241379310345 Train loss: 0.24424580103868646 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 29 training...
Evaluating...
Train: 0.9545652173913044 Validation: 0.6846784922394679 Test: 0.7320114942528736 Train loss: 0.24401859780575366 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 30 training...
Evaluating...
Train: 0.955 Validation: 0.6921064301552107 Test: 0.7338505747126437 Train loss: 0.22776905348167775 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 31 training...
Evaluating...
Train: 0.9545780051150895 Validation: 0.6723281596452328 Test: 0.7174137931034483 Train loss: 0.22694046827682496 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 32 training...
Evaluating...
Train: 0.9616624040920716 Validation: 0.7088470066518847 Test: 0.7437931034482759 Train loss: 0.22825994858679816 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 33 training...
Evaluating...
Train: 0.9639386189258312 Validation: 0.6915521064301552 Test: 0.7419827586206896 Train loss: 0.21659019971403573 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 34 training...
Evaluating...
Train: 0.9617391304347827 Validation: 0.6908869179600887 Test: 0.7532183908045977 Train loss: 0.20250625710221046 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 35 training...
Evaluating...
Train: 0.9617007672634271 Validation: 0.6650554323725055 Test: 0.7142528735632184 Train loss: 0.20669875179345792 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 36 training...
Evaluating...
Train: 0.9627237851662405 Validation: 0.6855432372505543 Test: 0.7323563218390805 Train loss: 0.20513330128062182 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 37 training...
Evaluating...
Train: 0.9673529411764706 Validation: 0.7011973392461197 Test: 0.7375574712643678 Train loss: 0.1997750077246873 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 38 training...
Evaluating...
Train: 0.9656521739130435 Validation: 0.6988026607538803 Test: 0.7366954022988506 Train loss: 0.18909814589201135 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 39 training...
Evaluating...
Train: 0.9677237851662404 Validation: 0.7019955654101996 Test: 0.7456896551724138 Train loss: 0.19645864044204842 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 40 training...
Evaluating...
Train: 0.9660102301790281 Validation: 0.6876053215077605 Test: 0.730632183908046 Train loss: 0.18971299581266268 lr: 0.0004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 41 training...
Evaluating...
Train: 0.977685421994885 Validation: 0.6968736141906874 Test: 0.7482758620689656 Train loss: 0.14049566403921518 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 42 training...
Evaluating...
Train: 0.9638746803069054 Validation: 0.6867405764966741 Test: 0.7308333333333333 Train loss: 0.1489506488553143 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 43 training...
Evaluating...
Train: 0.9721994884910486 Validation: 0.682660753880266 Test: 0.7446839080459771 Train loss: 0.14005437619075692 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 44 training...
Evaluating...
Train: 0.975 Validation: 0.6995121951219512 Test: 0.7575 Train loss: 0.13437074156395737 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 45 training...
Evaluating...
Train: 0.9794373401534527 Validation: 0.70019955654102 Test: 0.7608333333333334 Train loss: 0.13526817524894072 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 46 training...
Evaluating...
Train: 0.9787851662404092 Validation: 0.6991574279379157 Test: 0.7513505747126437 Train loss: 0.13536336994234552 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 47 training...
Evaluating...
Train: 0.9768030690537084 Validation: 0.6920620842572062 Test: 0.7456034482758621 Train loss: 0.13410591985420636 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 48 training...
Evaluating...
Train: 0.9416368286445013 Validation: 0.6516851441241686 Test: 0.7050862068965518 Train loss: 0.13692368028926283 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 49 training...
Evaluating...
Train: 0.9785294117647059 Validation: 0.6973170731707317 Test: 0.7454310344827586 Train loss: 0.1478090018290057 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 50 training...
Evaluating...
Train: 0.9816240409207161 Validation: 0.7056097560975609 Test: 0.765603448275862 Train loss: 0.133228980454444 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 51 training...
Evaluating...
Train: 0.9786700767263428 Validation: 0.7036141906873614 Test: 0.7455459770114943 Train loss: 0.1292161355988784 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 52 training...
Evaluating...
Train: 0.9812531969309463 Validation: 0.7010421286031042 Test: 0.7555747126436781 Train loss: 0.12345981841781915 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 53 training...
Evaluating...
Train: 0.97769820971867 Validation: 0.6919733924611974 Test: 0.7460057471264367 Train loss: 0.12105228730253327 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 54 training...
Evaluating...
Train: 0.9819820971867008 Validation: 0.7012638580931264 Test: 0.760603448275862 Train loss: 0.12725846126139068 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 55 training...
Evaluating...
Train: 0.9796035805626598 Validation: 0.6975831485587584 Test: 0.7455747126436781 Train loss: 0.11795709779830543 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 56 training...
Evaluating...
Train: 0.976611253196931 Validation: 0.6914190687361419 Test: 0.7562931034482758 Train loss: 0.13347949481088325 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 57 training...
Evaluating...
Train: 0.9858056265984655 Validation: 0.7110864745011086 Test: 0.7662068965517241 Train loss: 0.1135897348907741 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 58 training...
Evaluating...
Train: 0.9821611253196931 Validation: 0.70529933481153 Test: 0.7543103448275862 Train loss: 0.11453839583221805 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 59 training...
Evaluating...
Train: 0.982685421994885 Validation: 0.7064523281596452 Test: 0.7421264367816092 Train loss: 0.11627061401666089 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 60 training...
Evaluating...
Train: 0.9830946291560102 Validation: 0.7119955654101996 Test: 0.7597988505747126 Train loss: 0.11417167109426617 lr: 0.00032
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 61 training...
Evaluating...
Train: 0.9865728900255755 Validation: 0.718780487804878 Test: 0.7641954022988505 Train loss: 0.08242359370769962 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 62 training...
Evaluating...
Train: 0.9865473145780052 Validation: 0.704079822616408 Test: 0.7459482758620689 Train loss: 0.08795461892386602 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 63 training...
Evaluating...
Train: 0.9874168797953964 Validation: 0.713170731707317 Test: 0.7664655172413793 Train loss: 0.10440991419625092 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 64 training...
Evaluating...
Train: 0.9817391304347826 Validation: 0.7007538802660754 Test: 0.7472126436781609 Train loss: 0.08401702111510716 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 65 training...
Evaluating...
Train: 0.9868542199488491 Validation: 0.7109534368070953 Test: 0.7685919540229885 Train loss: 0.08265546557177986 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 66 training...
Evaluating...
Train: 0.990537084398977 Validation: 0.7146341463414634 Test: 0.765316091954023 Train loss: 0.08260014596503416 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 67 training...
Evaluating...
Train: 0.9878516624040921 Validation: 0.705720620842572 Test: 0.7604597701149425 Train loss: 0.08135751674162092 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 68 training...
Evaluating...
Train: 0.9876086956521739 Validation: 0.7003325942350332 Test: 0.7484195402298851 Train loss: 0.08131975638729698 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 69 training...
Evaluating...
Train: 0.9878644501278773 Validation: 0.7045676274944568 Test: 0.7632758620689655 Train loss: 0.07897798789576696 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 70 training...
Evaluating...
Train: 0.9895652173913043 Validation: 0.7136585365853658 Test: 0.7503735632183908 Train loss: 0.07877067655554337 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 71 training...
Evaluating...
Train: 0.9892966751918159 Validation: 0.7117294900221729 Test: 0.7640229885057471 Train loss: 0.08000999549989674 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 72 training...
Evaluating...
Train: 0.9845012787723785 Validation: 0.694079822616408 Test: 0.7400574712643678 Train loss: 0.0769256729321667 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 73 training...
Evaluating...
Train: 0.9901406649616368 Validation: 0.7106873614190687 Test: 0.7580172413793104 Train loss: 0.07911308485642685 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 74 training...
Evaluating...
Train: 0.9805498721227621 Validation: 0.7068736141906874 Test: 0.7537068965517242 Train loss: 0.10926035031334859 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 75 training...
Evaluating...
Train: 0.9864194373401535 Validation: 0.7119733924611973 Test: 0.7618390804597701 Train loss: 0.08808025793033711 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 76 training...
Evaluating...
Train: 0.9858184143222506 Validation: 0.698270509977827 Test: 0.7442816091954023 Train loss: 0.084522069412026 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 77 training...
Evaluating...
Train: 0.9899616368286445 Validation: 0.708980044345898 Test: 0.7704022988505748 Train loss: 0.0736245593016452 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 78 training...
Evaluating...
Train: 0.9889641943734016 Validation: 0.7084035476718403 Test: 0.7558333333333334 Train loss: 0.10271472067039145 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 79 training...
Evaluating...
Train: 0.989769820971867 Validation: 0.7182261640798226 Test: 0.769051724137931 Train loss: 0.07447622170437085 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 80 training...
Evaluating...
Train: 0.9925575447570333 Validation: 0.7135920177383592 Test: 0.7679022988505747 Train loss: 0.08645953241363777 lr: 0.00025600000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 81 training...
Evaluating...
Train: 0.993618925831202 Validation: 0.718070953436807 Test: 0.7735632183908046 Train loss: 0.05727411730265635 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 82 training...
Evaluating...
Train: 0.9926342710997442 Validation: 0.7294235033259423 Test: 0.7766954022988506 Train loss: 0.05871974601701463 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 83 training...
Evaluating...
Train: 0.9917774936061381 Validation: 0.7149223946784923 Test: 0.7711781609195403 Train loss: 0.058713343409050114 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 84 training...
Evaluating...
Train: 0.9917263427109975 Validation: 0.6984035476718403 Test: 0.7625 Train loss: 0.0612140996396883 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 85 training...
Evaluating...
Train: 0.993925831202046 Validation: 0.7206651884700666 Test: 0.7693390804597701 Train loss: 0.05489417431196244 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 86 training...
Evaluating...
Train: 0.9934910485933504 Validation: 0.7125277161862528 Test: 0.7701436781609196 Train loss: 0.054789580034363385 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 87 training...
Evaluating...
Train: 0.9948209718670077 Validation: 0.7222172949002217 Test: 0.7710057471264368 Train loss: 0.05289625605816363 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 88 training...
Evaluating...
Train: 0.9911125319693095 Validation: 0.707960088691796 Test: 0.7518678160919541 Train loss: 0.056243549798657574 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 89 training...
Evaluating...
Train: 0.9946675191815857 Validation: 0.7133259423503326 Test: 0.7674712643678161 Train loss: 0.049304065581600894 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 90 training...
Evaluating...
Train: 0.9940664961636828 Validation: 0.7110864745011086 Test: 0.7543390804597702 Train loss: 0.05347471783194293 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 91 training...
Evaluating...
Train: 0.9947698209718671 Validation: 0.7106430155210643 Test: 0.7643965517241379 Train loss: 0.05517797872828817 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 92 training...
Evaluating...
Train: 0.9926598465473145 Validation: 0.7047671840354767 Test: 0.7453735632183908 Train loss: 0.04791428706015776 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 93 training...
Evaluating...
Train: 0.9932736572890025 Validation: 0.7161862527716186 Test: 0.7497988505747126 Train loss: 0.05555522424385788 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 94 training...
Evaluating...
Train: 0.9943734015345268 Validation: 0.7098447893569845 Test: 0.7694827586206896 Train loss: 0.051602874957207966 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 95 training...
Evaluating...
Train: 0.9945012787723785 Validation: 0.7209977827050997 Test: 0.7612068965517241 Train loss: 0.05471904450429086 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 96 training...
Evaluating...
Train: 0.9925575447570333 Validation: 0.7186474501108647 Test: 0.7636494252873564 Train loss: 0.046627462359404216 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 97 training...
Evaluating...
Train: 0.9945140664961637 Validation: 0.7200443458980045 Test: 0.7668103448275863 Train loss: 0.04819513231808542 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 98 training...
Evaluating...
Train: 0.9926342710997442 Validation: 0.7126385809312639 Test: 0.767787356321839 Train loss: 0.050854442587027815 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 99 training...
Evaluating...
Train: 0.9947570332480818 Validation: 0.7207538802660753 Test: 0.7622413793103449 Train loss: 0.049029034458251686 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 100 training...
Evaluating...
Train: 0.9933503836317136 Validation: 0.7071175166297118 Test: 0.7608045977011494 Train loss: 0.046733323318006816 lr: 0.00020480000000000004
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 101 training...
Evaluating...
Train: 0.9959718670076726 Validation: 0.7274944567627495 Test: 0.7708908045977011 Train loss: 0.03535219601853926 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 102 training...
Evaluating...
Train: 0.9971611253196931 Validation: 0.7227050997782705 Test: 0.7730172413793104 Train loss: 0.03607287073779223 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 103 training...
Evaluating...
Train: 0.9942455242966752 Validation: 0.7067405764966741 Test: 0.7582471264367816 Train loss: 0.03959419266145475 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 104 training...
Evaluating...
Train: 0.9948849104859335 Validation: 0.7181152993348116 Test: 0.770603448275862 Train loss: 0.03822431201801167 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 105 training...
Evaluating...
Train: 0.9949616368286445 Validation: 0.716430155210643 Test: 0.766235632183908 Train loss: 0.03572363509053626 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 106 training...
Evaluating...
Train: 0.995920716112532 Validation: 0.7273392461197339 Test: 0.7683333333333333 Train loss: 0.03277774224442824 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 107 training...
Evaluating...
Train: 0.9962148337595907 Validation: 0.7199113082039912 Test: 0.7745977011494253 Train loss: 0.03550508131607523 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 108 training...
Evaluating...
Train: 0.9961892583120204 Validation: 0.7028381374722839 Test: 0.7556034482758621 Train loss: 0.032865499613230056 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 109 training...
Evaluating...
Train: 0.9963938618925832 Validation: 0.7192239467849224 Test: 0.7707758620689655 Train loss: 0.03375850626421443 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 110 training...
Evaluating...
Train: 0.9964705882352941 Validation: 0.718780487804878 Test: 0.7717816091954023 Train loss: 0.03358542001046511 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 111 training...
Evaluating...
Train: 0.9960613810741688 Validation: 0.7172727272727273 Test: 0.768448275862069 Train loss: 0.034525294123095546 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 112 training...
Evaluating...
Train: 0.9967007672634272 Validation: 0.7092461197339246 Test: 0.7648275862068965 Train loss: 0.03247796843388292 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 113 training...
Evaluating...
Train: 0.9965473145780052 Validation: 0.7122616407982262 Test: 0.7687356321839081 Train loss: 0.032882676088977485 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 114 training...
Evaluating...
Train: 0.9964194373401535 Validation: 0.7203325942350333 Test: 0.7715804597701149 Train loss: 0.03285583056838735 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 115 training...
Evaluating...
Train: 0.9966496163682864 Validation: 0.7263192904656319 Test: 0.7753735632183908 Train loss: 0.029927340346813786 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 116 training...
Evaluating...
Train: 0.9969437340153453 Validation: 0.7210864745011086 Test: 0.7700287356321839 Train loss: 0.030867910762538496 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 117 training...
Evaluating...
Train: 0.9960869565217392 Validation: 0.7152328159645233 Test: 0.7682471264367816 Train loss: 0.032970850294381196 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 118 training...
Evaluating...
Train: 0.9952813299232737 Validation: 0.7113968957871397 Test: 0.7643103448275862 Train loss: 0.028838647170769796 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 119 training...
Evaluating...
Train: 0.9962148337595907 Validation: 0.7125277161862528 Test: 0.7649425287356322 Train loss: 0.030410677493350205 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 120 training...
Evaluating...
Train: 0.9973529411764706 Validation: 0.7233037694013303 Test: 0.7697413793103448 Train loss: 0.029531793299995352 lr: 0.00016384000000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 121 training...
Evaluating...
Train: 0.9975575447570333 Validation: 0.7221729490022173 Test: 0.767787356321839 Train loss: 0.024495553531655022 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 122 training...
Evaluating...
Train: 0.9974424552429667 Validation: 0.7223059866962306 Test: 0.7722413793103449 Train loss: 0.023255389074013002 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 123 training...
Evaluating...
Train: 0.9971867007672635 Validation: 0.722749445676275 Test: 0.7631034482758621 Train loss: 0.02217966164586725 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 124 training...
Evaluating...
Train: 0.9965473145780052 Validation: 0.7197117516629712 Test: 0.7655172413793103 Train loss: 0.022316067392668046 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 125 training...
Evaluating...
Train: 0.9961892583120204 Validation: 0.7187361419068736 Test: 0.7675862068965518 Train loss: 0.021474592790080755 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 126 training...
Evaluating...
Train: 0.9975703324808184 Validation: 0.7213082039911308 Test: 0.7709770114942529 Train loss: 0.024507995477159653 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 127 training...
Evaluating...
Train: 0.9977109974424553 Validation: 0.7254101995565411 Test: 0.7692816091954023 Train loss: 0.020021012657643607 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 128 training...
Evaluating...
Train: 0.9978772378516624 Validation: 0.7300221729490022 Test: 0.7733620689655173 Train loss: 0.023299214282300196 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 129 training...
Evaluating...
Train: 0.9973913043478261 Validation: 0.7245676274944568 Test: 0.7716091954022989 Train loss: 0.021857982412980544 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 130 training...
Evaluating...
Train: 0.9966879795396419 Validation: 0.7148337028824834 Test: 0.7617241379310344 Train loss: 0.022665052923165053 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 131 training...
Evaluating...
Train: 0.9969693094629156 Validation: 0.7163192904656319 Test: 0.7676436781609195 Train loss: 0.023554985931237667 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 132 training...
Evaluating...
Train: 0.9970971867007673 Validation: 0.7207538802660753 Test: 0.7658908045977012 Train loss: 0.01937778732565909 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 133 training...
Evaluating...
Train: 0.9980562659846547 Validation: 0.7175831485587583 Test: 0.7708333333333334 Train loss: 0.022191925321853493 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 134 training...
Evaluating...
Train: 0.9982480818414322 Validation: 0.7204212860310422 Test: 0.7712931034482758 Train loss: 0.022981383607596304 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 135 training...
Evaluating...
Train: 0.9979923273657288 Validation: 0.7230820399113081 Test: 0.7704885057471265 Train loss: 0.021345200142083895 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 136 training...
Evaluating...
Train: 0.9970460358056266 Validation: 0.7171840354767184 Test: 0.7631034482758621 Train loss: 0.038291267853533 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 137 training...
Evaluating...
Train: 0.9970076726342711 Validation: 0.7181818181818181 Test: 0.7686781609195402 Train loss: 0.028791553756975112 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 138 training...
Evaluating...
Train: 0.9978516624040921 Validation: 0.7173835920177384 Test: 0.7695689655172414 Train loss: 0.02383750324509428 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 139 training...
Evaluating...
Train: 0.9974808184143222 Validation: 0.7207538802660753 Test: 0.7702011494252874 Train loss: 0.020038111369084365 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 140 training...
Evaluating...
Train: 0.9973657289002558 Validation: 0.7263858093126386 Test: 0.778419540229885 Train loss: 0.0215697024917862 lr: 0.00013107200000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 141 training...
Evaluating...
Train: 0.9984782608695653 Validation: 0.732549889135255 Test: 0.7797988505747127 Train loss: 0.016014742879913405 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 142 training...
Evaluating...
Train: 0.9988618925831202 Validation: 0.718159645232816 Test: 0.7731609195402299 Train loss: 0.013592165024454192 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 143 training...
Evaluating...
Train: 0.9984143222506394 Validation: 0.7289356984478935 Test: 0.7710057471264368 Train loss: 0.014911088890274626 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 144 training...
Evaluating...
Train: 0.9987851662404093 Validation: 0.7263636363636363 Test: 0.7739942528735633 Train loss: 0.015011228685024912 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 145 training...
Evaluating...
Train: 0.9979411764705882 Validation: 0.72019955654102 Test: 0.7722988505747126 Train loss: 0.01551021398757714 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 146 training...
Evaluating...
Train: 0.9984782608695653 Validation: 0.7213525498891352 Test: 0.7677011494252873 Train loss: 0.015021173999859737 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 147 training...
Evaluating...
Train: 0.9984526854219948 Validation: 0.7284035476718403 Test: 0.7816954022988506 Train loss: 0.01391207755823248 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 148 training...
Evaluating...
Train: 0.9984910485933504 Validation: 0.7299334811529934 Test: 0.7710632183908046 Train loss: 0.01638231764658226 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 149 training...
Evaluating...
Train: 0.9975703324808184 Validation: 0.722350332594235 Test: 0.7719827586206897 Train loss: 0.01601511314796026 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 150 training...
Evaluating...
Train: 0.9988107416879796 Validation: 0.7294456762749446 Test: 0.7818103448275862 Train loss: 0.012587390071826753 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 151 training...
Evaluating...
Train: 0.9976854219948849 Validation: 0.7166740576496674 Test: 0.7677011494252873 Train loss: 0.0134061250177177 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 152 training...
Evaluating...
Train: 0.9975575447570333 Validation: 0.7234811529933481 Test: 0.7708333333333334 Train loss: 0.013946784096244119 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 153 training...
Evaluating...
Train: 0.9981202046035805 Validation: 0.715609756097561 Test: 0.769367816091954 Train loss: 0.016317693359104987 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 154 training...
Evaluating...
Train: 0.9985038363171356 Validation: 0.7175609756097561 Test: 0.7627586206896552 Train loss: 0.014896080942506669 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 155 training...
Evaluating...
Train: 0.9979156010230179 Validation: 0.7236585365853658 Test: 0.7676149425287356 Train loss: 0.013972629782318483 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 156 training...
Evaluating...
Train: 0.9977621483375959 Validation: 0.7164079822616408 Test: 0.7788505747126436 Train loss: 0.01386706563971827 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 157 training...
Evaluating...
Train: 0.9975447570332481 Validation: 0.7216186252771618 Test: 0.7679022988505747 Train loss: 0.017195305407486258 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 158 training...
Evaluating...
Train: 0.9983375959079284 Validation: 0.7200221729490022 Test: 0.7736206896551724 Train loss: 0.014130555341234577 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 159 training...
Evaluating...
Train: 0.9983503836317136 Validation: 0.7309977827050997 Test: 0.781235632183908 Train loss: 0.015522945889861684 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 160 training...
Evaluating...
Train: 0.9983375959079284 Validation: 0.7215077605321508 Test: 0.767787356321839 Train loss: 0.014474587014023233 lr: 0.00010485760000000006
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 161 training...
Evaluating...
Train: 0.9985166240409207 Validation: 0.7221507760532151 Test: 0.7770689655172414 Train loss: 0.009204988320603503 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 162 training...
Evaluating...
Train: 0.9991943734015345 Validation: 0.7297117516629712 Test: 0.7778448275862069 Train loss: 0.01065608035962047 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 163 training...
Evaluating...
Train: 0.9988235294117647 Validation: 0.7318181818181818 Test: 0.7820114942528735 Train loss: 0.010470550936132316 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 164 training...
Evaluating...
Train: 0.998772378516624 Validation: 0.7270509977827051 Test: 0.7786494252873564 Train loss: 0.010876248371916931 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 165 training...
Evaluating...
Train: 0.9982480818414322 Validation: 0.7287139689578714 Test: 0.766235632183908 Train loss: 0.010604802312799885 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 166 training...
Evaluating...
Train: 0.9981969309462916 Validation: 0.7255432372505544 Test: 0.775316091954023 Train loss: 0.011174255684334418 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 167 training...
Evaluating...
Train: 0.9987212276214834 Validation: 0.7303991130820399 Test: 0.776551724137931 Train loss: 0.010885412279865513 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 168 training...
Evaluating...
Train: 0.9983887468030691 Validation: 0.7239024390243902 Test: 0.774080459770115 Train loss: 0.011433131139231587 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 169 training...
Evaluating...
Train: 0.9985166240409207 Validation: 0.7250776053215078 Test: 0.7761206896551724 Train loss: 0.010847233322210739 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 170 training...
Evaluating...
Train: 0.9987084398976982 Validation: 0.7328381374722838 Test: 0.7773275862068966 Train loss: 0.010014129722310949 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 171 training...
Evaluating...
Train: 0.9990025575447571 Validation: 0.731019955654102 Test: 0.7733908045977012 Train loss: 0.00917793628675848 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 172 training...
Evaluating...
Train: 0.9991815856777494 Validation: 0.7180487804878048 Test: 0.7702298850574713 Train loss: 0.012115207953460869 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 173 training...
Evaluating...
Train: 0.9991048593350383 Validation: 0.7230155210643016 Test: 0.7666091954022989 Train loss: 0.009380151126970703 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 174 training...
Evaluating...
Train: 0.9987979539641944 Validation: 0.7283148558758314 Test: 0.7785919540229885 Train loss: 0.011293044894054964 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 175 training...
Evaluating...
Train: 0.9974296675191816 Validation: 0.7334811529933482 Test: 0.7842528735632184 Train loss: 0.010169881488975449 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 176 training...
Evaluating...
Train: 0.9987468030690537 Validation: 0.7317073170731707 Test: 0.7797413793103448 Train loss: 0.010930043181320126 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 177 training...
Evaluating...
Train: 0.9985677749360614 Validation: 0.7275388026607539 Test: 0.7754022988505748 Train loss: 0.009116649597200356 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 178 training...
Evaluating...
Train: 0.998925831202046 Validation: 0.7276940133037694 Test: 0.772816091954023 Train loss: 0.011134439443207071 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 179 training...
Evaluating...
Train: 0.9987851662404093 Validation: 0.7284035476718403 Test: 0.7714655172413794 Train loss: 0.010281149029682975 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 180 training...
Evaluating...
Train: 0.9988107416879796 Validation: 0.7314855875831485 Test: 0.775316091954023 Train loss: 0.01046302516076337 lr: 8.388608000000005e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 181 training...
Evaluating...
Train: 0.9991304347826087 Validation: 0.7278270509977827 Test: 0.7802298850574713 Train loss: 0.0076135350111900535 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 182 training...
Evaluating...
Train: 0.9991176470588236 Validation: 0.7289356984478935 Test: 0.7736781609195402 Train loss: 0.006882285238921935 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 183 training...
Evaluating...
Train: 0.9991432225063939 Validation: 0.7245676274944568 Test: 0.7763793103448275 Train loss: 0.00894210583127581 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 184 training...
Evaluating...
Train: 0.9992710997442456 Validation: 0.7302660753880266 Test: 0.7795689655172414 Train loss: 0.007116953072590836 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 185 training...
Evaluating...
Train: 0.9991560102301791 Validation: 0.7250332594235033 Test: 0.7758045977011494 Train loss: 0.006217259976686657 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 186 training...
Evaluating...
Train: 0.9992455242966752 Validation: 0.7258314855875831 Test: 0.7871264367816092 Train loss: 0.006404927062374081 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 187 training...
Evaluating...
Train: 0.9992710997442456 Validation: 0.7306873614190688 Test: 0.7786494252873564 Train loss: 0.006728734604636308 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 188 training...
Evaluating...
Train: 0.9991687979539642 Validation: 0.730509977827051 Test: 0.7801436781609196 Train loss: 0.007502721921341118 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 189 training...
Evaluating...
Train: 0.9992583120204603 Validation: 0.7197117516629712 Test: 0.7778448275862069 Train loss: 0.007093135645512473 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 190 training...
Evaluating...
Train: 0.9991432225063939 Validation: 0.718270509977827 Test: 0.7725574712643678 Train loss: 0.0061223841187454 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 191 training...
Evaluating...
Train: 0.9991943734015345 Validation: 0.7276718403547672 Test: 0.7787931034482759 Train loss: 0.006508478202815922 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 192 training...
Evaluating...
Train: 0.9990409207161125 Validation: 0.7289135254988913 Test: 0.7725862068965518 Train loss: 0.0061110929386315295 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 193 training...
Evaluating...
Train: 0.9991687979539642 Validation: 0.7258980044345898 Test: 0.7798563218390805 Train loss: 0.006580905374026776 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 194 training...
Evaluating...
Train: 0.9991815856777494 Validation: 0.7270953436807095 Test: 0.7764942528735632 Train loss: 0.0074687674824520335 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 195 training...
Evaluating...
Train: 0.9988235294117647 Validation: 0.7321729490022173 Test: 0.7775 Train loss: 0.008038498969301247 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 196 training...
Evaluating...
Train: 0.9983248081841433 Validation: 0.7261197339246119 Test: 0.7765229885057471 Train loss: 0.00726437930218912 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 197 training...
Evaluating...
Train: 0.9988618925831202 Validation: 0.7304212860310422 Test: 0.7819252873563218 Train loss: 0.006368696663169336 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 198 training...
Evaluating...
Train: 0.998925831202046 Validation: 0.7312638580931264 Test: 0.7792241379310345 Train loss: 0.005206001893018203 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 199 training...
Evaluating...
Train: 0.9988107416879796 Validation: 0.7308869179600886 Test: 0.7800574712643679 Train loss: 0.007279864327948534 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 200 training...
Evaluating...
Train: 0.9988618925831202 Validation: 0.7342350332594235 Test: 0.7773275862068966 Train loss: 0.005768174762836064 lr: 6.710886400000004e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 201 training...
Evaluating...
Train: 0.9991304347826087 Validation: 0.7314190687361419 Test: 0.7799425287356322 Train loss: 0.004920012629052913 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 202 training...
Evaluating...
Train: 0.9987595907928388 Validation: 0.7286696230598669 Test: 0.778448275862069 Train loss: 0.005181783539892377 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 203 training...
Evaluating...
Train: 0.9980434782608696 Validation: 0.7313968957871397 Test: 0.7750287356321839 Train loss: 0.004630254407805038 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 204 training...
Evaluating...
Train: 0.998772378516624 Validation: 0.7237028824833703 Test: 0.7773850574712644 Train loss: 0.0055332823213960994 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 205 training...
Evaluating...
Train: 0.9985933503836317 Validation: 0.7282039911308203 Test: 0.7784770114942529 Train loss: 0.004630979583423384 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 206 training...
Evaluating...
Train: 0.9984910485933504 Validation: 0.7362971175166297 Test: 0.7846551724137931 Train loss: 0.005081200046592838 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 207 training...
Evaluating...
Train: 0.9987595907928388 Validation: 0.7322838137472284 Test: 0.7785632183908046 Train loss: 0.004795695834386554 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 208 training...
Evaluating...
Train: 0.9982864450127877 Validation: 0.7321729490022173 Test: 0.7820402298850575 Train loss: 0.005179882323927263 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 209 training...
Evaluating...
Train: 0.9977365728900256 Validation: 0.730820399113082 Test: 0.7793103448275862 Train loss: 0.004934273739444449 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 210 training...
Evaluating...
Train: 0.9985805626598465 Validation: 0.7336141906873614 Test: 0.7798275862068965 Train loss: 0.004546525415118413 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 211 training...
Evaluating...
Train: 0.9986700767263427 Validation: 0.7302882483370289 Test: 0.784080459770115 Train loss: 0.005312742936728239 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 212 training...
Evaluating...
Train: 0.9982225063938619 Validation: 0.7271840354767184 Test: 0.7866091954022989 Train loss: 0.004243767066806128 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 213 training...
Evaluating...
Train: 0.9985805626598465 Validation: 0.7303991130820399 Test: 0.7788793103448276 Train loss: 0.0055817027900935 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 214 training...
Evaluating...
Train: 0.9984143222506394 Validation: 0.7348115299334812 Test: 0.7832758620689655 Train loss: 0.0059716868261561265 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 215 training...
Evaluating...
Train: 0.9988874680306905 Validation: 0.7287361419068736 Test: 0.7791666666666667 Train loss: 0.004644281154145877 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 216 training...
Evaluating...
Train: 0.9988107416879796 Validation: 0.7290243902439024 Test: 0.7816666666666666 Train loss: 0.004179589864957938 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 217 training...
Evaluating...
Train: 0.9987979539641944 Validation: 0.7260088691796008 Test: 0.7767528735632184 Train loss: 0.0051743091026649314 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 218 training...
Evaluating...
Train: 0.9988618925831202 Validation: 0.73529933481153 Test: 0.7832758620689655 Train loss: 0.004491639658361623 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 219 training...
Evaluating...
Train: 0.9987340153452685 Validation: 0.7303104212860311 Test: 0.7782758620689655 Train loss: 0.0042621456696339405 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 220 training...
Evaluating...
Train: 0.9989769820971867 Validation: 0.7313747228381374 Test: 0.7808908045977011 Train loss: 0.004029701868823228 lr: 5.3687091200000036e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 221 training...
Evaluating...
Train: 0.9987851662404093 Validation: 0.731840354767184 Test: 0.7824425287356321 Train loss: 0.004589252592548012 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 222 training...
Evaluating...
Train: 0.9983759590792839 Validation: 0.7270066518847007 Test: 0.7723850574712644 Train loss: 0.003324037695184667 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 223 training...
Evaluating...
Train: 0.9982736572890025 Validation: 0.7292017738359202 Test: 0.7800574712643679 Train loss: 0.004570561016578919 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 224 training...
Evaluating...
Train: 0.9988491048593351 Validation: 0.7271840354767184 Test: 0.773448275862069 Train loss: 0.003643356918056938 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 225 training...
Evaluating...
Train: 0.9986445012787724 Validation: 0.7275388026607539 Test: 0.776264367816092 Train loss: 0.004504777442316377 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 226 training...
Evaluating...
Train: 0.9975575447570333 Validation: 0.7306430155210643 Test: 0.7801149425287356 Train loss: 0.0033830124529183286 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 227 training...
Evaluating...
Train: 0.9984271099744245 Validation: 0.7317960088691796 Test: 0.7852011494252874 Train loss: 0.0035718178983210735 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 228 training...
Evaluating...
Train: 0.9988491048593351 Validation: 0.7295121951219512 Test: 0.7794252873563219 Train loss: 0.003310030823155823 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 229 training...
Evaluating...
Train: 0.9986317135549873 Validation: 0.7292017738359202 Test: 0.7789080459770115 Train loss: 0.003424836758603441 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 230 training...
Evaluating...
Train: 0.9984398976982097 Validation: 0.7288026607538802 Test: 0.7808333333333334 Train loss: 0.0036683711754249716 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 231 training...
Evaluating...
Train: 0.9986445012787724 Validation: 0.7300221729490022 Test: 0.7769827586206897 Train loss: 0.003692308551567837 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 232 training...
Evaluating...
Train: 0.9984271099744245 Validation: 0.7338580931263858 Test: 0.7804597701149425 Train loss: 0.003941695905502416 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 233 training...
Evaluating...
Train: 0.9991304347826087 Validation: 0.7364745011086474 Test: 0.783132183908046 Train loss: 0.004054553254999818 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 234 training...
Evaluating...
Train: 0.9984143222506394 Validation: 0.7313747228381374 Test: 0.7862931034482759 Train loss: 0.002862601236638407 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 235 training...
Evaluating...
Train: 0.9986317135549873 Validation: 0.7333481152993349 Test: 0.7886494252873564 Train loss: 0.003765180930535847 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 236 training...
Evaluating...
Train: 0.9984910485933504 Validation: 0.7344124168514412 Test: 0.7808620689655172 Train loss: 0.003059078209138736 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 237 training...
Evaluating...
Train: 0.9981969309462916 Validation: 0.7377827050997783 Test: 0.788419540229885 Train loss: 0.003770062294460943 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 238 training...
Evaluating...
Train: 0.9974296675191816 Validation: 0.7309756097560975 Test: 0.7813793103448275 Train loss: 0.0037682043583210064 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 239 training...
Evaluating...
Train: 0.9986956521739131 Validation: 0.7320842572062084 Test: 0.7828448275862069 Train loss: 0.0029130633076967834 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 240 training...
Evaluating...
Train: 0.9985933503836317 Validation: 0.7270288248337029 Test: 0.7826149425287356 Train loss: 0.0031963754780651504 lr: 4.2949672960000034e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 241 training...
Evaluating...
Train: 0.9982097186700767 Validation: 0.7321507760532151 Test: 0.782183908045977 Train loss: 0.0019197451551300024 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 242 training...
Evaluating...
Train: 0.9985294117647059 Validation: 0.7305543237250555 Test: 0.7793103448275862 Train loss: 0.00296929853003466 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 243 training...
Evaluating...
Train: 0.9988618925831202 Validation: 0.734079822616408 Test: 0.7829310344827586 Train loss: 0.0029665370310714588 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 244 training...
Evaluating...
Train: 0.9979923273657288 Validation: 0.7346341463414634 Test: 0.7789080459770115 Train loss: 0.003005587027915761 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 245 training...
Evaluating...
Train: 0.9986700767263427 Validation: 0.7329711751662971 Test: 0.7853448275862069 Train loss: 0.0028261311303476653 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 246 training...
Evaluating...
Train: 0.999079283887468 Validation: 0.7353436807095344 Test: 0.7809195402298851 Train loss: 0.0024899293592863282 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 247 training...
Evaluating...
Train: 0.9986956521739131 Validation: 0.7344124168514412 Test: 0.7774712643678161 Train loss: 0.0021174742915935434 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 248 training...
Evaluating...
Train: 0.9989002557544757 Validation: 0.7320842572062084 Test: 0.7802298850574713 Train loss: 0.0023240659383886603 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 249 training...
Evaluating...
Train: 0.9988874680306905 Validation: 0.7337915742793791 Test: 0.7825862068965517 Train loss: 0.0025605163895166838 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 250 training...
Evaluating...
Train: 0.9990281329923274 Validation: 0.7358758314855876 Test: 0.7835057471264368 Train loss: 0.002732047218689924 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 251 training...
Evaluating...
Train: 0.9989897698209719 Validation: 0.7289356984478935 Test: 0.7802011494252874 Train loss: 0.0019531602713655917 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 252 training...
Evaluating...
Train: 0.9982225063938619 Validation: 0.7297560975609756 Test: 0.780316091954023 Train loss: 0.0025428644601464996 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 253 training...
Evaluating...
Train: 0.9984143222506394 Validation: 0.7312638580931264 Test: 0.784051724137931 Train loss: 0.00288270997362129 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 254 training...
Evaluating...
Train: 0.9980690537084399 Validation: 0.7319512195121951 Test: 0.7817816091954023 Train loss: 0.0026210140573213704 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 255 training...
Evaluating...
Train: 0.9984143222506394 Validation: 0.7303769401330377 Test: 0.7773850574712644 Train loss: 0.003008030602922873 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 256 training...
Evaluating...
Train: 0.998312020460358 Validation: 0.7320177383592018 Test: 0.7828735632183909 Train loss: 0.002544457799120957 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 257 training...
Evaluating...
Train: 0.9987212276214834 Validation: 0.737450110864745 Test: 0.7862068965517242 Train loss: 0.002376578506377979 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 258 training...
Evaluating...
Train: 0.9981329923273657 Validation: 0.7342350332594235 Test: 0.7819827586206897 Train loss: 0.0028947914599461843 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 259 training...
Evaluating...
Train: 0.998772378516624 Validation: 0.7323725055432373 Test: 0.7827298850574713 Train loss: 0.002649524378698508 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 260 training...
Evaluating...
Train: 0.9987084398976982 Validation: 0.7299556541019956 Test: 0.7816666666666666 Train loss: 0.002101062082132224 lr: 3.435973836800003e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 261 training...
Evaluating...
Train: 0.9987212276214834 Validation: 0.7301552106430155 Test: 0.7852011494252874 Train loss: 0.002330618569565433 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 262 training...
Evaluating...
Train: 0.9976214833759591 Validation: 0.7291796008869179 Test: 0.7802298850574713 Train loss: 0.0027633529060906345 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 263 training...
Evaluating...
Train: 0.9987595907928388 Validation: 0.7318847006651885 Test: 0.7816091954022989 Train loss: 0.0019613861208461507 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 264 training...
Evaluating...
Train: 0.9988874680306905 Validation: 0.7274057649667406 Test: 0.7782471264367816 Train loss: 0.0027392064076398673 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 265 training...
Evaluating...
Train: 0.9984271099744245 Validation: 0.7335698447893569 Test: 0.7820689655172414 Train loss: 0.0017715565701748462 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 266 training...
Evaluating...
Train: 0.9986700767263427 Validation: 0.731330376940133 Test: 0.7802586206896551 Train loss: 0.002804263084882995 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 267 training...
Evaluating...
Train: 0.9985038363171356 Validation: 0.7313747228381374 Test: 0.7852873563218391 Train loss: 0.0032407061297967904 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 268 training...
Evaluating...
Train: 0.9991560102301791 Validation: 0.734589800443459 Test: 0.7856609195402299 Train loss: 0.0019167116124220315 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 269 training...
Evaluating...
Train: 0.9989130434782608 Validation: 0.7324833702882484 Test: 0.7818390804597701 Train loss: 0.0018035765093041465 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 270 training...
Evaluating...
Train: 0.9986445012787724 Validation: 0.7292239467849224 Test: 0.780632183908046 Train loss: 0.0018866409126423215 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 271 training...
Evaluating...
Train: 0.9991048593350383 Validation: 0.7342128603104213 Test: 0.7875574712643678 Train loss: 0.001962645894929608 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 272 training...
Evaluating...
Train: 0.999079283887468 Validation: 0.7287139689578714 Test: 0.7811781609195402 Train loss: 0.0017159839780097842 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 273 training...
Evaluating...
Train: 0.9989641943734016 Validation: 0.7340133037694013 Test: 0.7780172413793104 Train loss: 0.0017052327312783258 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 274 training...
Evaluating...
Train: 0.9986445012787724 Validation: 0.7326164079822617 Test: 0.7791379310344828 Train loss: 0.0019435834523698896 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 275 training...
Evaluating...
Train: 0.9985933503836317 Validation: 0.7329268292682927 Test: 0.7786494252873564 Train loss: 0.0014878557522441283 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 276 training...
Evaluating...
Train: 0.9983631713554987 Validation: 0.7305986696230599 Test: 0.7776724137931035 Train loss: 0.001305349378460948 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 277 training...
Evaluating...
Train: 0.9984015345268542 Validation: 0.7309534368070953 Test: 0.779683908045977 Train loss: 0.001849552540264036 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 278 training...
Evaluating...
Train: 0.9989897698209719 Validation: 0.7346341463414634 Test: 0.7829885057471264 Train loss: 0.0017253539224693312 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 279 training...
Evaluating...
Train: 0.9988107416879796 Validation: 0.7317516629711752 Test: 0.7832758620689655 Train loss: 0.002070153846450418 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 280 training...
Evaluating...
Train: 0.9979411764705882 Validation: 0.7288913525498891 Test: 0.7793103448275862 Train loss: 0.0025593083223812707 lr: 2.7487790694400027e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 281 training...
Evaluating...
Train: 0.9986956521739131 Validation: 0.7303104212860311 Test: 0.7789080459770115 Train loss: 0.0021373050900118248 lr: 2.1990232555520022e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 282 training...
Evaluating...
Train: 0.9991687979539642 Validation: 0.7276274944567628 Test: 0.7789367816091954 Train loss: 0.0018140151060251869 lr: 2.1990232555520022e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 283 training...
Evaluating...
Train: 0.9986572890025576 Validation: 0.7312860310421286 Test: 0.7834770114942529 Train loss: 0.001694678552997483 lr: 2.1990232555520022e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 284 training...
Evaluating...
Train: 0.9984910485933504 Validation: 0.7302882483370289 Test: 0.7818103448275862 Train loss: 0.0017772738319305724 lr: 2.1990232555520022e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 285 training...
Evaluating...
Train: 0.9982352941176471 Validation: 0.733059866962306 Test: 0.7844252873563219 Train loss: 0.0013775845031254374 lr: 2.1990232555520022e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_1.tar... Model saved.
Epoch 286 training...
Evaluating...
Train: 0.9986700767263427 Validation: 0.7323281596452328 Test: 0.7804022988505747 Train loss: 0.002104299521989302 lr: 2.1990232555520022e-05
Saving model as 7e9542b_1604036902_ogbg-ppa_0.tar... Model saved.
Epoch 287 training...
