{'dataset_name': 'ogbg-ppa', 'checkpoint_dir': './checkpoint', 'num_workers': 2, 'feature': 'full', 'hyperparams': {'batch_size': 32, 'epochs': 801, 'learning_rate': 0.001, 'step_size': 20, 'decay_rate': 0.8}, 'architecture': {'layers': 5, 'hidden': 256, 'pooling': 'add', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': '7e9542b0240da82fdde9245560aa88b8587e9a98', 'time_stamp': '1604103293', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Epoch 1 training...
Evaluating...
Train: 0.19260869565217392 Validation: 0.152039911308204 Test: 0.15172413793103448 Train loss: 25.34571879214429 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 2 training...
Evaluating...
Train: 0.31884910485933504 Validation: 0.2412860310421286 Test: 0.25439655172413794 Train loss: 8.1818321323824 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 3 training...
Evaluating...
Train: 0.4813554987212276 Validation: 0.388270509977827 Test: 0.41522988505747127 Train loss: 3.7627519737630353 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 4 training...
Evaluating...
Train: 0.6160485933503836 Validation: 0.5013968957871396 Test: 0.5463218390804597 Train loss: 2.3074041769615756 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 5 training...
Evaluating...
Train: 0.6641048593350384 Validation: 0.525920177383592 Test: 0.5745689655172413 Train loss: 1.8490571029203808 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 6 training...
Evaluating...
Train: 0.7394245524296675 Validation: 0.5694235033259424 Test: 0.6337931034482759 Train loss: 1.1347863529724984 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 7 training...
Evaluating...
Train: 0.6852429667519182 Validation: 0.530310421286031 Test: 0.5799425287356322 Train loss: 0.9727632369352246 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 8 training...
Evaluating...
Train: 0.7560997442455243 Validation: 0.579179600886918 Test: 0.6245689655172414 Train loss: 1.1637611831134451 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 9 training...
Evaluating...
Train: 0.7628005115089515 Validation: 0.5964079822616408 Test: 0.6189367816091954 Train loss: 0.9797922542193712 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 10 training...
Evaluating...
Train: 0.7737851662404092 Validation: 0.5954545454545455 Test: 0.6343390804597702 Train loss: 0.9641734697595361 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 11 training...
Evaluating...
Train: 0.7691176470588236 Validation: 0.5826164079822617 Test: 0.6383045977011494 Train loss: 0.8091335840669572 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 12 training...
Evaluating...
Train: 0.7717391304347826 Validation: 0.5691130820399113 Test: 0.5954597701149426 Train loss: 0.7484757329494297 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 13 training...
Evaluating...
Train: 0.8419437340153453 Validation: 0.6345676274944567 Test: 0.6849712643678161 Train loss: 0.677442053768863 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 14 training...
Evaluating...
Train: 0.8290920716112532 Validation: 0.6191574279379157 Test: 0.6462068965517241 Train loss: 0.6420254909087417 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 15 training...
Evaluating...
Train: 0.8452685421994884 Validation: 0.6141019955654102 Test: 0.649080459770115 Train loss: 0.6238555850311748 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 16 training...
Evaluating...
Train: 0.8719820971867007 Validation: 0.666629711751663 Test: 0.6979885057471265 Train loss: 0.6070345259239552 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 17 training...
Evaluating...
Train: 0.7729156010230179 Validation: 0.5793126385809313 Test: 0.6101436781609195 Train loss: 0.5878754250595496 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 18 training...
Evaluating...
Train: 0.870076726342711 Validation: 0.6480487804878049 Test: 0.6904597701149425 Train loss: 0.5797042806134384 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 19 training...
Evaluating...
Train: 0.8753964194373401 Validation: 0.6564966740576497 Test: 0.6975 Train loss: 0.5469004573718128 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 20 training...
Evaluating...
Train: 0.8942455242966751 Validation: 0.6717960088691796 Test: 0.7173850574712644 Train loss: 0.5450258058162006 lr: 0.001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 21 training...
Evaluating...
Train: 0.8925063938618926 Validation: 0.6690909090909091 Test: 0.7004885057471264 Train loss: 0.44269465033800237 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 22 training...
Evaluating...
Train: 0.8940537084398977 Validation: 0.6767627494456763 Test: 0.7122701149425288 Train loss: 0.45590727161707545 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 23 training...
Evaluating...
Train: 0.9130179028132992 Validation: 0.6806651884700665 Test: 0.728735632183908 Train loss: 0.44581984986479467 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 24 training...
Evaluating...
Train: 0.9048849104859336 Validation: 0.6768070953436807 Test: 0.703103448275862 Train loss: 0.4174126122762646 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 25 training...
Evaluating...
Train: 0.8144117647058824 Validation: 0.6280931263858093 Test: 0.6414942528735632 Train loss: 0.41659908855727185 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 26 training...
Evaluating...
Train: 0.9199744245524296 Validation: 0.6897782705099779 Test: 0.7312356321839081 Train loss: 0.41880374630446715 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 27 training...
Evaluating...
Train: 0.904693094629156 Validation: 0.6898447893569845 Test: 0.7269252873563219 Train loss: 0.4022293493682107 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 28 training...
Evaluating...
Train: 0.9262020460358056 Validation: 0.6844345898004435 Test: 0.731580459770115 Train loss: 0.40199889532258387 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 29 training...
Evaluating...
Train: 0.9038618925831202 Validation: 0.6659423503325942 Test: 0.6985057471264368 Train loss: 0.4098060418091068 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 30 training...
Evaluating...
Train: 0.9196547314578005 Validation: 0.6881152993348115 Test: 0.7306034482758621 Train loss: 0.39394040740172814 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 31 training...
Evaluating...
Train: 0.9133375959079284 Validation: 0.6874722838137473 Test: 0.7261494252873564 Train loss: 0.3848172259530732 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 32 training...
Evaluating...
Train: 0.9275831202046035 Validation: 0.6953880266075388 Test: 0.7355747126436781 Train loss: 0.411473967442853 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 33 training...
Evaluating...
Train: 0.9230562659846547 Validation: 0.6907538802660754 Test: 0.7223563218390805 Train loss: 0.37562374001804816 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 34 training...
Evaluating...
Train: 0.9246419437340153 Validation: 0.6937694013303769 Test: 0.7439080459770115 Train loss: 0.3641349193556219 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 35 training...
Evaluating...
Train: 0.9236317135549872 Validation: 0.6804878048780488 Test: 0.7356609195402298 Train loss: 0.3676946167414932 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 36 training...
Evaluating...
Train: 0.9197314578005115 Validation: 0.6644124168514413 Test: 0.707212643678161 Train loss: 0.3578904250426349 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 37 training...
Evaluating...
Train: 0.93076726342711 Validation: 0.6807982261640798 Test: 0.7246551724137931 Train loss: 0.3610634007559763 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 38 training...
Evaluating...
Train: 0.9326086956521739 Validation: 0.689490022172949 Test: 0.7392528735632183 Train loss: 0.35550802233956647 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 39 training...
Evaluating...
Train: 0.9303196930946291 Validation: 0.6974057649667406 Test: 0.7277011494252874 Train loss: 0.34397990833632586 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 40 training...
Evaluating...
Train: 0.9107161125319693 Validation: 0.6640354767184036 Test: 0.7288793103448276 Train loss: 0.34356790997770825 lr: 0.0008
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 41 training...
Evaluating...
Train: 0.9459846547314578 Validation: 0.7135476718403547 Test: 0.7510919540229885 Train loss: 0.28694959900626965 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 42 training...
Evaluating...
Train: 0.9446675191815856 Validation: 0.7116186252771619 Test: 0.7503448275862069 Train loss: 0.2883892573276001 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 43 training...
Evaluating...
Train: 0.9482864450127877 Validation: 0.7066518847006652 Test: 0.7481609195402299 Train loss: 0.2840456094367219 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 44 training...
Evaluating...
Train: 0.9419693094629156 Validation: 0.6984922394678492 Test: 0.7380172413793104 Train loss: 0.27527402347158003 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 45 training...
Evaluating...
Train: 0.9489514066496164 Validation: 0.7089356984478936 Test: 0.7518103448275862 Train loss: 0.2762499698841679 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 46 training...
Evaluating...
Train: 0.9548593350383632 Validation: 0.7176718403547672 Test: 0.753448275862069 Train loss: 0.2774394713250734 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 47 training...
Evaluating...
Train: 0.9484143222506394 Validation: 0.7072727272727273 Test: 0.743764367816092 Train loss: 0.2746605848445391 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 48 training...
Evaluating...
Train: 0.9481329923273657 Validation: 0.7077827050997783 Test: 0.7476149425287356 Train loss: 0.2686735747013174 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 49 training...
Evaluating...
Train: 0.9532864450127877 Validation: 0.7026164079822617 Test: 0.7518965517241379 Train loss: 0.275351836487846 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 50 training...
Evaluating...
Train: 0.9501406649616368 Validation: 0.7020177383592018 Test: 0.7465229885057472 Train loss: 0.26408934937378487 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 51 training...
Evaluating...
Train: 0.9520204603580563 Validation: 0.7106651884700665 Test: 0.7436781609195402 Train loss: 0.2651419450701161 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 52 training...
Evaluating...
Train: 0.9515345268542199 Validation: 0.7154323725055433 Test: 0.7411781609195403 Train loss: 0.25940679106708925 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 53 training...
Evaluating...
Train: 0.957851662404092 Validation: 0.7053215077605322 Test: 0.7532471264367816 Train loss: 0.26177224618993983 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 54 training...
Evaluating...
Train: 0.9493350383631713 Validation: 0.7073170731707317 Test: 0.7447701149425288 Train loss: 0.2579805014865342 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 55 training...
Evaluating...
Train: 0.9531074168797954 Validation: 0.7151219512195122 Test: 0.7479022988505747 Train loss: 0.26107686050175255 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 56 training...
Evaluating...
Train: 0.9575063938618926 Validation: 0.7204878048780488 Test: 0.7630172413793104 Train loss: 0.2520422309960213 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 57 training...
Evaluating...
Train: 0.9558184143222507 Validation: 0.7119068736141907 Test: 0.7433045977011494 Train loss: 0.25160257478965575 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 58 training...
Evaluating...
Train: 0.9609718670076727 Validation: 0.7235033259423503 Test: 0.764683908045977 Train loss: 0.25183795234599987 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 59 training...
Evaluating...
Train: 0.9568158567774936 Validation: 0.7113747228381375 Test: 0.7413218390804598 Train loss: 0.24615428133969808 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 60 training...
Evaluating...
Train: 0.9627493606138108 Validation: 0.7239689578713969 Test: 0.7587931034482759 Train loss: 0.252171643852651 lr: 0.00064
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 61 training...
Evaluating...
Train: 0.9670332480818414 Validation: 0.7263858093126386 Test: 0.7692241379310345 Train loss: 0.2109363669721614 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 62 training...
Evaluating...
Train: 0.9669948849104859 Validation: 0.7293791574279379 Test: 0.7755172413793103 Train loss: 0.2065668766998035 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 63 training...
Evaluating...
Train: 0.9653964194373401 Validation: 0.7273392461197339 Test: 0.7541954022988506 Train loss: 0.20978000147021247 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 64 training...
Evaluating...
Train: 0.9656010230179028 Validation: 0.7265631929046563 Test: 0.7719540229885058 Train loss: 0.19832721032482709 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 65 training...
Evaluating...
Train: 0.9587084398976982 Validation: 0.7088248337028825 Test: 0.7464080459770115 Train loss: 0.2032116468059914 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 66 training...
Evaluating...
Train: 0.9678772378516624 Validation: 0.7240354767184035 Test: 0.7583620689655173 Train loss: 0.20531593023535663 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 67 training...
Evaluating...
Train: 0.9629667519181586 Validation: 0.7155654101995566 Test: 0.7433045977011494 Train loss: 0.1996901843257846 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 68 training...
Evaluating...
Train: 0.9652685421994885 Validation: 0.7155432372505544 Test: 0.7473850574712644 Train loss: 0.19981048920735986 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 69 training...
Evaluating...
Train: 0.9613554987212276 Validation: 0.7099778270509978 Test: 0.7606609195402299 Train loss: 0.2006015868509972 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 70 training...
Evaluating...
Train: 0.9651662404092072 Validation: 0.7069844789356985 Test: 0.7441379310344828 Train loss: 0.19645265376106905 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 71 training...
Evaluating...
Train: 0.9714194373401535 Validation: 0.7192239467849224 Test: 0.7711781609195403 Train loss: 0.1955712513476854 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 72 training...
Evaluating...
Train: 0.9690664961636829 Validation: 0.7198891352549889 Test: 0.7543103448275862 Train loss: 0.19494096964670868 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 73 training...
Evaluating...
Train: 0.97 Validation: 0.7310864745011086 Test: 0.7688505747126437 Train loss: 0.19257750051208877 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 74 training...
Evaluating...
Train: 0.9683759590792839 Validation: 0.7227716186252772 Test: 0.7628448275862069 Train loss: 0.19228691982986396 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 75 training...
Evaluating...
Train: 0.9685549872122762 Validation: 0.7150332594235034 Test: 0.7610919540229885 Train loss: 0.19195939527912928 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 76 training...
Evaluating...
Train: 0.969693094629156 Validation: 0.7148337028824834 Test: 0.7637931034482759 Train loss: 0.18993650621287952 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 77 training...
Evaluating...
Train: 0.9683759590792839 Validation: 0.7057427937915742 Test: 0.761551724137931 Train loss: 0.1895923076285912 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 78 training...
Evaluating...
Train: 0.9739641943734015 Validation: 0.7247228381374723 Test: 0.7667816091954023 Train loss: 0.1854552393763916 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 79 training...
Evaluating...
Train: 0.9713299232736573 Validation: 0.7222616407982262 Test: 0.7620977011494253 Train loss: 0.18961570241813183 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_1.tar... Model saved.
Epoch 80 training...
Evaluating...
Train: 0.9741048593350383 Validation: 0.7268070953436807 Test: 0.7722988505747126 Train loss: 0.18863497061103143 lr: 0.0005120000000000001
Saving model as 7e9542b_1604103293_ogbg-ppa_0.tar... Model saved.
Epoch 81 training...
Evaluating...
