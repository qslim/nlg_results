{'dataset_name': 'ogbg-ppa', 'checkpoint_dir': './checkpoint', 'num_workers': 0, 'feature': 'full', 'hyperparams': {'batch_size': 32, 'epochs': 601, 'learning_rate': 0.0005, 'step_size': 20, 'decay_rate': 0.8}, 'architecture': {'layers': 4, 'hidden': 256, 'pooling': 'add', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': 'cd0c964e80fcfd3e96244b42aeefabc8568d613b', 'time_stamp': '1603416007', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Epoch 1 training...
Evaluating...
Train: 0.20837595907928388 Validation: 0.19070953436807095 Test: 0.19956896551724138 Train loss: 19.11951644838149 lr: 0.0005
Saving model as cd0c964_1603416007_ogbg-ppa_1.tar... Model saved.
Epoch 2 training...
Evaluating...
Train: 0.37184143222506394 Validation: 0.30226164079822615 Test: 0.31192528735632186 Train loss: 7.248991913374044 lr: 0.0005
Saving model as cd0c964_1603416007_ogbg-ppa_0.tar... Model saved.
Epoch 3 training...
Evaluating...
Train: 0.4465089514066496 Validation: 0.3425942350332594 Test: 0.369051724137931 Train loss: 3.440501417812271 lr: 0.0005
Saving model as cd0c964_1603416007_ogbg-ppa_1.tar... Model saved.
Epoch 4 training...
Evaluating...
Train: 0.3054219948849105 Validation: 0.25634146341463415 Test: 0.2725862068965517 Train loss: 3.3737629390826203 lr: 0.0005
Saving model as cd0c964_1603416007_ogbg-ppa_0.tar... Model saved.
Epoch 5 training...
Traceback (most recent call last):
  File "./main.py", line 229, in <module>
    main()
  File "./main.py", line 171, in main
    train_loss = train(model, device, train_loader, optimizer, multicls_criterion)
  File "./main.py", line 32, in train
    loss.backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 852.00 MiB (GPU 0; 11.78 GiB total capacity; 8.27 GiB already allocated; 457.69 MiB free; 10.24 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f4baaf95536 in /opt/conda/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f4bab1def1e in /opt/conda/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1df9e (0x7f4bab1dff9e in /opt/conda/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: THCStorage_resize + 0x96 (0x7f4bac4543d6 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: at::native::(anonymous namespace)::resize_cuda_(at::Tensor&, c10::ArrayRef<long>, c10::optional<c10::MemoryFormat>) + 0x9aa (0x7f4badc77e4a in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x2887de3 (0x7f4badc78de3 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf0ffe2 (0x7f4bac300fe2 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x1041be6 (0x7f4bac432be6 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: <unknown function> + 0xf65018 (0x7f4bac356018 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0x10c2780 (0x7f4be8cc6780 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: <unknown function> + 0x2c9b47e (0x7f4bea89f47e in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: <unknown function> + 0x10c2780 (0x7f4be8cc6780 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::Tensor c10::Dispatcher::callUnboxed<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::OperatorHandle const&, at::Tensor const&, at::Tensor const&) const + 0xb3 (0x7f4bf7007da3 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #13: <unknown function> + 0x28ac327 (0x7f4bea4b0327 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: torch::autograd::generated::AddmmBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x134 (0x7f4bea4eaff4 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2d89705 (0x7f4bea98d705 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f4bea98aa03 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f4bea98b7e2 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f4bea983e59 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f4bf72cb5f8 in /opt/conda/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #20: <unknown function> + 0xbd66f (0x7f4bf817a66f in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #21: <unknown function> + 0x76db (0x7f4bfa0a06db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #22: clone + 0x3f (0x7f4bf9dc988f in /lib/x86_64-linux-gnu/libc.so.6)

