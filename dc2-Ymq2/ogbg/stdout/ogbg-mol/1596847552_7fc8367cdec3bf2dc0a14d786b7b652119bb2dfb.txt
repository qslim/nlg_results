{'dataset_name': 'ogbg-molhiv', 'seed': 666, 'num_workers': 0, 'feature': 'full', 'hyperparams': {'batch_size': 128, 'epochs': 501, 'learning_rate': 0.0001, 'step_size': 30, 'decay_rate': 0.85}, 'architecture': {'layers': 10, 'hidden': 256, 'pooling': 'mean', 'JK': 'last', 'nonlinear_conv': 'EB1', 'variants': {'BN': 'N', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '7fc8367cdec3bf2dc0a14d786b7b652119bb2dfb', 'time_stamp': '1596847552', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Epoch 1 training...
Evaluating...
Train: 0.5040194962052693 Validation: 0.6104359567901234 Test: 0.5391799764383244 Train loss: 0.222872754183504
Epoch 2 training...
Evaluating...
Train: 0.5604567978518056 Validation: 0.5844968645894572 Test: 0.5478842774097608 Train loss: 0.1603933319218399
Epoch 3 training...
Evaluating...
Train: 0.5870450172912755 Validation: 0.5928115201842052 Test: 0.5883823557813013 Train loss: 0.15940649329518625
Epoch 4 training...
Evaluating...
Train: 0.6132740783009973 Validation: 0.6005321624534586 Test: 0.5778288495335947 Train loss: 0.1586196018137442
Epoch 5 training...
Evaluating...
Train: 0.630182807616773 Validation: 0.6068948412698413 Test: 0.5956797157148651 Train loss: 0.15749565831046233
Epoch 6 training...
Evaluating...
Train: 0.6619583328036389 Validation: 0.6690733392122281 Test: 0.6058006141485931 Train loss: 0.15626043998167033
Epoch 7 training...
Evaluating...
Train: 0.6645898417396175 Validation: 0.6763056045463451 Test: 0.632574016493173 Train loss: 0.15540179631911044
Epoch 8 training...
Evaluating...
Train: 0.6801624212173567 Validation: 0.684278855575152 Test: 0.649732517043589 Train loss: 0.15586185748436193
Epoch 9 training...
Evaluating...
Train: 0.6800834155897466 Validation: 0.682227366255144 Test: 0.6605168118349138 Train loss: 0.15359774866509576
Epoch 10 training...
Evaluating...
Train: 0.6843528079407409 Validation: 0.696615348814423 Test: 0.6804862975337491 Train loss: 0.15113126334207233
Epoch 11 training...
Evaluating...
Train: 0.6925282052012847 Validation: 0.6892024299431707 Test: 0.6781436489696596 Train loss: 0.15086382600052875
Epoch 12 training...
Evaluating...
Train: 0.6875717009710426 Validation: 0.6889666617675877 Test: 0.7019950172849997 Train loss: 0.15090749188968838
Epoch 13 training...
Evaluating...
Train: 0.7058657519972213 Validation: 0.7108869782480894 Test: 0.6829834488885457 Train loss: 0.14885832756295686
Epoch 14 training...
Evaluating...
Train: 0.7142927626385425 Validation: 0.714337766999804 Test: 0.6963498715695552 Train loss: 0.1482142042440846
Epoch 15 training...
Evaluating...
Train: 0.7196395405724718 Validation: 0.7482026504017243 Test: 0.7212846907047259 Train loss: 0.14695718405811592
Epoch 16 training...
Evaluating...
Train: 0.7327226674616867 Validation: 0.73609580148932 Test: 0.7232121130187914 Train loss: 0.14513334249283455
Epoch 17 training...
Evaluating...
Train: 0.7415976457783904 Validation: 0.7378564079952967 Test: 0.7138434500473165 Train loss: 0.1432030362098716
Epoch 18 training...
Evaluating...
Train: 0.7515461651219412 Validation: 0.7493478101116989 Test: 0.7187199443789953 Train loss: 0.1414354513868574
Epoch 19 training...
Evaluating...
Train: 0.7497632906816573 Validation: 0.7332696453066824 Test: 0.688132254388845 Train loss: 0.13900662018996915
Epoch 20 training...
Evaluating...
Train: 0.7502224203848821 Validation: 0.7337718009014305 Test: 0.6791826802371618 Train loss: 0.1374513328494143
Epoch 21 training...
Evaluating...
Train: 0.7649966008998107 Validation: 0.7569199490495786 Test: 0.7259313621352286 Train loss: 0.13570247155202683
Epoch 22 training...
Evaluating...
Train: 0.777116243587793 Validation: 0.7379574514991181 Test: 0.6878580119353406 Train loss: 0.13654319231593331
Epoch 23 training...
Evaluating...
Train: 0.7703004095118623 Validation: 0.7448988340192044 Test: 0.7145773383031732 Train loss: 0.13376100580821665
Epoch 24 training...
Evaluating...
Train: 0.7532289401368785 Validation: 0.7471462864981384 Test: 0.700602560883756 Train loss: 0.13865523516785266
Epoch 25 training...
Evaluating...
Train: 0.7650473234097993 Validation: 0.7418736527532823 Test: 0.7061974931922208 Train loss: 0.13615724846518548
Epoch 26 training...
Evaluating...
Train: 0.7700120678052567 Validation: 0.7425702405447776 Test: 0.6939145213310416 Train loss: 0.1327544084150893
Epoch 27 training...
Evaluating...
Train: 0.7705148075897073 Validation: 0.748196526553008 Test: 0.694127928310705 Train loss: 0.1319189745600718
Epoch 28 training...
Evaluating...
Train: 0.77633577307154 Validation: 0.783359665882814 Test: 0.6922671353251317 Train loss: 0.13068841273224976
Epoch 29 training...
Evaluating...
Train: 0.7832242948879091 Validation: 0.7442313345091123 Test: 0.7176442186987003 Train loss: 0.128952082051614
Epoch 30 training...
Evaluating...
Train: 0.7701875205299296 Validation: 0.7497274887321184 Test: 0.641478205450086 Train loss: 0.12841322061483018
Epoch 31 training...
Evaluating...
Train: 0.7906905765931942 Validation: 0.7546173819321967 Test: 0.7177987214894068 Train loss: 0.12789026838402415
Epoch 32 training...
Evaluating...
Train: 0.79698834392107 Validation: 0.7424829757005683 Test: 0.6895073292261341 Train loss: 0.1262877389297698
Epoch 33 training...
Evaluating...
Train: 0.8021638084357148 Validation: 0.7483128796786205 Test: 0.6795264489464842 Train loss: 0.1235762783759382
Epoch 34 training...
Evaluating...
Train: 0.8060872291843431 Validation: 0.7492620762296689 Test: 0.6852256706386759 Train loss: 0.12304056786693805
Epoch 35 training...
Evaluating...
Train: 0.8053354646868809 Validation: 0.7498652753282382 Test: 0.678288495335947 Train loss: 0.12142905809505042
Epoch 36 training...
Evaluating...
Train: 0.8115969778508461 Validation: 0.7559202307466195 Test: 0.7129280210123796 Train loss: 0.12486812343835368
Epoch 37 training...
Evaluating...
Train: 0.816257515338241 Validation: 0.7523240005878895 Test: 0.686324571737577 Train loss: 0.12132128146152164
Epoch 38 training...
Evaluating...
Train: 0.8134347781824415 Validation: 0.7706235915147952 Test: 0.7091436682825084 Train loss: 0.12301360621557449
Epoch 39 training...
