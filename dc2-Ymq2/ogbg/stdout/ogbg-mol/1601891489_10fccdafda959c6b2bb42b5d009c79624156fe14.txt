{'dataset_name': 'ogbg-molpcba', 'seed': 555, 'num_workers': 0, 'feature': 'full', 'hyperparams': {'batch_size': 128, 'epochs': 601, 'learning_rate': 0.0001, 'step_size': 20, 'decay_rate': 0.8}, 'architecture': {'layers': 8, 'hidden': 256, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': '10fccdafda959c6b2bb42b5d009c79624156fe14', 'time_stamp': '1601891489', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Downloading https://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/pcba.zip
  0%|          | 0/39 [00:00<?, ?it/s]Downloaded 0.00 GB:   0%|          | 0/39 [00:01<?, ?it/s]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:01<01:06,  1.76s/it]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:02<01:06,  1.76s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:02<00:49,  1.35s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:02<00:49,  1.35s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [00:02<00:38,  1.07s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [00:03<00:38,  1.07s/it]Downloaded 0.00 GB:  10%|█         | 4/39 [00:03<00:31,  1.10it/s]Downloaded 0.00 GB:  10%|█         | 4/39 [00:03<00:31,  1.10it/s]Downloaded 0.00 GB:  13%|█▎        | 5/39 [00:03<00:25,  1.32it/s]Downloaded 0.01 GB:  13%|█▎        | 5/39 [00:03<00:25,  1.32it/s]Downloaded 0.01 GB:  15%|█▌        | 6/39 [00:03<00:21,  1.55it/s]Downloaded 0.01 GB:  15%|█▌        | 6/39 [00:04<00:21,  1.55it/s]Downloaded 0.01 GB:  18%|█▊        | 7/39 [00:04<00:18,  1.76it/s]Downloaded 0.01 GB:  18%|█▊        | 7/39 [00:04<00:18,  1.76it/s]Downloaded 0.01 GB:  21%|██        | 8/39 [00:04<00:15,  1.95it/s]Downloaded 0.01 GB:  21%|██        | 8/39 [00:05<00:15,  1.95it/s]Downloaded 0.01 GB:  23%|██▎       | 9/39 [00:05<00:14,  2.12it/s]Downloaded 0.01 GB:  23%|██▎       | 9/39 [00:05<00:14,  2.12it/s]Downloaded 0.01 GB:  26%|██▌       | 10/39 [00:05<00:12,  2.37it/s]Downloaded 0.01 GB:  26%|██▌       | 10/39 [00:05<00:12,  2.37it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:05<00:10,  2.56it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:06<00:10,  2.56it/s]Downloaded 0.01 GB:  31%|███       | 12/39 [00:06<00:10,  2.59it/s]Downloaded 0.01 GB:  31%|███       | 12/39 [00:06<00:10,  2.59it/s]Downloaded 0.01 GB:  33%|███▎      | 13/39 [00:06<00:10,  2.60it/s]Downloaded 0.01 GB:  33%|███▎      | 13/39 [00:06<00:10,  2.60it/s]Downloaded 0.01 GB:  36%|███▌      | 14/39 [00:06<00:09,  2.62it/s]Downloaded 0.01 GB:  36%|███▌      | 14/39 [00:07<00:09,  2.62it/s]Downloaded 0.01 GB:  38%|███▊      | 15/39 [00:07<00:09,  2.66it/s]Downloaded 0.02 GB:  38%|███▊      | 15/39 [00:07<00:09,  2.66it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:07<00:07,  2.95it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:07<00:07,  2.95it/s]Downloaded 0.02 GB:  44%|████▎     | 17/39 [00:07<00:07,  2.82it/s]Downloaded 0.02 GB:  44%|████▎     | 17/39 [00:08<00:07,  2.82it/s]Downloaded 0.02 GB:  46%|████▌     | 18/39 [00:08<00:08,  2.44it/s]Downloaded 0.02 GB:  46%|████▌     | 18/39 [00:08<00:08,  2.44it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:08<00:08,  2.44it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:09<00:08,  2.44it/s]Downloaded 0.02 GB:  51%|█████▏    | 20/39 [00:09<00:07,  2.47it/s]Downloaded 0.02 GB:  51%|█████▏    | 20/39 [00:09<00:07,  2.47it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:09<00:07,  2.50it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:09<00:07,  2.50it/s]Downloaded 0.02 GB:  56%|█████▋    | 22/39 [00:09<00:06,  2.53it/s]Downloaded 0.02 GB:  56%|█████▋    | 22/39 [00:10<00:06,  2.53it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:10<00:06,  2.55it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:10<00:06,  2.55it/s]Downloaded 0.02 GB:  62%|██████▏   | 24/39 [00:10<00:05,  2.53it/s]Downloaded 0.02 GB:  62%|██████▏   | 24/39 [00:11<00:05,  2.53it/s]Downloaded 0.02 GB:  64%|██████▍   | 25/39 [00:11<00:06,  2.28it/s]Downloaded 0.03 GB:  64%|██████▍   | 25/39 [00:11<00:06,  2.28it/s]Downloaded 0.03 GB:  67%|██████▋   | 26/39 [00:11<00:05,  2.29it/s]Downloaded 0.03 GB:  67%|██████▋   | 26/39 [00:12<00:05,  2.29it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:12<00:05,  2.16it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:12<00:05,  2.16it/s]Downloaded 0.03 GB:  72%|███████▏  | 28/39 [00:12<00:04,  2.22it/s]Downloaded 0.03 GB:  72%|███████▏  | 28/39 [00:13<00:04,  2.22it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:13<00:04,  2.29it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:13<00:04,  2.29it/s]Downloaded 0.03 GB:  77%|███████▋  | 30/39 [00:13<00:04,  2.17it/s]Downloaded 0.03 GB:  77%|███████▋  | 30/39 [00:13<00:04,  2.17it/s]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [00:13<00:03,  2.24it/s]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [00:14<00:03,  2.24it/s]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [00:14<00:03,  2.30it/s]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [00:14<00:03,  2.30it/s]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [00:14<00:02,  2.35it/s]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [00:15<00:02,  2.35it/s]Downloaded 0.03 GB:  87%|████████▋ | 34/39 [00:15<00:02,  2.39it/s]Downloaded 0.03 GB:  87%|████████▋ | 34/39 [00:15<00:02,  2.39it/s]Downloaded 0.03 GB:  90%|████████▉ | 35/39 [00:15<00:01,  2.22it/s]Downloaded 0.04 GB:  90%|████████▉ | 35/39 [00:16<00:01,  2.22it/s]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [00:16<00:01,  2.29it/s]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [00:16<00:01,  2.29it/s]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [00:16<00:00,  2.34it/s]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [00:16<00:00,  2.34it/s]Downloaded 0.04 GB:  97%|█████████▋| 38/39 [00:16<00:00,  2.47it/s]Downloaded 0.04 GB:  97%|█████████▋| 38/39 [00:16<00:00,  2.47it/s]Downloaded 0.04 GB: 100%|██████████| 39/39 [00:16<00:00,  2.31it/s]
Extracting dataset/pcba.zip
Processing...
Loading necessary files...
This might take a while.
Processing graphs...
  0%|          | 0/437929 [00:00<?, ?it/s]  1%|          | 3863/437929 [00:00<00:11, 38623.22it/s]  2%|▏         | 7607/437929 [00:00<00:11, 38259.15it/s]  3%|▎         | 11493/437929 [00:00<00:11, 38436.28it/s]  4%|▎         | 15456/437929 [00:00<00:10, 38784.73it/s]  5%|▍         | 19977/437929 [00:00<00:10, 40510.30it/s]  5%|▌         | 23912/437929 [00:00<00:10, 40151.85it/s]  6%|▋         | 27644/437929 [00:00<00:10, 39255.85it/s]  7%|▋         | 32049/437929 [00:00<00:10, 40579.05it/s]  8%|▊         | 36517/437929 [00:00<00:09, 41725.69it/s]  9%|▉         | 40558/437929 [00:01<00:09, 39967.33it/s] 10%|█         | 44478/437929 [00:01<00:10, 39049.89it/s] 11%|█         | 48573/437929 [00:01<00:09, 39599.60it/s] 12%|█▏        | 52697/437929 [00:01<00:09, 40077.56it/s] 13%|█▎        | 56684/437929 [00:01<00:09, 39129.53it/s] 14%|█▍        | 60592/437929 [00:01<00:09, 39112.51it/s] 15%|█▍        | 65135/437929 [00:01<00:09, 40813.47it/s] 16%|█▌        | 69381/437929 [00:01<00:08, 41292.87it/s] 17%|█▋        | 73522/437929 [00:01<00:08, 40564.00it/s] 18%|█▊        | 78091/437929 [00:01<00:08, 41976.31it/s] 19%|█▉        | 82309/437929 [00:02<00:08, 41561.28it/s] 20%|█▉        | 86481/437929 [00:02<00:08, 41361.17it/s] 21%|██        | 90628/437929 [00:02<00:08, 41200.11it/s] 22%|██▏       | 94756/437929 [00:02<00:08, 39511.92it/s] 23%|██▎       | 99074/437929 [00:02<00:08, 40543.33it/s] 24%|██▎       | 103566/437929 [00:02<00:08, 41763.59it/s] 25%|██▍       | 107767/437929 [00:02<00:08, 40788.03it/s] 26%|██▌       | 111868/437929 [00:02<00:09, 35445.74it/s] 26%|██▋       | 115698/437929 [00:02<00:08, 36255.87it/s] 27%|██▋       | 119427/437929 [00:03<00:08, 36293.72it/s] 28%|██▊       | 123520/437929 [00:03<00:08, 37569.89it/s] 29%|██▉       | 128070/437929 [00:03<00:07, 39640.94it/s] 30%|███       | 132108/437929 [00:03<00:07, 38651.14it/s] 31%|███       | 136300/437929 [00:03<00:07, 39574.81it/s] 32%|███▏      | 140848/437929 [00:03<00:07, 41177.87it/s] 33%|███▎      | 145015/437929 [00:03<00:07, 41216.86it/s] 34%|███▍      | 149592/437929 [00:03<00:06, 42484.74it/s] 35%|███▌      | 153875/437929 [00:03<00:06, 41225.34it/s] 36%|███▌      | 158138/437929 [00:03<00:06, 41635.83it/s] 37%|███▋      | 162584/437929 [00:04<00:06, 42441.82it/s] 38%|███▊      | 166849/437929 [00:04<00:06, 41105.84it/s] 39%|███▉      | 171442/437929 [00:04<00:06, 42442.11it/s] 40%|████      | 175714/437929 [00:04<00:06, 42522.08it/s] 41%|████      | 179986/437929 [00:04<00:06, 41460.68it/s] 42%|████▏     | 184341/437929 [00:04<00:06, 42063.92it/s] 43%|████▎     | 188563/437929 [00:04<00:06, 38168.04it/s] 44%|████▍     | 192460/437929 [00:04<00:07, 33808.32it/s] 45%|████▍     | 195989/437929 [00:04<00:07, 31473.08it/s] 46%|████▌     | 199605/437929 [00:05<00:07, 32746.20it/s] 46%|████▋     | 203445/437929 [00:05<00:06, 34257.95it/s] 47%|████▋     | 207675/437929 [00:05<00:06, 36329.16it/s] 48%|████▊     | 212215/437929 [00:05<00:05, 38644.86it/s] 49%|████▉     | 216661/437929 [00:05<00:05, 40223.14it/s] 51%|█████     | 221234/437929 [00:05<00:05, 41728.36it/s] 52%|█████▏    | 225806/437929 [00:05<00:04, 42848.78it/s] 53%|█████▎    | 230155/437929 [00:05<00:04, 41627.98it/s] 54%|█████▎    | 234370/437929 [00:05<00:04, 41042.20it/s] 55%|█████▍    | 238943/437929 [00:05<00:04, 42343.76it/s] 56%|█████▌    | 243215/437929 [00:06<00:04, 41821.87it/s] 56%|█████▋    | 247425/437929 [00:06<00:04, 41161.91it/s] 58%|█████▊    | 252012/437929 [00:06<00:04, 42469.53it/s] 59%|█████▊    | 256285/437929 [00:06<00:04, 42307.53it/s] 59%|█████▉    | 260534/437929 [00:06<00:04, 40432.01it/s] 61%|██████    | 265061/437929 [00:06<00:04, 41769.51it/s] 62%|██████▏   | 269547/437929 [00:06<00:03, 42648.72it/s] 63%|██████▎   | 273840/437929 [00:06<00:03, 41225.62it/s] 63%|██████▎   | 278048/437929 [00:06<00:03, 41477.35it/s] 65%|██████▍   | 282663/437929 [00:07<00:03, 42775.64it/s] 66%|██████▌   | 286966/437929 [00:07<00:03, 42754.32it/s] 67%|██████▋   | 291259/437929 [00:07<00:03, 40936.86it/s] 68%|██████▊   | 295852/437929 [00:07<00:03, 42315.25it/s] 69%|██████▊   | 300116/437929 [00:07<00:03, 42346.22it/s] 70%|██████▉   | 304373/437929 [00:07<00:03, 40392.15it/s] 70%|███████   | 308637/437929 [00:07<00:03, 41041.03it/s] 71%|███████▏  | 312942/437929 [00:07<00:03, 41620.54it/s] 72%|███████▏  | 317125/437929 [00:07<00:03, 38881.98it/s] 73%|███████▎  | 321184/437929 [00:07<00:02, 39377.58it/s] 74%|███████▍  | 325606/437929 [00:08<00:02, 40714.15it/s] 75%|███████▌  | 329715/437929 [00:08<00:02, 40724.81it/s] 76%|███████▋  | 334151/437929 [00:08<00:02, 41749.08it/s] 77%|███████▋  | 338369/437929 [00:08<00:02, 41876.10it/s] 78%|███████▊  | 342815/437929 [00:08<00:02, 42615.65it/s] 79%|███████▉  | 347092/437929 [00:08<00:02, 41556.33it/s] 80%|████████  | 351265/437929 [00:08<00:02, 41484.71it/s] 81%|████████  | 355426/437929 [00:08<00:01, 41479.15it/s] 82%|████████▏ | 359583/437929 [00:08<00:01, 40496.49it/s] 83%|████████▎ | 364057/437929 [00:09<00:01, 41681.05it/s] 84%|████████▍ | 368431/437929 [00:09<00:01, 42275.24it/s] 85%|████████▌ | 372672/437929 [00:09<00:01, 41514.79it/s] 86%|████████▌ | 377215/437929 [00:09<00:01, 42614.85it/s] 87%|████████▋ | 381493/437929 [00:09<00:01, 41254.05it/s] 88%|████████▊ | 385640/437929 [00:09<00:01, 39973.71it/s] 89%|████████▉ | 389661/437929 [00:09<00:01, 38016.32it/s] 90%|████████▉ | 393705/437929 [00:09<00:01, 38709.83it/s] 91%|█████████ | 398266/437929 [00:09<00:00, 40548.34it/s] 92%|█████████▏| 402364/437929 [00:09<00:00, 40325.40it/s] 93%|█████████▎| 406603/437929 [00:10<00:00, 40922.66it/s] 94%|█████████▍| 410719/437929 [00:10<00:00, 39589.59it/s] 95%|█████████▍| 415047/437929 [00:10<00:00, 40626.95it/s] 96%|█████████▌| 419540/437929 [00:10<00:00, 41827.88it/s] 97%|█████████▋| 423750/437929 [00:10<00:00, 39926.81it/s] 98%|█████████▊| 428168/437929 [00:10<00:00, 41114.07it/s] 99%|█████████▉| 432701/437929 [00:10<00:00, 42292.13it/s]100%|█████████▉| 436963/437929 [00:10<00:00, 40505.80it/s]100%|██████████| 437929/437929 [00:10<00:00, 40454.82it/s]
Converting graphs into PyG objects...
  0%|          | 0/437929 [00:00<?, ?it/s]  1%|          | 2427/437929 [00:00<00:29, 14801.10it/s]  2%|▏         | 8138/437929 [00:00<00:22, 19030.50it/s]  3%|▎         | 15324/437929 [00:00<00:17, 24415.31it/s]  5%|▍         | 21045/437929 [00:00<00:16, 25409.90it/s]  6%|▋         | 27817/437929 [00:00<00:13, 31270.92it/s]  8%|▊         | 35238/437929 [00:00<00:10, 37838.92it/s]  9%|▉         | 40525/437929 [00:00<00:12, 32878.16it/s] 11%|█         | 47576/437929 [00:01<00:09, 39145.62it/s] 13%|█▎        | 55193/437929 [00:01<00:08, 45828.29it/s] 14%|█▍        | 61503/437929 [00:01<00:07, 49927.44it/s] 15%|█▌        | 67561/437929 [00:01<00:09, 38100.24it/s] 17%|█▋        | 74487/437929 [00:01<00:08, 44044.63it/s] 18%|█▊        | 80570/437929 [00:01<00:07, 48018.82it/s] 20%|██        | 87871/437929 [00:01<00:06, 53513.30it/s] 21%|██▏       | 94064/437929 [00:02<00:08, 39319.01it/s] 23%|██▎       | 99830/437929 [00:02<00:07, 43466.59it/s] 25%|██▍       | 107499/437929 [00:02<00:06, 49959.53it/s] 26%|██▌       | 114775/437929 [00:02<00:05, 55142.22it/s] 28%|██▊       | 121153/437929 [00:02<00:05, 57357.46it/s] 29%|██▉       | 127516/437929 [00:02<00:08, 38426.25it/s] 31%|███       | 133623/437929 [00:02<00:07, 43235.30it/s] 32%|███▏      | 141215/437929 [00:02<00:05, 49647.02it/s] 34%|███▍      | 148307/437929 [00:03<00:05, 54554.46it/s] 35%|███▌      | 154678/437929 [00:03<00:05, 55829.44it/s] 37%|███▋      | 161630/437929 [00:03<00:04, 59334.17it/s] 38%|███▊      | 168077/437929 [00:03<00:07, 36895.57it/s] 40%|███▉      | 174613/437929 [00:03<00:06, 42397.38it/s] 41%|████▏     | 180705/437929 [00:03<00:05, 46651.27it/s] 43%|████▎     | 186880/437929 [00:03<00:04, 50344.04it/s] 44%|████▍     | 193093/437929 [00:04<00:04, 53306.55it/s] 46%|████▌     | 200050/437929 [00:04<00:04, 57325.15it/s] 47%|████▋     | 206452/437929 [00:04<00:03, 59180.78it/s] 49%|████▉     | 213562/437929 [00:04<00:03, 62313.25it/s] 51%|█████     | 221306/437929 [00:04<00:03, 66191.79it/s] 52%|█████▏    | 228206/437929 [00:04<00:05, 37895.75it/s] 54%|█████▎    | 234669/437929 [00:04<00:04, 43264.37it/s] 55%|█████▌    | 241032/437929 [00:04<00:04, 47858.96it/s] 57%|█████▋    | 248734/437929 [00:05<00:03, 53990.08it/s] 58%|█████▊    | 255628/437929 [00:05<00:03, 57744.75it/s] 60%|█████▉    | 262210/437929 [00:05<00:02, 58668.66it/s] 61%|██████▏   | 268914/437929 [00:05<00:02, 60949.40it/s] 63%|██████▎   | 275787/437929 [00:05<00:02, 63091.83it/s] 64%|██████▍   | 282410/437929 [00:05<00:02, 63114.70it/s] 66%|██████▌   | 289131/437929 [00:06<00:04, 33749.10it/s] 68%|██████▊   | 296100/437929 [00:06<00:03, 39926.30it/s] 69%|██████▉   | 303728/437929 [00:06<00:02, 46586.65it/s] 71%|███████   | 311382/437929 [00:06<00:02, 52782.84it/s] 73%|███████▎  | 319037/437929 [00:06<00:02, 58203.26it/s] 74%|███████▍  | 325994/437929 [00:06<00:01, 59849.19it/s] 76%|███████▌  | 332786/437929 [00:06<00:01, 59958.95it/s] 78%|███████▊  | 339632/437929 [00:06<00:01, 62277.28it/s] 79%|███████▉  | 346356/437929 [00:06<00:01, 63687.24it/s] 81%|████████  | 353026/437929 [00:06<00:01, 62947.93it/s] 82%|████████▏ | 360295/437929 [00:07<00:01, 65583.71it/s] 84%|████████▍ | 367058/437929 [00:07<00:01, 66184.17it/s] 85%|████████▌ | 373802/437929 [00:07<00:02, 30566.65it/s] 87%|████████▋ | 381367/437929 [00:07<00:01, 37220.82it/s] 89%|████████▊ | 388466/437929 [00:07<00:01, 43416.31it/s] 90%|█████████ | 396131/437929 [00:07<00:00, 49907.26it/s] 92%|█████████▏| 402792/437929 [00:08<00:00, 53864.75it/s] 93%|█████████▎| 409438/437929 [00:08<00:00, 56792.59it/s] 95%|█████████▌| 417006/437929 [00:08<00:00, 61388.33it/s] 97%|█████████▋| 424642/437929 [00:08<00:00, 65224.40it/s] 99%|█████████▊| 432289/437929 [00:08<00:00, 68233.30it/s]100%|██████████| 437929/437929 [00:08<00:00, 51472.81it/s]
Saving...
Done!
Epoch 1 training...
Evaluating...
Train: 0.08426121829221296 Validation: 0.08375703776575145 Test: 0.08214602138344645 Train loss: 0.12530687593544068
Epoch 2 training...
Evaluating...
Train: 0.11932336104120513 Validation: 0.11334090699723977 Test: 0.11021224284466832 Train loss: 0.046115142394638216
Epoch 3 training...
Evaluating...
Train: 0.15064515785333765 Validation: 0.12896028359498393 Test: 0.12899326625601407 Train loss: 0.04369604842801265
Epoch 4 training...
Evaluating...
Train: 0.18540726097565635 Validation: 0.15017195874754405 Test: 0.15422802680519496 Train loss: 0.04196447405659364
Epoch 5 training...
Evaluating...
Train: 0.2172379240448916 Validation: 0.17021801205921286 Test: 0.16988342214487337 Train loss: 0.040533584244603696
Epoch 6 training...
Evaluating...
Train: 0.23363658234742077 Validation: 0.17210196684151793 Test: 0.17182963006682228 Train loss: 0.039286102960124296
Epoch 7 training...
Evaluating...
Train: 0.2472567065874356 Validation: 0.18377302473444249 Test: 0.1883577982741352 Train loss: 0.03829308030099613
Epoch 8 training...
Evaluating...
Train: 0.2801827285435368 Validation: 0.191553196041141 Test: 0.18802540872636977 Train loss: 0.03738378756118352
Epoch 9 training...
Evaluating...
Train: 0.291858033783183 Validation: 0.1993527852043632 Test: 0.194957694959841 Train loss: 0.03668159066030716
Epoch 10 training...
Evaluating...
Train: 0.31142454666083785 Validation: 0.20709934700268354 Test: 0.2038739444272941 Train loss: 0.03593634239039428
Epoch 11 training...
Evaluating...
Train: 0.3256509920319858 Validation: 0.21320784410191115 Test: 0.20800832801305974 Train loss: 0.035366248488399
Epoch 12 training...
Evaluating...
Train: 0.3357721968440984 Validation: 0.21190061385899686 Test: 0.2093239465139637 Train loss: 0.03476637668181088
Epoch 13 training...
Evaluating...
Train: 0.3563059098559855 Validation: 0.21373593105453736 Test: 0.20960302216450652 Train loss: 0.03426003940791229
Epoch 14 training...
Evaluating...
Train: 0.3685651811297528 Validation: 0.22333427741561956 Test: 0.21587300975241827 Train loss: 0.033834430988445345
Epoch 15 training...
Evaluating...
Train: 0.37156047780954526 Validation: 0.21476052452166292 Test: 0.21124525549005027 Train loss: 0.03337585455564533
Epoch 16 training...
Evaluating...
Train: 0.38457537952827636 Validation: 0.22127779036653775 Test: 0.2166602921022163 Train loss: 0.03309306073076669
Epoch 17 training...
Evaluating...
Train: 0.38920411923583886 Validation: 0.22495314718842813 Test: 0.21739958833876344 Train loss: 0.03266672946314053
Epoch 18 training...
Evaluating...
Train: 0.40998826857561554 Validation: 0.2252465028241933 Test: 0.22472042567518813 Train loss: 0.03222345008288283
Epoch 19 training...
Evaluating...
Train: 0.41837974483095686 Validation: 0.22581679333897348 Test: 0.22377620005110727 Train loss: 0.031893752695593934
Epoch 20 training...
Evaluating...
Train: 0.42394387881358375 Validation: 0.2283755132742973 Test: 0.22776920861809594 Train loss: 0.03164060042873079
Epoch 21 training...
Evaluating...
Train: 0.44058231705362777 Validation: 0.22574190438710975 Test: 0.22928237152260478 Train loss: 0.03064924106001854
Epoch 22 training...
Evaluating...
Train: 0.4452228766512222 Validation: 0.23296461346170058 Test: 0.23116517433543143 Train loss: 0.03030223906015701
Epoch 23 training...
Evaluating...
Train: 0.46947892578874484 Validation: 0.23239940640418036 Test: 0.22952228490292098 Train loss: 0.02986069017214397
Epoch 24 training...
Evaluating...
Train: 0.47454375533599474 Validation: 0.23203784402171188 Test: 0.22929421461461874 Train loss: 0.029575155068997095
Epoch 25 training...
Evaluating...
Train: 0.4831604661920086 Validation: 0.23721949644981574 Test: 0.23316574499490125 Train loss: 0.02931550074330619
Epoch 26 training...
Evaluating...
Train: 0.4885123538779373 Validation: 0.2360316712249566 Test: 0.22988902308413223 Train loss: 0.028991774028647416
Epoch 27 training...
Evaluating...
Train: 0.4980798046598219 Validation: 0.23724914912605838 Test: 0.2340468371199962 Train loss: 0.028718621346220604
Epoch 28 training...
Evaluating...
Train: 0.4983917034407367 Validation: 0.23595976401943292 Test: 0.23240475533675928 Train loss: 0.028464601126174972
Epoch 29 training...
Evaluating...
Train: 0.5136656871911278 Validation: 0.24206567433283765 Test: 0.23868802728989919 Train loss: 0.02820262684941923
Epoch 30 training...
Evaluating...
Train: 0.5214508208896305 Validation: 0.2403882593683847 Test: 0.2364919922592344 Train loss: 0.02793614580102096
Epoch 31 training...
Evaluating...
Train: 0.5279882100113389 Validation: 0.2359723563264006 Test: 0.2302568591428682 Train loss: 0.027720932065733075
Epoch 32 training...
Evaluating...
Train: 0.5349881239536175 Validation: 0.23262628470344623 Test: 0.23054187451686448 Train loss: 0.027454567062576662
Epoch 33 training...
Evaluating...
Train: 0.5402465025563133 Validation: 0.2400204828770479 Test: 0.23478647063631702 Train loss: 0.02721874630439229
Epoch 34 training...
Evaluating...
Train: 0.542323262852853 Validation: 0.2381271957283631 Test: 0.23759388116866773 Train loss: 0.02700872836706628
Epoch 35 training...
Evaluating...
Train: 0.5520959185261018 Validation: 0.2350323414223816 Test: 0.23140449341573469 Train loss: 0.026800785515079147
Epoch 36 training...
Evaluating...
Train: 0.5518217198711494 Validation: 0.23673791094514438 Test: 0.23257743534203804 Train loss: 0.026651977168204274
Epoch 37 training...
Evaluating...
Train: 0.5647500808295711 Validation: 0.24279755694578062 Test: 0.2337327266066546 Train loss: 0.026378073352011474
Epoch 38 training...
Evaluating...
Train: 0.5701684093299574 Validation: 0.24000379672075703 Test: 0.23280473597349488 Train loss: 0.026219868443367513
Epoch 39 training...
Evaluating...
Train: 0.5708139698171764 Validation: 0.23792466824886882 Test: 0.2299462132241386 Train loss: 0.026002441799585142
Epoch 40 training...
Evaluating...
Train: 0.5766814477530325 Validation: 0.24118711329476758 Test: 0.23338051994939366 Train loss: 0.02583214871985382
Epoch 41 training...
Evaluating...
Train: 0.5999281009741496 Validation: 0.24463525669563047 Test: 0.24032688916208717 Train loss: 0.02504541182964006
Epoch 42 training...
Evaluating...
Train: 0.602412054335189 Validation: 0.24128448302151195 Test: 0.2332692062450744 Train loss: 0.02471228416293446
Epoch 43 training...
Evaluating...
Train: 0.6096432503298738 Validation: 0.24230440253333357 Test: 0.23545609300623863 Train loss: 0.024445431022255132
Epoch 44 training...
Evaluating...
Train: 0.612092583214596 Validation: 0.2395857310930881 Test: 0.23552050305762925 Train loss: 0.024248771368096656
Epoch 45 training...
Evaluating...
Train: 0.6173945474683399 Validation: 0.23874911784171896 Test: 0.2329981755729713 Train loss: 0.024043585799316078
Epoch 46 training...
Evaluating...
Train: 0.6236554331744112 Validation: 0.24357696905135937 Test: 0.23310624878820668 Train loss: 0.02388650705320849
Epoch 47 training...
Evaluating...
Train: 0.6313175764870195 Validation: 0.24151902615752027 Test: 0.23533470096241008 Train loss: 0.023696141296737794
Epoch 48 training...
Evaluating...
Train: 0.6295634817059292 Validation: 0.23733655346201712 Test: 0.22833557660843654 Train loss: 0.023512214065751862
Epoch 49 training...
Evaluating...
Train: 0.635785253859809 Validation: 0.2341658674774022 Test: 0.2298683120345504 Train loss: 0.023392310612981252
Epoch 50 training...
Evaluating...
Train: 0.6453945889849702 Validation: 0.2439922775408606 Test: 0.23469205456052963 Train loss: 0.023222558802419593
Epoch 51 training...
Evaluating...
Train: 0.6481583767222076 Validation: 0.24229894019142725 Test: 0.2332413893262556 Train loss: 0.02304141128121435
Epoch 52 training...
Evaluating...
Train: 0.6491569354900255 Validation: 0.23983302862440956 Test: 0.23394927934078827 Train loss: 0.022896816826801697
Epoch 53 training...
Evaluating...
Train: 0.6528930764833948 Validation: 0.24019838444528693 Test: 0.2287790843775474 Train loss: 0.022733754376350876
Epoch 54 training...
Evaluating...
Train: 0.6525108010669018 Validation: 0.23603449262426573 Test: 0.22875560900091882 Train loss: 0.02261529704440219
Epoch 55 training...
Evaluating...
Train: 0.6647132498365514 Validation: 0.23772856040920956 Test: 0.22921538191697194 Train loss: 0.022436425121129647
Epoch 56 training...
Evaluating...
Train: 0.6628348455285864 Validation: 0.23581649411982042 Test: 0.22708978204057886 Train loss: 0.022274823589937542
Epoch 57 training...
Evaluating...
Train: 0.6664071112395616 Validation: 0.23693933621400326 Test: 0.22763158126801483 Train loss: 0.022186903225174998
Epoch 58 training...
Evaluating...
Train: 0.6728461022208649 Validation: 0.2360696546958239 Test: 0.23162456738993903 Train loss: 0.022025282222266025
Epoch 59 training...
Evaluating...
Train: 0.6801423022054566 Validation: 0.23897108933960792 Test: 0.231017765105164 Train loss: 0.021862855733496764
Epoch 60 training...
Evaluating...
Train: 0.6750140460389041 Validation: 0.2361686189086163 Test: 0.22786206946707516 Train loss: 0.021735062768276022
Epoch 61 training...
Evaluating...
Train: 0.6961512248295173 Validation: 0.2396865444466784 Test: 0.23065797196588667 Train loss: 0.021023167705080364
Epoch 62 training...
Evaluating...
Train: 0.7055626105170294 Validation: 0.23812105387367455 Test: 0.22777450815161518 Train loss: 0.020726811950325618
Epoch 63 training...
Evaluating...
Train: 0.7056657443564669 Validation: 0.2373714857924592 Test: 0.2279828779424586 Train loss: 0.02046689560597421
Epoch 64 training...
Evaluating...
Train: 0.7080726896024191 Validation: 0.23517373453525936 Test: 0.22757512421439402 Train loss: 0.020348611914663636
Epoch 65 training...
Evaluating...
Train: 0.7159665093166355 Validation: 0.2371294804598038 Test: 0.22806085591949882 Train loss: 0.02023645649358652
Epoch 66 training...
Evaluating...
Train: 0.7158550577182321 Validation: 0.23606330157315022 Test: 0.22449443853451628 Train loss: 0.0200761101039234
Epoch 67 training...
Evaluating...
Train: 0.7211963091355174 Validation: 0.234381022051273 Test: 0.22756438461540043 Train loss: 0.01990302070129018
Epoch 68 training...
Evaluating...
Train: 0.7183682282604463 Validation: 0.23518268155999206 Test: 0.22850416559976797 Train loss: 0.0197733768742937
Epoch 69 training...
Evaluating...
Train: 0.7300988273320225 Validation: 0.23715062347382018 Test: 0.2267708713434227 Train loss: 0.0196522383558121
Epoch 70 training...
Evaluating...
Train: 0.73152363541821 Validation: 0.23672488181125917 Test: 0.22703188411329772 Train loss: 0.019522541101240954
Epoch 71 training...
Evaluating...
Train: 0.7370251757202826 Validation: 0.2343112820424401 Test: 0.22667393383633516 Train loss: 0.019355907080418833
Epoch 72 training...
Evaluating...
Train: 0.7381728874896502 Validation: 0.23128785524115036 Test: 0.2255740567849812 Train loss: 0.019245955392370003
Epoch 73 training...
Evaluating...
Train: 0.7403797711940471 Validation: 0.2344520930551316 Test: 0.22293086613411167 Train loss: 0.019135027568395486
Epoch 74 training...
Evaluating...
Train: 0.7444388130136732 Validation: 0.23612928814271097 Test: 0.2269655840323154 Train loss: 0.019026533085880072
Epoch 75 training...
Evaluating...
Train: 0.7454036691572508 Validation: 0.2330339641831196 Test: 0.22493373172793077 Train loss: 0.018888175435815963
Epoch 76 training...
Evaluating...
Train: 0.7499081916460896 Validation: 0.2348494485877929 Test: 0.22045625640530764 Train loss: 0.018797828760093324
Epoch 77 training...
Evaluating...
Train: 0.746917824149891 Validation: 0.23066239396351323 Test: 0.22192592101692926 Train loss: 0.01869119278279761
Epoch 78 training...
Evaluating...
Train: 0.7569863023350891 Validation: 0.23266352701225193 Test: 0.22333243174977577 Train loss: 0.018554034174832878
Epoch 79 training...
Evaluating...
Train: 0.7549789857555756 Validation: 0.22990561350029573 Test: 0.2233517721398791 Train loss: 0.018467001310482328
Epoch 80 training...
Evaluating...
Train: 0.7619232048961738 Validation: 0.23102352682403665 Test: 0.22415436570222233 Train loss: 0.01833114494760762
Epoch 81 training...
Evaluating...
Train: 0.7748137707619154 Validation: 0.2339722644312622 Test: 0.22417255611669065 Train loss: 0.017671119844523266
Epoch 82 training...
Evaluating...
Train: 0.7782271190912192 Validation: 0.23486400709095256 Test: 0.22480179833381608 Train loss: 0.017456487054515486
Epoch 83 training...
Evaluating...
Train: 0.7814100945201073 Validation: 0.22863346944301782 Test: 0.22214346657637601 Train loss: 0.01728182491949107
Epoch 84 training...
Evaluating...
Train: 0.7840223612225867 Validation: 0.2323462823599082 Test: 0.22127713904563104 Train loss: 0.01716836011669904
Epoch 85 training...
Evaluating...
Train: 0.7895266241603643 Validation: 0.23489303912782203 Test: 0.22113570700039234 Train loss: 0.01702382558666937
Epoch 86 training...
Evaluating...
Train: 0.7903692649101558 Validation: 0.23160702902900862 Test: 0.22001959220048348 Train loss: 0.016907671545043728
Epoch 87 training...
Evaluating...
Train: 0.7914152681093842 Validation: 0.23072107820352547 Test: 0.21929802300297627 Train loss: 0.016842977815954636
Epoch 88 training...
Evaluating...
Train: 0.7952799141052904 Validation: 0.23238793200940108 Test: 0.2205371804911058 Train loss: 0.016702743570291056
Epoch 89 training...
Evaluating...
Train: 0.7979684562615267 Validation: 0.23100188395801258 Test: 0.22084791226975453 Train loss: 0.016610588308306747
Epoch 90 training...
Evaluating...
Train: 0.8007292081994962 Validation: 0.2316948882003556 Test: 0.21968640225233987 Train loss: 0.016566066239083594
Epoch 91 training...
Evaluating...
Train: 0.8006967128313776 Validation: 0.23338353182806323 Test: 0.22240152448483885 Train loss: 0.016435702939887196
Epoch 92 training...
Evaluating...
Train: 0.8075771037101596 Validation: 0.23290690463842748 Test: 0.2218656749157093 Train loss: 0.016378779225173855
Epoch 93 training...
Evaluating...
Train: 0.8093415035388075 Validation: 0.22880865828342023 Test: 0.2186749537710389 Train loss: 0.016226357575628424
Epoch 94 training...
Evaluating...
Train: 0.8100874818026969 Validation: 0.22888513317295325 Test: 0.21856855726395108 Train loss: 0.016218165320074193
Epoch 95 training...
