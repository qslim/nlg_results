{'dataset_name': 'ogbg-molpcba', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'hyperparams': {'batch_size': 128, 'epochs': 501, 'learning_rate': 0.0005, 'step_size': 50, 'decay_rate': 0.75}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'sum', 'nonlinear_conv': 'CB', 'variants': {'BN': 'N', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '4be31d67403d061af877d0ffc1a1e7960d55f83e', 'time_stamp': '1593912987', 'directory': '../../nlg_results/ogbg/board/'}
Downloading https://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/pcba.zip
  0%|          | 0/39 [00:00<?, ?it/s]Downloaded 0.00 GB:   0%|          | 0/39 [00:30<?, ?it/s]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:30<19:06, 30.16s/it]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:57<19:06, 30.16s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:57<18:06, 29.36s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [01:24<18:06, 29.36s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [01:24<17:10, 28.63s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [01:58<17:10, 28.63s/it]Downloaded 0.00 GB:  10%|█         | 4/39 [01:58<17:40, 30.30s/it]Downloaded 0.00 GB:  10%|█         | 4/39 [02:37<17:40, 30.30s/it]Downloaded 0.00 GB:  13%|█▎        | 5/39 [02:37<18:34, 32.79s/it]Downloaded 0.01 GB:  13%|█▎        | 5/39 [03:12<18:34, 32.79s/it]Downloaded 0.01 GB:  15%|█▌        | 6/39 [03:12<18:23, 33.43s/it]Downloaded 0.01 GB:  15%|█▌        | 6/39 [03:57<18:23, 33.43s/it]Downloaded 0.01 GB:  18%|█▊        | 7/39 [03:57<19:44, 37.02s/it]Downloaded 0.01 GB:  18%|█▊        | 7/39 [04:29<19:44, 37.02s/it]Downloaded 0.01 GB:  21%|██        | 8/39 [04:29<18:17, 35.40s/it]Downloaded 0.01 GB:  21%|██        | 8/39 [05:03<18:17, 35.40s/it]Downloaded 0.01 GB:  23%|██▎       | 9/39 [05:03<17:30, 35.03s/it]Downloaded 0.01 GB:  23%|██▎       | 9/39 [05:55<17:30, 35.03s/it]Downloaded 0.01 GB:  26%|██▌       | 10/39 [05:55<19:20, 40.02s/it]Downloaded 0.01 GB:  26%|██▌       | 10/39 [06:46<19:20, 40.02s/it]Downloaded 0.01 GB:  28%|██▊       | 11/39 [06:46<20:17, 43.48s/it]Downloaded 0.01 GB:  28%|██▊       | 11/39 [07:34<20:17, 43.48s/it]Downloaded 0.01 GB:  31%|███       | 12/39 [07:34<20:09, 44.81s/it]Downloaded 0.01 GB:  31%|███       | 12/39 [08:29<20:09, 44.81s/it]Downloaded 0.01 GB:  33%|███▎      | 13/39 [08:29<20:42, 47.78s/it]Downloaded 0.01 GB:  33%|███▎      | 13/39 [09:18<20:42, 47.78s/it]Downloaded 0.01 GB:  36%|███▌      | 14/39 [09:18<20:02, 48.11s/it]Downloaded 0.01 GB:  36%|███▌      | 14/39 [10:03<20:02, 48.11s/it]Downloaded 0.01 GB:  38%|███▊      | 15/39 [10:03<18:51, 47.14s/it]Downloaded 0.02 GB:  38%|███▊      | 15/39 [10:39<18:51, 47.14s/it]Downloaded 0.02 GB:  41%|████      | 16/39 [10:39<16:48, 43.85s/it]Downloaded 0.02 GB:  41%|████      | 16/39 [11:17<16:48, 43.85s/it]Downloaded 0.02 GB:  44%|████▎     | 17/39 [11:17<15:27, 42.15s/it]Downloaded 0.02 GB:  44%|████▎     | 17/39 [12:12<15:27, 42.15s/it]Downloaded 0.02 GB:  46%|████▌     | 18/39 [12:12<16:05, 45.96s/it]Downloaded 0.02 GB:  46%|████▌     | 18/39 [13:07<16:05, 45.96s/it]Downloaded 0.02 GB:  49%|████▊     | 19/39 [13:07<16:15, 48.77s/it]Downloaded 0.02 GB:  49%|████▊     | 19/39 [13:50<16:15, 48.77s/it]Downloaded 0.02 GB:  51%|█████▏    | 20/39 [13:50<14:53, 47.04s/it]Downloaded 0.02 GB:  51%|█████▏    | 20/39 [14:37<14:53, 47.04s/it]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [14:37<14:06, 47.04s/it]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [15:28<14:06, 47.04s/it]Downloaded 0.02 GB:  56%|█████▋    | 22/39 [15:28<13:39, 48.22s/it]Downloaded 0.02 GB:  56%|█████▋    | 22/39 [16:17<13:39, 48.22s/it]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [16:17<12:55, 48.47s/it]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [17:13<12:55, 48.47s/it]Downloaded 0.02 GB:  62%|██████▏   | 24/39 [17:13<12:40, 50.70s/it]Downloaded 0.02 GB:  62%|██████▏   | 24/39 [18:05<12:40, 50.70s/it]Downloaded 0.02 GB:  64%|██████▍   | 25/39 [18:05<11:55, 51.12s/it]Downloaded 0.03 GB:  64%|██████▍   | 25/39 [18:36<11:55, 51.12s/it]Downloaded 0.03 GB:  67%|██████▋   | 26/39 [18:36<09:45, 45.03s/it]Downloaded 0.03 GB:  67%|██████▋   | 26/39 [19:38<09:45, 45.03s/it]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [19:38<10:02, 50.23s/it]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [20:32<10:02, 50.23s/it]Downloaded 0.03 GB:  72%|███████▏  | 28/39 [20:32<09:23, 51.18s/it]Downloaded 0.03 GB:  72%|███████▏  | 28/39 [21:34<09:23, 51.18s/it]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [21:34<09:04, 54.40s/it]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [22:25<09:04, 54.40s/it]Downloaded 0.03 GB:  77%|███████▋  | 30/39 [22:25<08:01, 53.50s/it]Downloaded 0.03 GB:  77%|███████▋  | 30/39 [23:24<08:01, 53.50s/it]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [23:24<07:20, 55.08s/it]Downloaded 0.03 GB:  79%|███████▉  | 31/39 [24:20<07:20, 55.08s/it]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [24:20<06:26, 55.27s/it]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [25:11<06:26, 55.27s/it]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [25:11<05:24, 54.00s/it]Downloaded 0.03 GB:  85%|████████▍ | 33/39 [25:57<05:24, 54.00s/it]Downloaded 0.03 GB:  87%|████████▋ | 34/39 [25:57<04:18, 51.71s/it]Downloaded 0.03 GB:  87%|████████▋ | 34/39 [27:08<04:18, 51.71s/it]Downloaded 0.03 GB:  90%|████████▉ | 35/39 [27:08<03:50, 57.52s/it]Downloaded 0.04 GB:  90%|████████▉ | 35/39 [27:50<03:50, 57.52s/it]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [27:50<02:38, 52.70s/it]Downloaded 0.04 GB:  92%|█████████▏| 36/39 [28:49<02:38, 52.70s/it]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [28:49<01:49, 54.88s/it]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [29:38<01:49, 54.88s/it]Downloaded 0.04 GB:  97%|█████████▋| 38/39 [29:38<00:53, 53.04s/it]Downloaded 0.04 GB:  97%|█████████▋| 38/39 [29:38<00:53, 53.04s/it]Downloaded 0.04 GB: 100%|██████████| 39/39 [29:38<00:00, 45.61s/it]
Extracting dataset/pcba.zip
Processing...
Loading necessary files...
This might take a while.
Processing graphs...
  0%|          | 0/437929 [00:00<?, ?it/s]  1%|          | 3510/437929 [00:00<00:12, 35097.94it/s]  2%|▏         | 7582/437929 [00:00<00:11, 36613.30it/s]  3%|▎         | 11478/437929 [00:00<00:11, 37285.96it/s]  3%|▎         | 14533/437929 [00:00<00:12, 34970.84it/s]  4%|▍         | 17919/437929 [00:00<00:12, 34627.43it/s]  5%|▍         | 21423/437929 [00:00<00:11, 34747.70it/s]  6%|▌         | 25653/437929 [00:00<00:11, 36712.93it/s]  7%|▋         | 29123/437929 [00:00<00:11, 36084.94it/s]  7%|▋         | 32645/437929 [00:00<00:11, 35820.07it/s]  8%|▊         | 36222/437929 [00:01<00:11, 35803.94it/s]  9%|▉         | 39789/437929 [00:01<00:11, 35763.15it/s] 10%|▉         | 43308/437929 [00:01<00:11, 35517.97it/s] 11%|█         | 46835/437929 [00:01<00:11, 35440.88it/s] 11%|█▏        | 50352/437929 [00:01<00:11, 34943.77it/s] 12%|█▏        | 53895/437929 [00:01<00:10, 35087.50it/s] 13%|█▎        | 57501/437929 [00:01<00:10, 35373.61it/s] 14%|█▍        | 61725/437929 [00:01<00:10, 37185.46it/s] 15%|█▌        | 65730/437929 [00:01<00:09, 37999.75it/s] 16%|█▌        | 69548/437929 [00:01<00:10, 35974.94it/s] 17%|█▋        | 73181/437929 [00:02<00:10, 35429.11it/s] 18%|█▊        | 76751/437929 [00:02<00:10, 34736.65it/s] 18%|█▊        | 80309/437929 [00:02<00:10, 34984.26it/s] 19%|█▉        | 83901/437929 [00:02<00:10, 35257.60it/s] 20%|█▉        | 87440/437929 [00:02<00:09, 35294.56it/s] 21%|██        | 90985/437929 [00:02<00:09, 35336.09it/s] 22%|██▏       | 94526/437929 [00:02<00:09, 35357.61it/s] 22%|██▏       | 98515/437929 [00:02<00:09, 36603.98it/s] 23%|██▎       | 102661/437929 [00:02<00:08, 37933.76it/s] 24%|██▍       | 106795/437929 [00:02<00:08, 38894.16it/s] 25%|██▌       | 111134/437929 [00:03<00:08, 40139.28it/s] 26%|██▋       | 115558/437929 [00:03<00:07, 41286.49it/s] 27%|██▋       | 119713/437929 [00:03<00:07, 41156.54it/s] 28%|██▊       | 123847/437929 [00:03<00:08, 38265.59it/s] 29%|██▉       | 127727/437929 [00:03<00:08, 36509.28it/s] 30%|███       | 131433/437929 [00:03<00:08, 35851.64it/s] 31%|███       | 135059/437929 [00:03<00:08, 35553.49it/s] 32%|███▏      | 138644/437929 [00:03<00:08, 34564.18it/s] 32%|███▏      | 142141/437929 [00:03<00:08, 34684.53it/s] 33%|███▎      | 145782/437929 [00:04<00:08, 35183.01it/s] 34%|███▍      | 149872/437929 [00:04<00:07, 36721.80it/s] 35%|███▌      | 154192/437929 [00:04<00:07, 38451.21it/s] 36%|███▌      | 158409/437929 [00:04<00:07, 39495.51it/s] 37%|███▋      | 162476/437929 [00:04<00:06, 39838.37it/s] 38%|███▊      | 166889/437929 [00:04<00:06, 41034.82it/s] 39%|███▉      | 171266/437929 [00:04<00:06, 41818.72it/s] 40%|████      | 175471/437929 [00:04<00:06, 41821.37it/s] 41%|████      | 179713/437929 [00:04<00:06, 41997.32it/s] 42%|████▏     | 183924/437929 [00:04<00:06, 38927.62it/s] 43%|████▎     | 187870/437929 [00:05<00:06, 37043.79it/s] 44%|████▍     | 191631/437929 [00:05<00:06, 36214.91it/s] 45%|████▍     | 195296/437929 [00:05<00:06, 35153.87it/s] 45%|████▌     | 198849/437929 [00:05<00:06, 34589.88it/s] 46%|████▌     | 202351/437929 [00:05<00:06, 34716.95it/s] 47%|████▋     | 206404/437929 [00:05<00:06, 36275.62it/s] 48%|████▊     | 210772/437929 [00:05<00:05, 38218.83it/s] 49%|████▉     | 215202/437929 [00:05<00:05, 39860.23it/s] 50%|█████     | 219418/437929 [00:05<00:05, 40523.09it/s] 51%|█████     | 223511/437929 [00:05<00:05, 40308.24it/s] 52%|█████▏    | 227571/437929 [00:06<00:05, 37006.68it/s] 53%|█████▎    | 231345/437929 [00:06<00:05, 36443.24it/s] 54%|█████▎    | 235043/437929 [00:06<00:05, 36253.83it/s] 55%|█████▍    | 239342/437929 [00:06<00:05, 38041.50it/s] 56%|█████▌    | 243614/437929 [00:06<00:04, 39332.62it/s] 57%|█████▋    | 247828/437929 [00:06<00:04, 40134.63it/s] 58%|█████▊    | 251892/437929 [00:06<00:04, 40284.10it/s] 59%|█████▊    | 256222/437929 [00:06<00:04, 41143.55it/s] 59%|█████▉    | 260359/437929 [00:06<00:04, 41083.02it/s] 60%|██████    | 264483/437929 [00:07<00:04, 37798.48it/s] 61%|██████▏   | 268326/437929 [00:07<00:04, 37126.22it/s] 62%|██████▏   | 272086/437929 [00:07<00:04, 36588.40it/s] 63%|██████▎   | 276536/437929 [00:07<00:04, 38644.89it/s] 64%|██████▍   | 280775/437929 [00:07<00:03, 39696.40it/s] 65%|██████▌   | 285200/437929 [00:07<00:03, 40957.91it/s] 66%|██████▌   | 289485/437929 [00:07<00:03, 41507.08it/s] 67%|██████▋   | 293895/437929 [00:07<00:03, 42251.74it/s] 68%|██████▊   | 298146/437929 [00:07<00:03, 39557.03it/s] 69%|██████▉   | 302155/437929 [00:08<00:03, 38083.11it/s] 70%|██████▉   | 306012/437929 [00:08<00:03, 38014.35it/s] 71%|███████   | 310206/437929 [00:08<00:03, 39111.02it/s] 72%|███████▏  | 314652/437929 [00:08<00:03, 40573.98it/s] 73%|███████▎  | 319068/437929 [00:08<00:02, 41586.50it/s] 74%|███████▍  | 323482/437929 [00:08<00:02, 42320.85it/s] 75%|███████▍  | 327740/437929 [00:08<00:02, 42087.82it/s] 76%|███████▌  | 331967/437929 [00:08<00:02, 39965.44it/s] 77%|███████▋  | 335999/437929 [00:08<00:02, 37208.50it/s] 78%|███████▊  | 339783/437929 [00:08<00:02, 36329.44it/s] 78%|███████▊  | 343615/437929 [00:09<00:02, 36904.48it/s] 79%|███████▉  | 347342/437929 [00:09<00:02, 36422.81it/s] 80%|████████  | 351011/437929 [00:09<00:02, 36156.00it/s] 81%|████████  | 354646/437929 [00:09<00:02, 35803.79it/s] 82%|████████▏ | 358241/437929 [00:09<00:02, 35816.73it/s] 83%|████████▎ | 361833/437929 [00:09<00:02, 35604.87it/s] 83%|████████▎ | 365401/437929 [00:09<00:02, 35587.66it/s] 84%|████████▍ | 369460/437929 [00:09<00:01, 36949.70it/s] 85%|████████▌ | 373172/437929 [00:09<00:01, 35269.68it/s] 86%|████████▌ | 376727/437929 [00:10<00:01, 34711.38it/s] 87%|████████▋ | 380354/437929 [00:10<00:01, 35162.24it/s] 88%|████████▊ | 384249/437929 [00:10<00:01, 36217.86it/s] 89%|████████▊ | 388493/437929 [00:10<00:01, 37880.89it/s] 90%|████████▉ | 392681/437929 [00:10<00:01, 38997.11it/s] 91%|█████████ | 396951/437929 [00:10<00:01, 40037.52it/s] 92%|█████████▏| 400984/437929 [00:10<00:00, 39242.27it/s] 92%|█████████▏| 404933/437929 [00:10<00:00, 37325.15it/s] 93%|█████████▎| 408702/437929 [00:10<00:00, 36542.70it/s] 94%|█████████▍| 412386/437929 [00:10<00:00, 36262.87it/s] 95%|█████████▌| 416034/437929 [00:11<00:00, 36059.38it/s] 96%|█████████▌| 419655/437929 [00:11<00:00, 35938.28it/s] 97%|█████████▋| 423260/437929 [00:11<00:00, 35748.03it/s] 97%|█████████▋| 426843/437929 [00:11<00:00, 35678.25it/s] 98%|█████████▊| 430417/437929 [00:11<00:00, 35604.05it/s] 99%|█████████▉| 434608/437929 [00:11<00:00, 37286.96it/s]100%|██████████| 437929/437929 [00:11<00:00, 37682.74it/s]
Converting graphs into PyG objects...
  0%|          | 0/437929 [00:00<?, ?it/s]  0%|          | 1156/437929 [00:00<00:40, 10832.06it/s]  2%|▏         | 8586/437929 [00:00<00:29, 14564.38it/s]  3%|▎         | 14414/437929 [00:00<00:22, 18793.33it/s]  4%|▍         | 18818/437929 [00:00<00:18, 22696.59it/s]  5%|▌         | 22567/437929 [00:00<00:19, 21271.34it/s]  6%|▋         | 28126/437929 [00:00<00:15, 26106.09it/s]  7%|▋         | 32556/437929 [00:00<00:13, 29774.15it/s]  9%|▊         | 37692/437929 [00:00<00:11, 34066.98it/s] 10%|▉         | 42071/437929 [00:01<00:14, 27279.89it/s] 10%|█         | 45767/437929 [00:01<00:13, 29604.17it/s] 11%|█▏        | 50319/437929 [00:01<00:11, 33072.89it/s] 13%|█▎        | 55413/437929 [00:01<00:10, 36962.15it/s] 14%|█▍        | 60370/437929 [00:01<00:13, 27578.58it/s] 15%|█▍        | 65649/437929 [00:01<00:11, 32189.97it/s] 16%|█▌        | 70290/437929 [00:01<00:10, 35448.24it/s] 17%|█▋        | 75063/437929 [00:02<00:09, 38412.02it/s] 18%|█▊        | 80057/437929 [00:02<00:08, 41269.43it/s] 20%|█▉        | 86291/437929 [00:02<00:07, 45925.90it/s] 21%|██        | 91359/437929 [00:02<00:10, 34551.71it/s] 22%|██▏       | 96247/437929 [00:02<00:09, 37881.83it/s] 23%|██▎       | 101062/437929 [00:02<00:08, 40470.58it/s] 24%|██▍       | 106130/437929 [00:02<00:07, 43072.79it/s] 25%|██▌       | 111462/437929 [00:02<00:07, 45707.96it/s] 27%|██▋       | 116346/437929 [00:02<00:07, 45149.75it/s] 28%|██▊       | 121126/437929 [00:03<00:11, 26636.39it/s] 29%|██▉       | 126228/437929 [00:03<00:10, 31094.63it/s] 30%|███       | 132850/437929 [00:03<00:08, 36978.76it/s] 32%|███▏      | 138232/437929 [00:03<00:07, 40808.71it/s] 33%|███▎      | 143265/437929 [00:03<00:07, 42067.01it/s] 34%|███▍      | 148424/437929 [00:03<00:06, 44533.10it/s] 35%|███▌      | 153750/437929 [00:03<00:06, 46834.31it/s] 36%|███▋      | 158824/437929 [00:04<00:05, 47687.97it/s] 37%|███▋      | 163870/437929 [00:04<00:10, 26658.56it/s] 38%|███▊      | 168302/437929 [00:04<00:08, 30265.03it/s] 40%|███▉      | 173425/437929 [00:04<00:07, 34500.52it/s] 41%|████      | 178788/437929 [00:04<00:06, 38634.14it/s] 42%|████▏     | 183738/437929 [00:04<00:06, 41356.67it/s] 43%|████▎     | 188500/437929 [00:04<00:05, 42675.85it/s] 44%|████▍     | 193546/437929 [00:05<00:05, 44745.73it/s] 46%|████▌     | 200109/437929 [00:05<00:04, 49467.78it/s] 47%|████▋     | 207075/437929 [00:05<00:04, 54178.76it/s] 49%|████▉     | 214133/437929 [00:05<00:03, 58237.36it/s] 50%|█████     | 220330/437929 [00:05<00:06, 34644.60it/s] 52%|█████▏    | 226026/437929 [00:05<00:05, 39257.82it/s] 53%|█████▎    | 231145/437929 [00:05<00:05, 40898.37it/s] 54%|█████▍    | 236217/437929 [00:05<00:04, 43420.68it/s] 55%|█████▌    | 242677/437929 [00:06<00:04, 48156.80it/s] 57%|█████▋    | 249873/437929 [00:06<00:03, 53461.17it/s] 58%|█████▊    | 255830/437929 [00:06<00:03, 52885.56it/s] 60%|█████▉    | 261547/437929 [00:06<00:03, 50400.14it/s] 61%|██████    | 266912/437929 [00:06<00:03, 50567.41it/s] 62%|██████▏   | 272906/437929 [00:06<00:03, 53055.71it/s] 64%|██████▍   | 280058/437929 [00:06<00:02, 57508.40it/s] 65%|██████▌   | 286052/437929 [00:07<00:06, 24814.18it/s] 66%|██████▋   | 291099/437929 [00:07<00:05, 29279.15it/s] 68%|██████▊   | 297213/437929 [00:07<00:04, 34704.19it/s] 70%|██████▉   | 304572/437929 [00:07<00:03, 41241.37it/s] 71%|███████   | 310385/437929 [00:07<00:02, 45178.60it/s] 72%|███████▏  | 316177/437929 [00:07<00:02, 45323.27it/s] 73%|███████▎  | 321601/437929 [00:07<00:02, 46706.37it/s] 75%|███████▍  | 326907/437929 [00:08<00:02, 47625.14it/s] 76%|███████▌  | 333814/437929 [00:08<00:01, 52516.15it/s] 78%|███████▊  | 339534/437929 [00:08<00:01, 52717.66it/s] 79%|███████▉  | 345134/437929 [00:08<00:01, 51224.11it/s] 80%|████████  | 350496/437929 [00:08<00:01, 51264.30it/s] 81%|████████  | 355790/437929 [00:08<00:01, 51399.21it/s] 82%|████████▏ | 361048/437929 [00:08<00:01, 49406.89it/s] 84%|████████▎ | 366196/437929 [00:08<00:01, 50009.77it/s] 85%|████████▍ | 371268/437929 [00:09<00:03, 21018.53it/s] 86%|████████▌ | 376615/437929 [00:09<00:02, 25696.91it/s] 87%|████████▋ | 382504/437929 [00:09<00:01, 30925.55it/s] 89%|████████▉ | 389607/437929 [00:09<00:01, 37231.93it/s] 91%|█████████ | 396776/437929 [00:09<00:00, 43504.56it/s] 92%|█████████▏| 403726/437929 [00:09<00:00, 49003.15it/s] 94%|█████████▍| 410565/437929 [00:09<00:00, 53557.11it/s] 95%|█████████▌| 417004/437929 [00:10<00:00, 56266.18it/s] 97%|█████████▋| 423425/437929 [00:10<00:00, 52287.39it/s] 98%|█████████▊| 429267/437929 [00:10<00:00, 51439.31it/s] 99%|█████████▉| 435494/437929 [00:10<00:00, 54270.58it/s]100%|██████████| 437929/437929 [00:10<00:00, 41922.60it/s]
Saving...
Done!
Epoch 1 training...
Evaluating...
Train: 0.09748390137556023 Validation: 0.09967984091764744 Test: 0.09963630272715632 Train loss: 0.05203558902077274
Epoch 2 training...
Evaluating...
Train: 0.15124911392773768 Validation: 0.13738210557434768 Test: 0.1368561053013396 Train loss: 0.0448096344720945
Epoch 3 training...
Evaluating...
Train: 0.1961132661518686 Validation: 0.1638583770009622 Test: 0.16151526175453051 Train loss: 0.041749761551428094
Epoch 4 training...
Evaluating...
Train: 0.23015669774833977 Validation: 0.17888130822339782 Test: 0.177703200583298 Train loss: 0.03981625175660026
Epoch 5 training...
Evaluating...
Train: 0.25490051051045115 Validation: 0.1918324454961753 Test: 0.18420268253385919 Train loss: 0.03833085047373639
Epoch 6 training...
Evaluating...
Train: 0.28388248564605695 Validation: 0.20064063459846918 Test: 0.1921348510434052 Train loss: 0.03710814186292268
Epoch 7 training...
Evaluating...
Train: 0.30638717468566157 Validation: 0.20398541513434773 Test: 0.20123964368336603 Train loss: 0.03607583224264547
Epoch 8 training...
Evaluating...
Train: 0.3272640129458018 Validation: 0.21193796075290638 Test: 0.2038031794083294 Train loss: 0.03527542972397073
Epoch 9 training...
Evaluating...
Train: 0.3453736158243831 Validation: 0.21498378271696292 Test: 0.20944155003145487 Train loss: 0.03447256219376714
Epoch 10 training...
Evaluating...
Train: 0.3657833292300286 Validation: 0.21716820497693795 Test: 0.2116246206352724 Train loss: 0.033755440957819766
Epoch 11 training...
Evaluating...
Train: 0.37917563213671784 Validation: 0.21628829692468987 Test: 0.21401120465396148 Train loss: 0.03314921173550749
Epoch 12 training...
Evaluating...
Train: 0.39901752489492553 Validation: 0.2231459862882549 Test: 0.2188180668708063 Train loss: 0.032608503514562015
Epoch 13 training...
Evaluating...
Train: 0.40828696220076965 Validation: 0.22511414008903718 Test: 0.21970416436396298 Train loss: 0.03209010812870946
Epoch 14 training...
Evaluating...
Train: 0.4285953946990653 Validation: 0.22852857323894477 Test: 0.22262123061775832 Train loss: 0.03158768323448081
Epoch 15 training...
Evaluating...
Train: 0.4376921614005105 Validation: 0.23159106280970745 Test: 0.22148095752317234 Train loss: 0.031068703422283413
Epoch 16 training...
Evaluating...
Train: 0.45144328343585366 Validation: 0.23250803543989948 Test: 0.22656758383871445 Train loss: 0.030703682647004363
Epoch 17 training...
Evaluating...
Train: 0.4648183963123927 Validation: 0.23642252073392403 Test: 0.23037841941221368 Train loss: 0.03029317056815976
Epoch 18 training...
Evaluating...
Train: 0.4710016027741636 Validation: 0.22913554131689778 Test: 0.23043686478400285 Train loss: 0.029930176554211
Epoch 19 training...
Evaluating...
Train: 0.4811582830637779 Validation: 0.23431552679435141 Test: 0.22878968248397932 Train loss: 0.029555036983649342
Epoch 20 training...
Evaluating...
Train: 0.4983123245302782 Validation: 0.23236809976940606 Test: 0.22696808678060554 Train loss: 0.029192409817594696
Epoch 21 training...
Evaluating...
Train: 0.5079201296688306 Validation: 0.2360413192515814 Test: 0.2265383093615448 Train loss: 0.028865060103693916
Epoch 22 training...
Evaluating...
Train: 0.5180477124916318 Validation: 0.2326837406633575 Test: 0.2283343586449871 Train loss: 0.028578110793680278
Epoch 23 training...
Evaluating...
Train: 0.5232589646868487 Validation: 0.2372997035665162 Test: 0.23056322187052308 Train loss: 0.028272544199477
Epoch 24 training...
Evaluating...
Train: 0.5323182807709081 Validation: 0.23422343714964908 Test: 0.2263830010009075 Train loss: 0.027986195073119474
Epoch 25 training...
Evaluating...
Train: 0.5392047185257394 Validation: 0.23863268957611586 Test: 0.22711027328927677 Train loss: 0.027734556819745623
Epoch 26 training...
Evaluating...
Train: 0.5494173501360127 Validation: 0.23797140565064326 Test: 0.2292245509639429 Train loss: 0.027473622127561957
Epoch 27 training...
Evaluating...
Train: 0.5575759786805454 Validation: 0.23552506603200477 Test: 0.22779582650980423 Train loss: 0.02719070887297849
Epoch 28 training...
Evaluating...
Train: 0.5657968136341534 Validation: 0.23348576028230697 Test: 0.2272273684775654 Train loss: 0.026984011670037115
Epoch 29 training...
Evaluating...
Train: 0.5711520164243361 Validation: 0.23580569583561983 Test: 0.22704676826596215 Train loss: 0.026786026350985138
Epoch 30 training...
Evaluating...
Train: 0.5838232329965594 Validation: 0.23394140336368635 Test: 0.22416912141284556 Train loss: 0.026561527626916843
Epoch 31 training...
Evaluating...
Train: 0.5905337459103975 Validation: 0.23340277519489083 Test: 0.2274027996565488 Train loss: 0.026338118514205262
Epoch 32 training...
Evaluating...
Train: 0.5952197323769234 Validation: 0.23268286834800958 Test: 0.2272329418593871 Train loss: 0.026132888757263856
Epoch 33 training...
Evaluating...
Train: 0.600801362919347 Validation: 0.23314066468585892 Test: 0.22603751798697075 Train loss: 0.02594199937811139
Epoch 34 training...
Evaluating...
Train: 0.6096278912034977 Validation: 0.23287926750620194 Test: 0.22491109840325763 Train loss: 0.02577122921291453
Epoch 35 training...
Evaluating...
Train: 0.614381401365052 Validation: 0.2357606924143213 Test: 0.22108117807369587 Train loss: 0.025592194603439054
Epoch 36 training...
Evaluating...
Train: 0.6221630639674591 Validation: 0.2351359754370953 Test: 0.22289533008889578 Train loss: 0.025451831122311995
Epoch 37 training...
Evaluating...
Train: 0.6238279186964093 Validation: 0.23343815974023335 Test: 0.22666781193704785 Train loss: 0.025208947261342325
Epoch 38 training...
Evaluating...
Train: 0.6302880806970178 Validation: 0.23121241041902216 Test: 0.22344646843257523 Train loss: 0.025079135029250858
Epoch 39 training...
Evaluating...
Train: 0.6404676752721722 Validation: 0.2297823809961225 Test: 0.22297356651304448 Train loss: 0.02492369350060886
Epoch 40 training...
Evaluating...
Train: 0.6339191074495142 Validation: 0.2337095205956338 Test: 0.2214637016681964 Train loss: 0.024779842189908398
Epoch 41 training...
Evaluating...
Train: 0.6444628221349071 Validation: 0.2297974862253562 Test: 0.22029852952203915 Train loss: 0.024690745540243527
Epoch 42 training...
Evaluating...
Train: 0.653540391218133 Validation: 0.23516646511288802 Test: 0.22381424231865002 Train loss: 0.024510695796644954
Epoch 43 training...
Evaluating...
Train: 0.6591857309319713 Validation: 0.22834220456203722 Test: 0.22215322395209583 Train loss: 0.0243588474564189
Epoch 44 training...
Evaluating...
Train: 0.6616202676515267 Validation: 0.22947706468896453 Test: 0.22030165798206916 Train loss: 0.024232308304452978
Epoch 45 training...
Evaluating...
Train: 0.6653464315580575 Validation: 0.23052535418646322 Test: 0.22223326775803395 Train loss: 0.024108173142318595
Epoch 46 training...
Evaluating...
Train: 0.6643138776378387 Validation: 0.22980915180875658 Test: 0.22046095073269173 Train loss: 0.024024711607515247
Epoch 47 training...
Evaluating...
Train: 0.6753882545451996 Validation: 0.2310239040453246 Test: 0.2198881111089341 Train loss: 0.02383028006438272
Epoch 48 training...
Evaluating...
Train: 0.6818390829158422 Validation: 0.23138621513304555 Test: 0.2197978573336492 Train loss: 0.023756601664028827
Epoch 49 training...
Evaluating...
Train: 0.6798354631337121 Validation: 0.23384301803837887 Test: 0.22130619814970043 Train loss: 0.023622638794577867
Epoch 50 training...
Evaluating...
Train: 0.6874220159560405 Validation: 0.22994578817887162 Test: 0.21939161383922634 Train loss: 0.023546428753673986
Epoch 51 training...
Evaluating...
Train: 0.7240236321747533 Validation: 0.2335432911386032 Test: 0.2239496908134089 Train loss: 0.022329247830785305
Epoch 52 training...
Evaluating...
Train: 0.7300354118581912 Validation: 0.23371112136858788 Test: 0.2218018240091922 Train loss: 0.021889274080683273
Epoch 53 training...
Evaluating...
Train: 0.740758744448568 Validation: 0.2301236103649429 Test: 0.22213774685821075 Train loss: 0.02168195866051057
Epoch 54 training...
Evaluating...
Train: 0.7476815446962585 Validation: 0.2282671859138779 Test: 0.22071478884600715 Train loss: 0.021437677498746983
Epoch 55 training...
Evaluating...
Train: 0.7496896516818603 Validation: 0.2251257185097239 Test: 0.21610084477453387 Train loss: 0.021292494866762983
Epoch 56 training...
Evaluating...
Train: 0.7590233571548687 Validation: 0.23130884196761314 Test: 0.21815970610530233 Train loss: 0.02112113598358618
Epoch 57 training...
Evaluating...
Train: 0.7617849618914818 Validation: 0.22846116077128875 Test: 0.21877921324336172 Train loss: 0.02095157976777254
Epoch 58 training...
Evaluating...
Train: 0.768494749858416 Validation: 0.2306668845928569 Test: 0.21785188080713905 Train loss: 0.020847780885442906
Epoch 59 training...
Evaluating...
Train: 0.7735854825686973 Validation: 0.23207835895905168 Test: 0.21801215761707546 Train loss: 0.020737311185777752
Epoch 60 training...
Evaluating...
Train: 0.7724285715676064 Validation: 0.22742298722503357 Test: 0.2178136427722214 Train loss: 0.020550980752740814
Epoch 61 training...
Evaluating...
Train: 0.7785147012090071 Validation: 0.22682727591884502 Test: 0.21641044900690365 Train loss: 0.020471855984433365
Epoch 62 training...
Evaluating...
Train: 0.7809861047073445 Validation: 0.22781202340074735 Test: 0.21900573838169285 Train loss: 0.020324098182688387
Epoch 63 training...
Evaluating...
Train: 0.7877664721993498 Validation: 0.22396019109550933 Test: 0.2144586076701929 Train loss: 0.020241789595384512
Epoch 64 training...
Evaluating...
Train: 0.7844877071198956 Validation: 0.22521546067873735 Test: 0.21556118873555247 Train loss: 0.020170205901325882
Epoch 65 training...
Evaluating...
Train: 0.7915706208084211 Validation: 0.22880287472002486 Test: 0.21490424002553704 Train loss: 0.020070280282097612
Epoch 66 training...
Evaluating...
Train: 0.7940775587142453 Validation: 0.22008265145636263 Test: 0.21340773260200732 Train loss: 0.019954262523781956
Epoch 67 training...
Evaluating...
Train: 0.7981037516844787 Validation: 0.22688098268998597 Test: 0.2126056584341454 Train loss: 0.01985171965171683
Epoch 68 training...
Evaluating...
Train: 0.7954690144100273 Validation: 0.22469425148698835 Test: 0.2116033066835515 Train loss: 0.019801896053908558
Epoch 69 training...
Evaluating...
Train: 0.8016922990442183 Validation: 0.22311613276942385 Test: 0.211324168294355 Train loss: 0.019675609267740583
Epoch 70 training...
Evaluating...
Train: 0.803701222277746 Validation: 0.22373520239742942 Test: 0.2126422428287187 Train loss: 0.019588204819798862
Epoch 71 training...
Evaluating...
Train: 0.8093422779486373 Validation: 0.22074426626179153 Test: 0.21195021632128971 Train loss: 0.019511381151267566
Epoch 72 training...
Evaluating...
Train: 0.8089231749741237 Validation: 0.22544442256844946 Test: 0.2117701769181184 Train loss: 0.019488293117006127
Epoch 73 training...
Evaluating...
Train: 0.8091508576343344 Validation: 0.222005020318621 Test: 0.21088710778017178 Train loss: 0.019350241952853984
Epoch 74 training...
Evaluating...
Train: 0.8162052352853327 Validation: 0.22041366722365852 Test: 0.21254687616183016 Train loss: 0.019256159515236418
Epoch 75 training...
Evaluating...
Train: 0.8120368097588639 Validation: 0.2224281283790255 Test: 0.21225669380189052 Train loss: 0.019202852571672924
Epoch 76 training...
Evaluating...
Train: 0.817849845094207 Validation: 0.22148811063112517 Test: 0.21090909241623487 Train loss: 0.019194066569405022
Epoch 77 training...
Evaluating...
Train: 0.8223872304458233 Validation: 0.22137032235474766 Test: 0.21450967084147052 Train loss: 0.019100224893129247
Epoch 78 training...
Evaluating...
Train: 0.820927325973586 Validation: 0.22269483433196666 Test: 0.21025794103698503 Train loss: 0.019012046535686476
Epoch 79 training...
Evaluating...
Train: 0.8217641597153744 Validation: 0.2193465791345696 Test: 0.21047240944440296 Train loss: 0.018929078390956512
Epoch 80 training...
Evaluating...
Train: 0.8253706215753821 Validation: 0.21939546402927523 Test: 0.20895545286265274 Train loss: 0.018882133652387396
Epoch 81 training...
Evaluating...
Train: 0.8278611714894368 Validation: 0.2180096101294648 Test: 0.2093256996648711 Train loss: 0.01880869524345248
Epoch 82 training...
Evaluating...
Train: 0.8325242411396041 Validation: 0.21994784169697504 Test: 0.21050223436140766 Train loss: 0.018750996915303807
Epoch 83 training...
Evaluating...
Train: 0.8297842810536488 Validation: 0.22679735345036367 Test: 0.21115460679695697 Train loss: 0.01872802653449939
Epoch 84 training...
Evaluating...
Train: 0.8352990667979896 Validation: 0.22266779033367767 Test: 0.20778467009306423 Train loss: 0.018659479533090176
Epoch 85 training...
Evaluating...
Train: 0.8351428411959614 Validation: 0.2213955847592792 Test: 0.20741735742136772 Train loss: 0.018577764354989073
Epoch 86 training...
Evaluating...
Train: 0.8391184491486121 Validation: 0.22383258754390667 Test: 0.21171392884489298 Train loss: 0.01854525173696573
Epoch 87 training...
Evaluating...
Train: 0.8392587793539269 Validation: 0.22033669394519806 Test: 0.20815346945883345 Train loss: 0.01846233258803475
Epoch 88 training...
Evaluating...
Train: 0.8337919093343971 Validation: 0.22112619021378171 Test: 0.20905419219514604 Train loss: 0.018402943700222725
Epoch 89 training...
Evaluating...
Train: 0.8440568980072688 Validation: 0.21870153712093202 Test: 0.2130560605157883 Train loss: 0.018397915143372696
Epoch 90 training...
Evaluating...
Train: 0.8436011522223682 Validation: 0.22149632271795466 Test: 0.20799558752958083 Train loss: 0.018309141961970605
Epoch 91 training...
Evaluating...
Train: 0.8438975837561827 Validation: 0.22151409622647592 Test: 0.2111197847309585 Train loss: 0.0182245980328802
Epoch 92 training...
Evaluating...
Train: 0.8451993998458442 Validation: 0.22072620737211382 Test: 0.2090823204360424 Train loss: 0.01822545108813289
Epoch 93 training...
Evaluating...
Train: 0.8438870046516843 Validation: 0.22049726113312956 Test: 0.20646658064445528 Train loss: 0.01816518486554308
Epoch 94 training...
Evaluating...
Train: 0.8506617256977782 Validation: 0.22142234941858702 Test: 0.20957988998402258 Train loss: 0.0181088640107627
Epoch 95 training...
Evaluating...
Train: 0.8467038883881677 Validation: 0.21655868195829941 Test: 0.20651502492533813 Train loss: 0.01805299537635964
Epoch 96 training...
Evaluating...
Train: 0.8507740869234338 Validation: 0.21764500993474592 Test: 0.20859687814262043 Train loss: 0.0180072545803882
Epoch 97 training...
Evaluating...
Train: 0.8507540965059496 Validation: 0.21659808496470273 Test: 0.20567616283906728 Train loss: 0.01793853829392362
Epoch 98 training...
Evaluating...
Train: 0.8527437614603463 Validation: 0.2174018052815583 Test: 0.20553865684946776 Train loss: 0.01797762094609782
Epoch 99 training...
Evaluating...
Train: 0.8534546278846107 Validation: 0.21816432026300692 Test: 0.20637770643116124 Train loss: 0.017896093398882273
Epoch 100 training...
Evaluating...
Train: 0.8559855467712674 Validation: 0.21686242818688486 Test: 0.20131474647578165 Train loss: 0.017881699412220297
Epoch 101 training...
Evaluating...
Train: 0.8799662100447925 Validation: 0.21693829623882696 Test: 0.2036115677794926 Train loss: 0.016801364446389494
Epoch 102 training...
Evaluating...
Train: 0.8817799123156312 Validation: 0.21248849730996158 Test: 0.20192093116105334 Train loss: 0.01650041228444625
Epoch 103 training...
Evaluating...
Train: 0.8871935343055428 Validation: 0.21930917677138492 Test: 0.20670146770975026 Train loss: 0.016392024391425338
Epoch 104 training...
Evaluating...
Train: 0.887317526714746 Validation: 0.22132430999137956 Test: 0.2073332897504396 Train loss: 0.016221095590496407
Epoch 105 training...
Evaluating...
Train: 0.8909507314974642 Validation: 0.21518387818792079 Test: 0.20435116800636866 Train loss: 0.016137068988752796
Epoch 106 training...
Evaluating...
Train: 0.8907939389896231 Validation: 0.21470430552217984 Test: 0.20706396039358482 Train loss: 0.016052831605504015
Epoch 107 training...
Evaluating...
Train: 0.8937521818296372 Validation: 0.21564496998274443 Test: 0.20384347556839533 Train loss: 0.015992508757277136
Epoch 108 training...
Evaluating...
Train: 0.8959353131602951 Validation: 0.217480345865033 Test: 0.20317329502056067 Train loss: 0.015935481372211124
Epoch 109 training...
Evaluating...
Train: 0.8953257824646833 Validation: 0.2158896419858725 Test: 0.2052321792786174 Train loss: 0.015819030265895945
Epoch 110 training...
Evaluating...
Train: 0.8982301082715911 Validation: 0.21443766511202983 Test: 0.2001482019179213 Train loss: 0.015789209902109653
Epoch 111 training...
Evaluating...
Train: 0.9006028107816205 Validation: 0.21506543072508089 Test: 0.20308715535881516 Train loss: 0.015712418300939834
Epoch 112 training...
Evaluating...
Train: 0.9006402166391548 Validation: 0.2144702494158356 Test: 0.20385856853186665 Train loss: 0.01565649096693822
Epoch 113 training...
Evaluating...
Train: 0.9003300470459947 Validation: 0.21492280648103015 Test: 0.20441400691971087 Train loss: 0.01563129518378371
Epoch 114 training...
Evaluating...
Train: 0.9040822251771021 Validation: 0.21462993451317278 Test: 0.20247251180530845 Train loss: 0.015549239483808213
Epoch 115 training...
Evaluating...
Train: 0.9046282900679407 Validation: 0.2155463698241178 Test: 0.20458329920046 Train loss: 0.015501524554735623
Epoch 116 training...
Evaluating...
Train: 0.9062644064524621 Validation: 0.2164362474436691 Test: 0.20401965222153642 Train loss: 0.015481885202185484
Epoch 117 training...
Evaluating...
Train: 0.9062803799120841 Validation: 0.21632871689071703 Test: 0.20345070387015834 Train loss: 0.015445083132458591
Epoch 118 training...
Evaluating...
Train: 0.9064646113099153 Validation: 0.2133153337280011 Test: 0.20150789546821204 Train loss: 0.015407872498015023
Epoch 119 training...
Evaluating...
Train: 0.9048551028608384 Validation: 0.21421991220873135 Test: 0.2004670796199849 Train loss: 0.015319230290737963
Epoch 120 training...
Evaluating...
Train: 0.9078425263212797 Validation: 0.2123770691057906 Test: 0.20138527318976213 Train loss: 0.015281762338295807
Epoch 121 training...
Evaluating...
Train: 0.9096853605592864 Validation: 0.21247204481953258 Test: 0.20544679781471253 Train loss: 0.015266047797449493
Epoch 122 training...
Evaluating...
Train: 0.90978894465549 Validation: 0.20944603056869027 Test: 0.20129056366402706 Train loss: 0.015205034777628213
Epoch 123 training...
Evaluating...
Train: 0.9105500486432604 Validation: 0.21129219514701092 Test: 0.20146850718548712 Train loss: 0.015185627281030407
Epoch 124 training...
Evaluating...
Train: 0.909913773502736 Validation: 0.21596550006281137 Test: 0.20174455631547392 Train loss: 0.015159003001687418
Epoch 125 training...
Evaluating...
Train: 0.9103497378761728 Validation: 0.2110510224483517 Test: 0.20011225630815768 Train loss: 0.015110543696039714
Epoch 126 training...
Evaluating...
Train: 0.9121260271095788 Validation: 0.21061327902132634 Test: 0.20216617031633516 Train loss: 0.015068957412212685
Epoch 127 training...
Evaluating...
Train: 0.9131177890192573 Validation: 0.21792660106562398 Test: 0.20430070617515092 Train loss: 0.015031749303700978
Epoch 128 training...
Evaluating...
Train: 0.9115640482094792 Validation: 0.21464954963328844 Test: 0.2033169066260521 Train loss: 0.014977024669824965
Epoch 129 training...
Evaluating...
Train: 0.9146861080016077 Validation: 0.21310777578760776 Test: 0.1992282518902896 Train loss: 0.014989491505174196
Epoch 130 training...
Evaluating...
Train: 0.9142524208767918 Validation: 0.2143952168115946 Test: 0.19975104397633137 Train loss: 0.014933408267586509
Epoch 131 training...
Evaluating...
Train: 0.9165326668474665 Validation: 0.21726306493407993 Test: 0.19907306329063407 Train loss: 0.014874976236506524
Epoch 132 training...
Evaluating...
Train: 0.9176395347802546 Validation: 0.21171621971667318 Test: 0.20188451165823781 Train loss: 0.014845762273413724
Epoch 133 training...
Evaluating...
Train: 0.9165785435400697 Validation: 0.21209009855285793 Test: 0.20098175475121335 Train loss: 0.014843543203751005
Epoch 134 training...
Evaluating...
Train: 0.917185341312032 Validation: 0.21624514950385368 Test: 0.20054388561210443 Train loss: 0.014857448641737343
Epoch 135 training...
Evaluating...
Train: 0.9198238164479627 Validation: 0.21104778674093796 Test: 0.1980757171430872 Train loss: 0.014783981344625191
Epoch 136 training...
Evaluating...
Train: 0.9188312336387787 Validation: 0.21314173416410534 Test: 0.20000678481643266 Train loss: 0.014718861102280965
Epoch 137 training...
Evaluating...
Train: 0.9197926639392581 Validation: 0.21352043403650312 Test: 0.20153358818793726 Train loss: 0.01473409194401292
Epoch 138 training...
Evaluating...
Train: 0.9186071519535054 Validation: 0.21571532877328117 Test: 0.20074062285040306 Train loss: 0.014694596624778757
Epoch 139 training...
Evaluating...
Train: 0.9215328243740611 Validation: 0.21335451185754872 Test: 0.1997749066554197 Train loss: 0.014657566851444427
Epoch 140 training...
Evaluating...
Train: 0.9215733227707069 Validation: 0.2099026400067865 Test: 0.1958995854011309 Train loss: 0.014625559141213133
Epoch 141 training...
Evaluating...
Train: 0.9227419128739995 Validation: 0.21061713426182482 Test: 0.1990911686078173 Train loss: 0.014566512386551994
Epoch 142 training...
Evaluating...
Train: 0.9207386961185212 Validation: 0.2107382125159469 Test: 0.20031069901030213 Train loss: 0.014493594996303243
Epoch 143 training...
Evaluating...
Train: 0.9199232031889965 Validation: 0.2110860401614605 Test: 0.19958215285039393 Train loss: 0.01453157796570725
Epoch 144 training...
Evaluating...
Train: 0.9233474961440367 Validation: 0.21298272999043705 Test: 0.20024053340835266 Train loss: 0.01459798682310977
Epoch 145 training...
Evaluating...
Train: 0.9238444721161752 Validation: 0.21099483102591876 Test: 0.1994852853550528 Train loss: 0.01446501235222516
Epoch 146 training...
Evaluating...
Train: 0.9229728933366946 Validation: 0.21148884681503538 Test: 0.2011558763418157 Train loss: 0.01448311167718112
Epoch 147 training...
Evaluating...
Train: 0.9246849677656196 Validation: 0.20929184019895314 Test: 0.19604939616906444 Train loss: 0.014487735846490104
Epoch 148 training...
Evaluating...
Train: 0.9232454563137314 Validation: 0.21339376877423746 Test: 0.2000724831931103 Train loss: 0.014393261522925449
Epoch 149 training...
Evaluating...
Train: 0.9244359888397519 Validation: 0.21281021607399037 Test: 0.19987085469235977 Train loss: 0.014421537772761188
Epoch 150 training...
Evaluating...
Train: 0.9253686281454034 Validation: 0.21319179517756598 Test: 0.19653471694707172 Train loss: 0.014406462006442319
Epoch 151 training...
Evaluating...
Train: 0.9356852254030974 Validation: 0.211169494382932 Test: 0.19628839599635695 Train loss: 0.013567709894286207
Epoch 152 training...
Evaluating...
Train: 0.9398620254006347 Validation: 0.21188808728178082 Test: 0.19845128342636234 Train loss: 0.01336274223662015
Epoch 153 training...
Evaluating...
Train: 0.9398051829659472 Validation: 0.21226208742622854 Test: 0.19763235207995558 Train loss: 0.013241220593528646
Epoch 154 training...
Evaluating...
Train: 0.9414649328229803 Validation: 0.21330054854066804 Test: 0.19562550556976957 Train loss: 0.013205491635986517
Epoch 155 training...
Evaluating...
Train: 0.9413559872122058 Validation: 0.21082226841362933 Test: 0.19544273740226187 Train loss: 0.013086025310589111
Epoch 156 training...
Evaluating...
Train: 0.9423735906566867 Validation: 0.21159368581821292 Test: 0.1960489057384456 Train loss: 0.013056644495682746
Epoch 157 training...
Evaluating...
Train: 0.9440641122695527 Validation: 0.21240221075178436 Test: 0.19645810621980506 Train loss: 0.013005743181799628
Epoch 158 training...
Evaluating...
Train: 0.9444589967256021 Validation: 0.21168837317694852 Test: 0.19603688558349414 Train loss: 0.012979272730040336
Epoch 159 training...
Evaluating...
Train: 0.9447123337285661 Validation: 0.21187596354285013 Test: 0.201216750254686 Train loss: 0.012941401968509438
Epoch 160 training...
Evaluating...
Train: 0.9449512769093058 Validation: 0.2097165701078931 Test: 0.1955011880006174 Train loss: 0.012899756892478818
Epoch 161 training...
Evaluating...
Train: 0.9454780067737475 Validation: 0.21175776959092224 Test: 0.19665736468773581 Train loss: 0.012866688788075264
Epoch 162 training...
Evaluating...
Train: 0.9457700105566768 Validation: 0.21051017414700682 Test: 0.1978973631893061 Train loss: 0.012833947055769705
Epoch 163 training...
Evaluating...
Train: 0.9457204226168089 Validation: 0.21310874212352704 Test: 0.19535381533529675 Train loss: 0.012804479453538546
Epoch 164 training...
Evaluating...
Train: 0.9467113473821506 Validation: 0.2105820903392301 Test: 0.19422008617647235 Train loss: 0.012758641623142886
Epoch 165 training...
Evaluating...
Train: 0.9467135143707427 Validation: 0.21163772464273867 Test: 0.19615911446407383 Train loss: 0.012748666872730284
Epoch 166 training...
Evaluating...
Train: 0.9469345464543546 Validation: 0.21184416401348657 Test: 0.19759010058694884 Train loss: 0.012713910079301982
Epoch 167 training...
Evaluating...
Train: 0.9487031390595825 Validation: 0.2100214280360972 Test: 0.1953577145801717 Train loss: 0.012682372178110907
Epoch 168 training...
Evaluating...
Train: 0.9475329823711708 Validation: 0.2082220329215737 Test: 0.19462792775558893 Train loss: 0.012664994634272921
Epoch 169 training...
Evaluating...
Train: 0.948001281991897 Validation: 0.2113856040162699 Test: 0.19374435130231313 Train loss: 0.012646539688485874
Epoch 170 training...
Evaluating...
Train: 0.9490555103261309 Validation: 0.20679389065080236 Test: 0.19637357262691066 Train loss: 0.012600382572445418
Epoch 171 training...
Evaluating...
Train: 0.949528016009771 Validation: 0.20983942278709972 Test: 0.1953516137685798 Train loss: 0.012592472652533928
Epoch 172 training...
Evaluating...
Train: 0.9490700310720122 Validation: 0.20863900201312321 Test: 0.19685891671409497 Train loss: 0.01256743315597105
Epoch 173 training...
Evaluating...
Train: 0.9500957975639626 Validation: 0.21090671636660505 Test: 0.19614548393495837 Train loss: 0.012564151110590168
Epoch 174 training...
Evaluating...
Train: 0.9497518610010566 Validation: 0.20624241041514832 Test: 0.19362579779292574 Train loss: 0.012516688944522217
Epoch 175 training...
Evaluating...
Train: 0.9509709321901257 Validation: 0.20787535721252326 Test: 0.19578963170857755 Train loss: 0.0124883078430882
Epoch 176 training...
Evaluating...
Train: 0.9503972690309123 Validation: 0.21008519751949026 Test: 0.19619008855111084 Train loss: 0.012468770493149834
Epoch 177 training...
Evaluating...
Train: 0.9508686818953362 Validation: 0.20859863666117243 Test: 0.19798211557276463 Train loss: 0.012467417568533012
Epoch 178 training...
Evaluating...
Train: 0.9521035172189681 Validation: 0.20837625231910664 Test: 0.19653982018314087 Train loss: 0.012417259519114284
Epoch 179 training...
Evaluating...
Train: 0.9506464724986903 Validation: 0.20591230772139227 Test: 0.1940043402251939 Train loss: 0.012362560632667887
Epoch 180 training...
Evaluating...
Train: 0.9516215056126647 Validation: 0.20807788620625942 Test: 0.19317359741409068 Train loss: 0.012412623687184004
Epoch 181 training...
Evaluating...
Train: 0.9514203614720615 Validation: 0.20825531866543898 Test: 0.196632036353946 Train loss: 0.012378839990892839
Epoch 182 training...
Evaluating...
Train: 0.9528423589878849 Validation: 0.20759475000998986 Test: 0.19318066499289333 Train loss: 0.01236010877649559
Epoch 183 training...
Evaluating...
Train: 0.9524858939098673 Validation: 0.20840598404483454 Test: 0.19501561196921 Train loss: 0.012277741322751036
Epoch 184 training...
Evaluating...
Train: 0.9520800899036214 Validation: 0.20809351837968487 Test: 0.19650805394190787 Train loss: 0.012288712581260425
Epoch 185 training...
Evaluating...
Train: 0.9536094547598709 Validation: 0.2074558097581917 Test: 0.19548895345218897 Train loss: 0.012285994913277996
Epoch 186 training...
Evaluating...
Train: 0.9510575523386335 Validation: 0.20723497664346174 Test: 0.195066254264269 Train loss: 0.012252590281601758
Epoch 187 training...
Evaluating...
Train: 0.955184366002892 Validation: 0.20790281230620755 Test: 0.19317180367213654 Train loss: 0.012256372676634382
Epoch 188 training...
Evaluating...
Train: 0.9539668838271929 Validation: 0.2093428801879668 Test: 0.19281897079787882 Train loss: 0.01221717616219694
Epoch 189 training...
Evaluating...
Train: 0.9541151122872115 Validation: 0.20763540413748066 Test: 0.1898723990024462 Train loss: 0.01217921078749344
Epoch 190 training...
Evaluating...
Train: 0.9547045963619776 Validation: 0.2086886155661169 Test: 0.19501278690464752 Train loss: 0.012204217083665078
Epoch 191 training...
Evaluating...
Train: 0.9542344425243013 Validation: 0.2089643239745864 Test: 0.19372727384262559 Train loss: 0.012165797955456541
Epoch 192 training...
Evaluating...
Train: 0.9540150493785452 Validation: 0.2062211369214225 Test: 0.19574779147285318 Train loss: 0.012166848814542153
Epoch 193 training...
Evaluating...
Train: 0.9545717400507455 Validation: 0.20617367745297466 Test: 0.19191779561152922 Train loss: 0.012201202452016778
Epoch 194 training...
Evaluating...
Train: 0.9553292265443861 Validation: 0.20964769865975397 Test: 0.19385725825199665 Train loss: 0.012060189732419119
Epoch 195 training...
Evaluating...
Train: 0.956315713532792 Validation: 0.20725377516611415 Test: 0.19438858868084377 Train loss: 0.01208401441528517
Epoch 196 training...
Evaluating...
Train: 0.955164085317113 Validation: 0.20825311804913949 Test: 0.1927451118898459 Train loss: 0.012063836486509424
Epoch 197 training...
Evaluating...
Train: 0.9552771156774154 Validation: 0.206625338895194 Test: 0.19215386812405155 Train loss: 0.012096477631299904
Epoch 198 training...
Evaluating...
Train: 0.9554104696603498 Validation: 0.20871241186110798 Test: 0.19284621629988502 Train loss: 0.012041681104627423
Epoch 199 training...
Evaluating...
Train: 0.9570685037901208 Validation: 0.2070849820421736 Test: 0.19281790562824178 Train loss: 0.012045553913462426
Epoch 200 training...
Evaluating...
Train: 0.9557879172722857 Validation: 0.2077839929587725 Test: 0.19499297579350466 Train loss: 0.012026976556921958
Epoch 201 training...
Evaluating...
Train: 0.9626399845469806 Validation: 0.20350667590643956 Test: 0.19282626798111144 Train loss: 0.011418491290709435
Epoch 202 training...
Evaluating...
Train: 0.961849961787678 Validation: 0.20722122744363897 Test: 0.193085161804966 Train loss: 0.011249618160207073
Epoch 203 training...
Evaluating...
Train: 0.9636285593926872 Validation: 0.20291621424564615 Test: 0.19199625729388992 Train loss: 0.011231444805480915
Epoch 204 training...
Evaluating...
Train: 0.965067301348564 Validation: 0.2059045640788999 Test: 0.19282002068352289 Train loss: 0.011140210721696202
Epoch 205 training...
Evaluating...
Train: 0.9654442576610319 Validation: 0.20419111997067088 Test: 0.19133975364765074 Train loss: 0.01109122802891855
Epoch 206 training...
Evaluating...
Train: 0.9649484528092904 Validation: 0.20551695228281502 Test: 0.19080885207025303 Train loss: 0.011044266578755658
Epoch 207 training...
Evaluating...
Train: 0.9658478171769809 Validation: 0.2082321733323606 Test: 0.19266648412915388 Train loss: 0.01102909316846909
Epoch 208 training...
Evaluating...
Train: 0.9664059011022943 Validation: 0.20414116645684124 Test: 0.1919694857978538 Train loss: 0.011012193320150344
Epoch 209 training...
Evaluating...
Train: 0.9662954023897764 Validation: 0.20514876361476447 Test: 0.19114010577837065 Train loss: 0.010980975133954657
Epoch 210 training...
Evaluating...
Train: 0.966528044751494 Validation: 0.20633859851135808 Test: 0.1928802230091809 Train loss: 0.010952823395025152
Epoch 211 training...
Evaluating...
Train: 0.9661570581284783 Validation: 0.20443211124336538 Test: 0.1938523536189862 Train loss: 0.010925982636076427
Epoch 212 training...
Evaluating...
Train: 0.9667710962136273 Validation: 0.2063128508657514 Test: 0.1910695596035685 Train loss: 0.010902247244697622
Epoch 213 training...
Evaluating...
Train: 0.9667347676640488 Validation: 0.20297620000432612 Test: 0.1898248423154199 Train loss: 0.010905402178493097
Epoch 214 training...
Evaluating...
Train: 0.96725275026174 Validation: 0.20759081717265762 Test: 0.19357305229809596 Train loss: 0.010890899904322633
Epoch 215 training...
Evaluating...
Train: 0.9672651266856793 Validation: 0.20678526189416802 Test: 0.19220826605666527 Train loss: 0.010840581655856073
Epoch 216 training...
Evaluating...
Train: 0.9667740525456104 Validation: 0.2020167503170791 Test: 0.19351904674753276 Train loss: 0.01083097127222009
Epoch 217 training...
Evaluating...
Train: 0.9684604695124464 Validation: 0.20565355998351154 Test: 0.1915674345234581 Train loss: 0.010819828121003152
Epoch 218 training...
Evaluating...
Train: 0.968033040214262 Validation: 0.20642443347934128 Test: 0.19289543633883655 Train loss: 0.010799817409443923
Epoch 219 training...
Evaluating...
Train: 0.9679810907765931 Validation: 0.20456808794840414 Test: 0.18993528190448156 Train loss: 0.010777802393656739
Epoch 220 training...
Evaluating...
Train: 0.9668867878696411 Validation: 0.2056905641315078 Test: 0.19177430115713925 Train loss: 0.01078808135686373
Epoch 221 training...
Evaluating...
Train: 0.9684769491691958 Validation: 0.2042543578694917 Test: 0.1938080146088164 Train loss: 0.010751819195888442
Epoch 222 training...
Evaluating...
Train: 0.9687103401896857 Validation: 0.20496274949609947 Test: 0.19211150227828272 Train loss: 0.010738114946453109
Epoch 223 training...
Evaluating...
Train: 0.9689985510981582 Validation: 0.2060675480432545 Test: 0.19278271695804883 Train loss: 0.010731485909377576
Epoch 224 training...
Evaluating...
Train: 0.968408980689741 Validation: 0.20589254585330677 Test: 0.19082140807784315 Train loss: 0.010655225078909338
Epoch 225 training...
Evaluating...
Train: 0.9689203728405785 Validation: 0.2050175093519602 Test: 0.1883613174011218 Train loss: 0.010709632051682781
Epoch 226 training...
Evaluating...
Train: 0.9691496054422389 Validation: 0.20621396418769455 Test: 0.1901225472348905 Train loss: 0.010685032243800258
Epoch 227 training...
Evaluating...
Train: 0.9694490010140733 Validation: 0.20561997231690723 Test: 0.19273342401191376 Train loss: 0.010665791829593188
Epoch 228 training...
Evaluating...
Train: 0.9698347997354407 Validation: 0.2047079273321577 Test: 0.19085758052363047 Train loss: 0.010669076389553524
Epoch 229 training...
Evaluating...
Train: 0.9697456239240594 Validation: 0.20224034817619765 Test: 0.1896039836375559 Train loss: 0.010644478296012045
Epoch 230 training...
Evaluating...
Train: 0.9700848771886971 Validation: 0.20541284494973727 Test: 0.18945551841735156 Train loss: 0.010621354879826373
Epoch 231 training...
Evaluating...
Train: 0.9694800489852406 Validation: 0.20449438304991308 Test: 0.190676511124434 Train loss: 0.010560911989800083
Epoch 232 training...
Evaluating...
Train: 0.9692131708475221 Validation: 0.20589335777023535 Test: 0.1917307864519831 Train loss: 0.010618897128055638
Epoch 233 training...
Evaluating...
Train: 0.9702665073501296 Validation: 0.20419980026435783 Test: 0.1917309282495963 Train loss: 0.010558349041947163
Epoch 234 training...
Evaluating...
Train: 0.9703792667063715 Validation: 0.20415613611252517 Test: 0.1924143827880618 Train loss: 0.010563026318752456
Epoch 235 training...
Evaluating...
Train: 0.9705516645325212 Validation: 0.20382131073582893 Test: 0.19080899745387805 Train loss: 0.010570402729778753
Epoch 236 training...
Evaluating...
Train: 0.9705436155737259 Validation: 0.20435195053440536 Test: 0.19098053292584477 Train loss: 0.010531607908492675
Epoch 237 training...
Evaluating...
Train: 0.9704827881917233 Validation: 0.20396422901274922 Test: 0.18942847347862482 Train loss: 0.010511176580552303
Epoch 238 training...
Evaluating...
Train: 0.9709996116106956 Validation: 0.2038594032638513 Test: 0.18965589404060687 Train loss: 0.010534379105923808
Epoch 239 training...
Evaluating...
Train: 0.9714938817882144 Validation: 0.20464975800061844 Test: 0.19238136098908476 Train loss: 0.01051274457435519
Epoch 240 training...
Evaluating...
Train: 0.9710223043409438 Validation: 0.20652329490744475 Test: 0.19204702590786904 Train loss: 0.010499321147248454
Epoch 241 training...
Evaluating...
Train: 0.9713533698352838 Validation: 0.2032960062641046 Test: 0.1892639099500966 Train loss: 0.010504841391055677
Epoch 242 training...
Evaluating...
Train: 0.9708315241749191 Validation: 0.20590653763668762 Test: 0.1894370288824934 Train loss: 0.010451318569096327
Epoch 243 training...
Evaluating...
Train: 0.9714023951450818 Validation: 0.2037281557575251 Test: 0.19080023486531014 Train loss: 0.010436845187099829
Epoch 244 training...
Evaluating...
Train: 0.9714671232814741 Validation: 0.20437400226109487 Test: 0.19092856652886778 Train loss: 0.010415364431880259
Epoch 245 training...
Evaluating...
Train: 0.9717042303536524 Validation: 0.2048613976699805 Test: 0.1911660746932737 Train loss: 0.010435812260480726
Epoch 246 training...
Evaluating...
Train: 0.9712134049839761 Validation: 0.2020848055319348 Test: 0.18769365077685943 Train loss: 0.010411600228548703
Epoch 247 training...
Evaluating...
Train: 0.9715768213498204 Validation: 0.20514076938789277 Test: 0.19117517222080788 Train loss: 0.010424026504425648
Epoch 248 training...
Evaluating...
Train: 0.9715943528391425 Validation: 0.20276306492442697 Test: 0.19028490974425993 Train loss: 0.010392187341981022
Epoch 249 training...
Evaluating...
Train: 0.9719447198909656 Validation: 0.20297821276162417 Test: 0.189253351398936 Train loss: 0.010398756373038283
Epoch 250 training...
Evaluating...
Train: 0.9722619393283348 Validation: 0.20443783848996788 Test: 0.1880833094896343 Train loss: 0.010377549735636711
Epoch 251 training...
Evaluating...
Train: 0.9749384477141344 Validation: 0.20489150430618297 Test: 0.18688557812220033 Train loss: 0.009933756930390312
Epoch 252 training...
Evaluating...
Train: 0.9758315402138475 Validation: 0.20270597442609956 Test: 0.18922293839916818 Train loss: 0.00982507134187719
Epoch 253 training...
Evaluating...
Train: 0.975831980001107 Validation: 0.2004253333493869 Test: 0.18926953625281445 Train loss: 0.009776469879940838
Epoch 254 training...
Evaluating...
Train: 0.9761794779782762 Validation: 0.2015396805428866 Test: 0.18936836796170373 Train loss: 0.009732604280884266
Epoch 255 training...
Evaluating...
Train: 0.976752288216652 Validation: 0.1999278606912342 Test: 0.18701537959540493 Train loss: 0.009692223614411343
Epoch 256 training...
Evaluating...
Train: 0.9764010088491075 Validation: 0.20183739214834628 Test: 0.18990997772761556 Train loss: 0.009672086950190164
Epoch 257 training...
Evaluating...
Train: 0.9767431702764813 Validation: 0.20312122417912612 Test: 0.18905492310298858 Train loss: 0.009670364905008094
Epoch 258 training...
Evaluating...
Train: 0.9769035898575145 Validation: 0.20212781520116507 Test: 0.18978237887469968 Train loss: 0.009646745510549006
Epoch 259 training...
Evaluating...
Train: 0.9763571087721814 Validation: 0.20334022139583335 Test: 0.18915005325294476 Train loss: 0.009619921579014121
Epoch 260 training...
Evaluating...
Train: 0.9770412188903903 Validation: 0.2046740087179189 Test: 0.18862065327107505 Train loss: 0.009623746856553187
Epoch 261 training...
Evaluating...
Train: 0.9770884693917663 Validation: 0.2005991939864942 Test: 0.18947808681947548 Train loss: 0.009591705295824636
Epoch 262 training...
Evaluating...
Train: 0.9773608931469938 Validation: 0.20223597127466644 Test: 0.19022442256419297 Train loss: 0.009561646518136263
Epoch 263 training...
Evaluating...
Train: 0.9776434559756231 Validation: 0.20152398152124446 Test: 0.19066238703509636 Train loss: 0.009565767904381637
Epoch 264 training...
Evaluating...
Train: 0.9775712524944726 Validation: 0.20328202153227345 Test: 0.1900917168696601 Train loss: 0.009571791075644886
Epoch 265 training...
Evaluating...
Train: 0.97785566691153 Validation: 0.20158201053476618 Test: 0.18795082318191195 Train loss: 0.009539244205835823
Epoch 266 training...
Evaluating...
Train: 0.9776118289861517 Validation: 0.20083557845484884 Test: 0.18823631259090387 Train loss: 0.009516426091680373
Epoch 267 training...
Evaluating...
Train: 0.9781280284548362 Validation: 0.2017669103591377 Test: 0.18849075148992822 Train loss: 0.009509573754370811
Epoch 268 training...
Evaluating...
Train: 0.9782331435111795 Validation: 0.1999539547833574 Test: 0.1862578736269168 Train loss: 0.009476482083475377
Epoch 269 training...
Evaluating...
Train: 0.9782165794332787 Validation: 0.2019735988992005 Test: 0.19017342626989558 Train loss: 0.009512745696198198
Epoch 270 training...
Evaluating...
Train: 0.9780281630370661 Validation: 0.2028798623752501 Test: 0.18861958341460108 Train loss: 0.009476275072542582
Epoch 271 training...
Evaluating...
Train: 0.9785304302558886 Validation: 0.20319479031365587 Test: 0.18808889492544242 Train loss: 0.009499839909267227
Epoch 272 training...
Evaluating...
Train: 0.9783654961113754 Validation: 0.20042705725384782 Test: 0.18837133999369007 Train loss: 0.009419723259798033
Epoch 273 training...
Evaluating...
Train: 0.978108134746703 Validation: 0.20305989170847027 Test: 0.1894008277785005 Train loss: 0.009434814280690863
Epoch 274 training...
Evaluating...
Train: 0.9783625162468784 Validation: 0.20190668893891875 Test: 0.18807337689151046 Train loss: 0.009432193752833343
Epoch 275 training...
Evaluating...
Train: 0.9785310778426547 Validation: 0.20080593121921406 Test: 0.1882126428467198 Train loss: 0.009422287917910232
Epoch 276 training...
Evaluating...
Train: 0.9783863291954178 Validation: 0.20057662089807785 Test: 0.18615781729669995 Train loss: 0.009422687882519414
Epoch 277 training...
Evaluating...
Train: 0.9790291660503749 Validation: 0.20151460771223922 Test: 0.18942002568661842 Train loss: 0.009386501170747892
Epoch 278 training...
Evaluating...
Train: 0.9790047546160343 Validation: 0.20168810910071094 Test: 0.18785310839682542 Train loss: 0.009399366890569404
Epoch 279 training...
Evaluating...
Train: 0.9790637479642709 Validation: 0.20015463833754182 Test: 0.1875618011847181 Train loss: 0.009406667158832139
Epoch 280 training...
Evaluating...
Train: 0.9791009280608303 Validation: 0.2016478212733476 Test: 0.18775412721309892 Train loss: 0.009392173390208293
Epoch 281 training...
