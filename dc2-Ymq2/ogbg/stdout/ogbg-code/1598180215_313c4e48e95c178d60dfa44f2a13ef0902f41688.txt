{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 128, 'epochs': 401, 'learning_rate': 0.0001, 'step_size': 30, 'decay_rate': 0.85}, 'architecture': {'layers': 5, 'hidden': 256, 'pooling': 'add', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0, 'variants': {'BN': 'N', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '313c4e48e95c178d60dfa44f2a13ef0902f41688', 'time_stamp': '1598180215', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 3.979522963688993
Evaluating...
Train: 0.07551698786808204 Validation: 0.0705153735591567 Test: 0.07059109738852767 Train loss: 3.979522963688993
Epoch 2 training...
Average training loss: 3.0313572286811645
Evaluating...
Train: 0.12326721196789492 Validation: 0.11471070625867488 Test: 0.1190494007743871 Train loss: 3.0313572286811645
Epoch 3 training...
Average training loss: 2.833761266887263
Evaluating...
Train: 0.19264152786959604 Validation: 0.17570227029402205 Test: 0.1900213406159278 Train loss: 2.833761266887263
Epoch 4 training...
Average training loss: 2.6488326298098643
Evaluating...
Train: 0.24366319510495846 Validation: 0.22131731226704274 Test: 0.2345520640285539 Train loss: 2.6488326298098643
Epoch 5 training...
Average training loss: 2.4812190890536554
Evaluating...
Train: 0.26872378577271944 Validation: 0.24068184205581758 Test: 0.2558539290428301 Train loss: 2.4812190890536554
Epoch 6 training...
Average training loss: 2.3414063785351353
Evaluating...
Train: 0.28813106655219806 Validation: 0.25326101756614094 Test: 0.2702238611478634 Train loss: 2.3414063785351353
Epoch 7 training...
Average training loss: 2.2372038570820463
Evaluating...
Train: 0.2918956556475829 Validation: 0.25305648853880436 Test: 0.2708672650375767 Train loss: 2.2372038570820463
Epoch 8 training...
Average training loss: 2.1316273962538994
Evaluating...
Train: 0.3236706353007271 Validation: 0.2706638034310384 Test: 0.2878616905339158 Train loss: 2.1316273962538994
Epoch 9 training...
Average training loss: 2.0300621938152026
Evaluating...
Train: 0.3307999875858823 Validation: 0.26888442840364657 Test: 0.28530239453558204 Train loss: 2.0300621938152026
Epoch 10 training...
Average training loss: 1.9418452581019143
Evaluating...
Train: 0.333340655885901 Validation: 0.2620256750159892 Test: 0.2793930807462793 Train loss: 1.9418452581019143
Epoch 11 training...
Average training loss: 1.8558008820753324
Evaluating...
Train: 0.3667178199520893 Validation: 0.2765970994134206 Test: 0.29653760521721156 Train loss: 1.8558008820753324
Epoch 12 training...
Average training loss: 1.7877946158723819
Evaluating...
Train: 0.37993949658494613 Validation: 0.27789291369735775 Test: 0.2966691932998658 Train loss: 1.7877946158723819
Epoch 13 training...
Average training loss: 1.7260599260871652
Evaluating...
Train: 0.377504210268374 Validation: 0.27604988837403266 Test: 0.2959881463230287 Train loss: 1.7260599260871652
Epoch 14 training...
Average training loss: 1.6610650391022264
Evaluating...
Train: 0.39756489296386144 Validation: 0.27914984656449354 Test: 0.29734467155872296 Train loss: 1.6610650391022264
Epoch 15 training...
Average training loss: 1.6061916359170916
Evaluating...
Train: 0.41604787967484 Validation: 0.2831259931820917 Test: 0.3019656949878382 Train loss: 1.6061916359170916
Epoch 16 training...
Average training loss: 1.5558944936453774
Evaluating...
Train: 0.4241182428575873 Validation: 0.282428970424763 Test: 0.30104537394039854 Train loss: 1.5558944936453774
Epoch 17 training...
Average training loss: 1.5118640302639534
Evaluating...
Train: 0.42705392576780593 Validation: 0.2797648502758728 Test: 0.29863683109309136 Train loss: 1.5118640302639534
Epoch 18 training...
Average training loss: 1.477733877215212
Evaluating...
Train: 0.41035044856844743 Validation: 0.25391479202015205 Test: 0.27541752235574 Train loss: 1.477733877215212
Epoch 19 training...
Average training loss: 1.4395172269909713
Evaluating...
Train: 0.4564589258036585 Validation: 0.28432097794634503 Test: 0.3028255195081329 Train loss: 1.4395172269909713
Epoch 20 training...
Average training loss: 1.3994469999182628
Evaluating...
Train: 0.42118934768416566 Validation: 0.24932330334442795 Test: 0.26363339190020435 Train loss: 1.3994469999182628
Epoch 21 training...
Average training loss: 1.3630929340233318
Evaluating...
Train: 0.4712465358178099 Validation: 0.28478146689568 Test: 0.3030123246840032 Train loss: 1.3630929340233318
Epoch 22 training...
Average training loss: 1.3408904755429611
Evaluating...
Train: 0.4721900842390265 Validation: 0.2822450046581177 Test: 0.3010558966477501 Train loss: 1.3408904755429611
Epoch 23 training...
Average training loss: 1.3184303220272662
Evaluating...
Train: 0.48162340369174506 Validation: 0.2767522307886949 Test: 0.2960728375162492 Train loss: 1.3184303220272662
Epoch 24 training...
Average training loss: 1.274627801521659
Evaluating...
Train: 0.2949724766692118 Validation: 0.1499777544919325 Test: 0.16314590225197115 Train loss: 1.274627801521659
Epoch 25 training...
Average training loss: 1.2699567509004133
Evaluating...
Train: 0.49993288191055907 Validation: 0.2795147149773086 Test: 0.297091511853677 Train loss: 1.2699567509004133
Epoch 26 training...
Average training loss: 1.2185255264772226
Evaluating...
Train: 0.5013789078848123 Validation: 0.2798783830010547 Test: 0.29945301316952494 Train loss: 1.2185255264772226
Epoch 27 training...
Average training loss: 1.1962313096750634
Evaluating...
Train: 0.5117662083138853 Validation: 0.28366982172697214 Test: 0.30213619177533885 Train loss: 1.1962313096750634
Epoch 28 training...
Average training loss: 1.1816875034361292
Evaluating...
Train: 0.5026205635111713 Validation: 0.26877426649745534 Test: 0.28879838900341903 Train loss: 1.1816875034361292
Epoch 29 training...
