{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 128, 'epochs': 201, 'learning_rate': 0.0002, 'step_size': 20, 'decay_rate': 0.85}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EB3', 'dropout': 0.4, 'variants': {'BN': 'Y', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '313c4e48e95c178d60dfa44f2a13ef0902f41688', 'time_stamp': '1598978455', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 2.990959516208773
Evaluating...
Train: 0.22561869114090607 Validation: 0.20484184629558694 Test: 0.21587703955117843 Train loss: 2.990959516208773
Epoch 2 training...
Average training loss: 2.3719817783632124
Evaluating...
Train: 0.3008790105761606 Validation: 0.2650067849590136 Test: 0.28014525543913193 Train loss: 2.3719817783632124
Epoch 3 training...
Average training loss: 2.1241956249234666
Evaluating...
Train: 0.3351594221612486 Validation: 0.2820899469845431 Test: 0.30060226309542876 Train loss: 2.1241956249234666
Epoch 4 training...
Average training loss: 1.928632229230036
Evaluating...
Train: 0.36537459854384685 Validation: 0.2916473888074011 Test: 0.3108305910520235 Train loss: 1.928632229230036
Epoch 5 training...
Average training loss: 1.7573562393822664
Evaluating...
Train: 0.40226983986385134 Validation: 0.3015432216466533 Test: 0.3204565605809455 Train loss: 1.7573562393822664
Epoch 6 training...
Average training loss: 1.6038525057407365
Evaluating...
Train: 0.4303526942909669 Validation: 0.30543791207550686 Test: 0.32258679447033745 Train loss: 1.6038525057407365
Epoch 7 training...
Average training loss: 1.4656509465936436
Evaluating...
Train: 0.4630187669660871 Validation: 0.303251701963189 Test: 0.3225169796588605 Train loss: 1.4656509465936436
Epoch 8 training...
Average training loss: 1.3462010314279098
Evaluating...
Train: 0.49832882604481793 Validation: 0.30941526662261204 Test: 0.32809454254916254 Train loss: 1.3462010314279098
Epoch 9 training...
Average training loss: 1.2348807138511197
Evaluating...
Train: 0.521191853703978 Validation: 0.30256112360464377 Test: 0.3213041628500896 Train loss: 1.2348807138511197
Epoch 10 training...
Average training loss: 1.1408808106834647
Evaluating...
Train: 0.5499484218537887 Validation: 0.30058253507217 Test: 0.3202197289881817 Train loss: 1.1408808106834647
Epoch 11 training...
Average training loss: 1.0557812566552287
Evaluating...
Train: 0.5769808434219023 Validation: 0.30396729900827724 Test: 0.3249893379609071 Train loss: 1.0557812566552287
Epoch 12 training...
Average training loss: 0.9817442581001459
Evaluating...
Train: 0.6068296045963111 Validation: 0.3036868870271596 Test: 0.32259503249115057 Train loss: 0.9817442581001459
Epoch 13 training...
Average training loss: 0.9161169879895681
Evaluating...
Train: 0.618551219673249 Validation: 0.2986100367811373 Test: 0.3186142419534984 Train loss: 0.9161169879895681
Epoch 14 training...
Average training loss: 0.8588848336128847
Evaluating...
Train: 0.6416864572208207 Validation: 0.30284225691378247 Test: 0.32318167753514937 Train loss: 0.8588848336128847
Epoch 15 training...
Average training loss: 0.8056569221888761
Evaluating...
Train: 0.6579773424650668 Validation: 0.299843181026071 Test: 0.32015926533422434 Train loss: 0.8056569221888761
Epoch 16 training...
Average training loss: 0.7598604344326998
Evaluating...
