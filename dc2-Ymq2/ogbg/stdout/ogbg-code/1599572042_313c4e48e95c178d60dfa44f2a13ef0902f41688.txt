{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 64, 'epochs': 201, 'learning_rate': 0.0001, 'step_size': 5, 'decay_rate': 0.6}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EB5', 'dropout': 0.5, 'variants': {'BN': 'Y', 'aggr_mlp': 1, 'fea_activation': 'ELU'}}, 'commit_id': '313c4e48e95c178d60dfa44f2a13ef0902f41688', 'time_stamp': '1599572042', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 3.0019329460929423
Evaluating...
Train: 0.22361892762602578 Validation: 0.19878026314017022 Test: 0.212665733462617 Train loss: 3.0019329460929423
Epoch 2 training...
Average training loss: 2.356629511571398
Evaluating...
Train: 0.2979311225954371 Validation: 0.25980176928154314 Test: 0.2772436640875679 Train loss: 2.356629511571398
Epoch 3 training...
Average training loss: 2.1311630321390487
Evaluating...
Train: 0.33717382126497486 Validation: 0.28370448390389663 Test: 0.3014559074564542 Train loss: 2.1311630321390487
Epoch 4 training...
Average training loss: 1.9748868173898435
Evaluating...
Train: 0.3540710665380105 Validation: 0.28860840892221 Test: 0.3068713772103603 Train loss: 1.9748868173898435
Epoch 5 training...
Average training loss: 1.8446005456961838
Evaluating...
Train: 0.3773851912826027 Validation: 0.29480271886591736 Test: 0.31411739699055174 Train loss: 1.8446005456961838
Epoch 6 training...
Average training loss: 1.670364044376448
Evaluating...
Train: 0.41393914126342546 Validation: 0.30740047815035765 Test: 0.3249736410138269 Train loss: 1.670364044376448
Epoch 7 training...
Average training loss: 1.578711973919588
Evaluating...
Train: 0.43284198264992635 Validation: 0.30579929169796377 Test: 0.3232057538577495 Train loss: 1.578711973919588
Epoch 8 training...
Average training loss: 1.4989276426539702
Evaluating...
Train: 0.4493951451530179 Validation: 0.30692540453464323 Test: 0.324443777826774 Train loss: 1.4989276426539702
Epoch 9 training...
Average training loss: 1.4225963221905278
Evaluating...
Train: 0.4665432802634555 Validation: 0.3036575093593983 Test: 0.32446688767765863 Train loss: 1.4225963221905278
Epoch 10 training...
Average training loss: 1.3495652918815613
Evaluating...
Train: 0.4839485828541971 Validation: 0.303743528486045 Test: 0.32404146260761896 Train loss: 1.3495652918815613
Epoch 11 training...
Average training loss: 1.223621356711668
Evaluating...
Train: 0.5227574259258991 Validation: 0.3043987164073064 Test: 0.32560402712124964 Train loss: 1.223621356711668
Epoch 12 training...
Average training loss: 1.1662115556025037
Evaluating...
Train: 0.5374498203196975 Validation: 0.30586316334223596 Test: 0.3244995879017202 Train loss: 1.1662115556025037
Epoch 13 training...
Average training loss: 1.1167008866422317
Evaluating...
Train: 0.5500320880498971 Validation: 0.3056623561291134 Test: 0.3244008302715246 Train loss: 1.1167008866422317
Epoch 14 training...
Average training loss: 1.069226741323284
Evaluating...
Train: 0.5699954772761842 Validation: 0.30388270283523827 Test: 0.323383855477896 Train loss: 1.069226741323284
Epoch 15 training...
