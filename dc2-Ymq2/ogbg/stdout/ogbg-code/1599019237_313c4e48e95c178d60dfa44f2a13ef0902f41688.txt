{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 64, 'epochs': 201, 'learning_rate': 0.0001, 'step_size': 20, 'decay_rate': 0.75}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EB4', 'dropout': 0.4, 'variants': {'BN': 'Y', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '313c4e48e95c178d60dfa44f2a13ef0902f41688', 'time_stamp': '1599019237', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 3.0150576300153547
Evaluating...
Train: 0.22803631954102094 Validation: 0.20794235785689524 Test: 0.2208299441076915 Train loss: 3.0150576300153547
Epoch 2 training...
Average training loss: 2.415340072781432
Evaluating...
Train: 0.2997393677213186 Validation: 0.267183347445871 Test: 0.2831733329546342 Train loss: 2.415340072781432
Epoch 3 training...
Average training loss: 2.1931823987212837
Evaluating...
Train: 0.3304962896895384 Validation: 0.2825349267125136 Test: 0.30214733249861736 Train loss: 2.1931823987212837
Epoch 4 training...
Average training loss: 2.022321741104126
Evaluating...
Train: 0.3524988755586304 Validation: 0.2903966283968037 Test: 0.3107908868160372 Train loss: 2.022321741104126
Epoch 5 training...
Average training loss: 1.8759299560995664
Evaluating...
Train: 0.37750210539217194 Validation: 0.29995235318897506 Test: 0.32084205787732306 Train loss: 1.8759299560995664
Epoch 6 training...
Average training loss: 1.7431411507924397
Evaluating...
Train: 0.39604947481429076 Validation: 0.2986086422866017 Test: 0.3182113370399319 Train loss: 1.7431411507924397
Epoch 7 training...
Average training loss: 1.623265929259506
Evaluating...
Train: 0.42815738700921774 Validation: 0.30463972047878785 Test: 0.32539780375346256 Train loss: 1.623265929259506
Epoch 8 training...
Average training loss: 1.5107332287208706
Evaluating...
Train: 0.45640229827222895 Validation: 0.31082708324677033 Test: 0.3289131177936536 Train loss: 1.5107332287208706
Epoch 9 training...
Average training loss: 1.4077936524129382
Evaluating...
Train: 0.4764092766880037 Validation: 0.3059197115186071 Test: 0.32480809492837925 Train loss: 1.4077936524129382
Epoch 10 training...
Average training loss: 1.3131856956762427
Evaluating...
Train: 0.510056650748579 Validation: 0.3084023396509701 Test: 0.32949225460160403 Train loss: 1.3131856956762427
Epoch 11 training...
Average training loss: 1.2264337220939936
Evaluating...
Train: 0.5306049044781047 Validation: 0.3046736784761065 Test: 0.32462083079223597 Train loss: 1.2264337220939936
Epoch 12 training...
Average training loss: 1.1462474344197442
Evaluating...
Train: 0.550676758868984 Validation: 0.30655882201002066 Test: 0.32507264848024825 Train loss: 1.1462474344197442
Epoch 13 training...
Average training loss: 1.074492995037752
Evaluating...
Train: 0.5789257028743402 Validation: 0.3021951861523233 Test: 0.32535679773924714 Train loss: 1.074492995037752
Epoch 14 training...
Average training loss: 1.0064939810995963
Evaluating...
Train: 0.6016866598516616 Validation: 0.30824756340599796 Test: 0.32860769629495706 Train loss: 1.0064939810995963
Epoch 15 training...
Average training loss: 0.945953642873203
Evaluating...
Train: 0.6160134313057684 Validation: 0.3036862792921871 Test: 0.3253393071804772 Train loss: 0.945953642873203
Epoch 16 training...
Average training loss: 0.8909524259380266
Evaluating...
Train: 0.6354219709348077 Validation: 0.30451564622139193 Test: 0.3250858109045643 Train loss: 0.8909524259380266
Epoch 17 training...
Average training loss: 0.8400037909956539
Evaluating...
Train: 0.6520422726748195 Validation: 0.3012968767559643 Test: 0.3243471273679038 Train loss: 0.8400037909956539
Epoch 18 training...
Average training loss: 0.7938526893597023
Evaluating...
Train: 0.6696335330576865 Validation: 0.3006672956754037 Test: 0.32184199323346396 Train loss: 0.7938526893597023
Epoch 19 training...
Average training loss: 0.7518670075874703
Evaluating...
Train: 0.6824957406552836 Validation: 0.3018797384993642 Test: 0.32368231317110485 Train loss: 0.7518670075874703
Epoch 20 training...
Average training loss: 0.7133905480515723
Evaluating...
Train: 0.6965834909188321 Validation: 0.30023613757014295 Test: 0.3199313555245759 Train loss: 0.7133905480515723
Epoch 21 training...
Average training loss: 0.6267311265655592
Evaluating...
Train: 0.7265989192812329 Validation: 0.3021074658055856 Test: 0.32347300098803655 Train loss: 0.6267311265655592
Epoch 22 training...
Average training loss: 0.5886076634304196
Evaluating...
Train: 0.7349325650253892 Validation: 0.29978710716756907 Test: 0.32052212817658415 Train loss: 0.5886076634304196
Epoch 23 training...
Average training loss: 0.5586823898436977
Evaluating...
Train: 0.7427043373741732 Validation: 0.2980756639454102 Test: 0.3186008251412844 Train loss: 0.5586823898436977
Epoch 24 training...
Average training loss: 0.5325770007488775
Evaluating...
Train: 0.7516497221463718 Validation: 0.2968421823266895 Test: 0.31852653831194017 Train loss: 0.5325770007488775
Epoch 25 training...
Average training loss: 0.509947843932638
Evaluating...
Train: 0.7642534551067495 Validation: 0.29907036008407795 Test: 0.32055902175503054 Train loss: 0.509947843932638
Epoch 26 training...
Average training loss: 0.4877104885040545
Evaluating...
Train: 0.7687814438694756 Validation: 0.2971090367220446 Test: 0.31889686791955796 Train loss: 0.4877104885040545
Epoch 27 training...
Average training loss: 0.46691741699564693
Evaluating...
