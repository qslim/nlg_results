{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 64, 'epochs': 61, 'learning_rate': 0.0001, 'step_size': 5, 'decay_rate': 0.6}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EA1', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': 'b1e82dd32d1089453a2bcac386c86153ad3dd67b', 'time_stamp': '1601172821', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 3.0665457987317852
Evaluating...
Train: 0.18874191516460911 Validation: 0.17165849543462725 Test: 0.1816752787843548 Train loss: 3.0665457987317852
Epoch 2 training...
Average training loss: 2.469112789958131
Evaluating...
Train: 0.2827330297736389 Validation: 0.25213855697705456 Test: 0.26769439427996017 Train loss: 2.469112789958131
Epoch 3 training...
Average training loss: 2.2471572484035116
Evaluating...
Train: 0.30700935247334427 Validation: 0.26544560171680304 Test: 0.282900649863471 Train loss: 2.2471572484035116
Epoch 4 training...
Average training loss: 2.0891241289961573
Evaluating...
Train: 0.339322939751086 Validation: 0.28437705399400626 Test: 0.3021938677829875 Train loss: 2.0891241289961573
Epoch 5 training...
Average training loss: 1.9581428545409558
Evaluating...
Train: 0.3576989807832068 Validation: 0.28786644296571107 Test: 0.30591471156670724 Train loss: 1.9581428545409558
Epoch 6 training...
Average training loss: 1.8036531752979055
Evaluating...
Train: 0.37712681016945043 Validation: 0.29459774081766454 Test: 0.3106886216167244 Train loss: 1.8036531752979055
Epoch 7 training...
Average training loss: 1.7264962922638538
Evaluating...
Train: 0.3960213348465277 Validation: 0.2990681709246814 Test: 0.3165738525087896 Train loss: 1.7264962922638538
Epoch 8 training...
Average training loss: 1.658462448942895
Evaluating...
Train: 0.4052269167742076 Validation: 0.2983524663675428 Test: 0.3158865747985486 Train loss: 1.658462448942895
Epoch 9 training...
Average training loss: 1.592553124446495
Evaluating...
Train: 0.4167194820932847 Validation: 0.2985622192156793 Test: 0.31813244594135787 Train loss: 1.592553124446495
Epoch 10 training...
Average training loss: 1.532074978762982
Evaluating...
Train: 0.43308763881869566 Validation: 0.3011335280060354 Test: 0.31934861783822965 Train loss: 1.532074978762982
Epoch 11 training...
Average training loss: 1.4348607623343375
Evaluating...
Train: 0.451976631466511 Validation: 0.30313725538557895 Test: 0.32150675474212925 Train loss: 1.4348607623343375
Epoch 12 training...
Average training loss: 1.3924501030491847
Evaluating...
Train: 0.4624097370036301 Validation: 0.30196293701574856 Test: 0.319479121105693 Train loss: 1.3924501030491847
Epoch 13 training...
Average training loss: 1.3566776791273378
Evaluating...
Train: 0.4723262741758713 Validation: 0.30147071522800145 Test: 0.3208433518165612 Train loss: 1.3566776791273378
Epoch 14 training...
Average training loss: 1.321725296160754
Evaluating...
Train: 0.4809909745928793 Validation: 0.30144782464763187 Test: 0.31985414171718163 Train loss: 1.321725296160754
Epoch 15 training...
Average training loss: 1.2854543220763113
Evaluating...
Train: 0.49346070261561426 Validation: 0.30256232302075314 Test: 0.32289896483444874 Train loss: 1.2854543220763113
Epoch 16 training...
