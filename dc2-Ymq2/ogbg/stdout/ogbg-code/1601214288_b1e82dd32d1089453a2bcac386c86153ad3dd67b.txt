{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 64, 'epochs': 46, 'learning_rate': 0.0001, 'step_size': 5, 'decay_rate': 0.6}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'CA', 'dropout': 0.5, 'variants': {'BN': 'Y', 'fea_activation': 'ReLU'}}, 'commit_id': 'b1e82dd32d1089453a2bcac386c86153ad3dd67b', 'time_stamp': '1601214288', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 3.0705042146794934
Evaluating...
Train: 0.18050865760046533 Validation: 0.16298736714435536 Test: 0.17318913115113227 Train loss: 3.0705042146794934
Epoch 2 training...
Average training loss: 2.485442846709607
Evaluating...
Train: 0.25013182192734684 Validation: 0.21831595843735915 Test: 0.23222618409879206 Train loss: 2.485442846709607
Epoch 3 training...
Average training loss: 2.2667744864482504
Evaluating...
Train: 0.30075435363193026 Validation: 0.2566943706247734 Test: 0.27167863447934526 Train loss: 2.2667744864482504
Epoch 4 training...
Average training loss: 2.1133703529133516
Evaluating...
Train: 0.3260379045303638 Validation: 0.2716472667496027 Test: 0.2910488282549519 Train loss: 2.1133703529133516
Epoch 5 training...
Average training loss: 1.9895552855659933
Evaluating...
Train: 0.35158318321426757 Validation: 0.2818526236197271 Test: 0.30049649690163627 Train loss: 1.9895552855659933
Epoch 6 training...
Average training loss: 1.8359360563240799
Evaluating...
Train: 0.3703361443324158 Validation: 0.28533950819308224 Test: 0.30466507678782145 Train loss: 1.8359360563240799
Epoch 7 training...
Average training loss: 1.7540075044444963
Evaluating...
Train: 0.39113651238293323 Validation: 0.29388114138081267 Test: 0.3125713939888352 Train loss: 1.7540075044444963
Epoch 8 training...
Average training loss: 1.6829849889138166
Evaluating...
Train: 0.4023112761787935 Validation: 0.29265440358923295 Test: 0.3110318242699325 Train loss: 1.6829849889138166
Epoch 9 training...
Average training loss: 1.6179085800694484
Evaluating...
Train: 0.4189348766932499 Validation: 0.2929549250669468 Test: 0.3117275412860432 Train loss: 1.6179085800694484
Epoch 10 training...
Average training loss: 1.553208989461263
Evaluating...
Train: 0.43466381166157647 Validation: 0.2963292287129777 Test: 0.3131829655066396 Train loss: 1.553208989461263
Epoch 11 training...
Average training loss: 1.4473404912387624
Evaluating...
Train: 0.45418218565906077 Validation: 0.2959521396826914 Test: 0.31343110218861997 Train loss: 1.4473404912387624
Epoch 12 training...
Average training loss: 1.397847878484165
Evaluating...
Train: 0.46499077468878414 Validation: 0.2963050922576715 Test: 0.31369743215697293 Train loss: 1.397847878484165
Epoch 13 training...
Average training loss: 1.3543993531769398
Evaluating...
Train: 0.4746406711287556 Validation: 0.2929202208095139 Test: 0.3104562936506622 Train loss: 1.3543993531769398
Epoch 14 training...
Average training loss: 1.3131533030435152
Evaluating...
Train: 0.48815009389985514 Validation: 0.29542499861341076 Test: 0.31390541626326207 Train loss: 1.3131533030435152
Epoch 15 training...
Average training loss: 1.2747641438409394
Evaluating...
Train: 0.4997680854073051 Validation: 0.29683863345606787 Test: 0.31525189545282495 Train loss: 1.2747641438409394
Epoch 16 training...
Average training loss: 1.198313818585639
Evaluating...
Train: 0.5155577259120887 Validation: 0.29362965488442105 Test: 0.3115411700362493 Train loss: 1.198313818585639
Epoch 17 training...
Average training loss: 1.1650513893669727
Evaluating...
Train: 0.523254555049131 Validation: 0.29552026377638857 Test: 0.31248026066232737 Train loss: 1.1650513893669727
Epoch 18 training...
Average training loss: 1.1390545944606556
Evaluating...
Train: 0.5342796536145837 Validation: 0.2948416107420359 Test: 0.3126310653989714 Train loss: 1.1390545944606556
Epoch 19 training...
Average training loss: 1.113436691602071
Evaluating...
Train: 0.5432923577280269 Validation: 0.29369056143391065 Test: 0.312881566674623 Train loss: 1.113436691602071
Epoch 20 training...
Average training loss: 1.0884379924418879
Evaluating...
Train: 0.5465330245055516 Validation: 0.29304116237981337 Test: 0.3124047180772167 Train loss: 1.0884379924418879
Epoch 21 training...
Average training loss: 1.0385539243268032
Evaluating...
Train: 0.5649760824281272 Validation: 0.2935361320490829 Test: 0.3121455951759396 Train loss: 1.0385539243268032
Epoch 22 training...
Average training loss: 1.017645668076534
Evaluating...
Train: 0.5674493628272825 Validation: 0.29274456825405676 Test: 0.310298070447059 Train loss: 1.017645668076534
Epoch 23 training...
Average training loss: 1.0017910721255283
Evaluating...
Train: 0.5711146155070751 Validation: 0.2927073090043682 Test: 0.30924935456783464 Train loss: 1.0017910721255283
Epoch 24 training...
Average training loss: 0.9856873346216538
Evaluating...
Train: 0.5776247391953718 Validation: 0.291226551858975 Test: 0.30937175788187266 Train loss: 0.9856873346216538
Epoch 25 training...
Average training loss: 0.9709428597992542
Evaluating...
Train: 0.5837324049657165 Validation: 0.2920249300207226 Test: 0.31046278711669634 Train loss: 0.9709428597992542
Epoch 26 training...
Average training loss: 0.9385008289486754
Evaluating...
Train: 0.5885102250122657 Validation: 0.29031763233674085 Test: 0.30786089404186723 Train loss: 0.9385008289486754
Epoch 27 training...
Average training loss: 0.9265748137212267
Evaluating...
Train: 0.5923313484917689 Validation: 0.2917467678873648 Test: 0.30876129722493856 Train loss: 0.9265748137212267
Epoch 28 training...
Average training loss: 0.9167442725218978
Evaluating...
Train: 0.5987400086378135 Validation: 0.29056191017447974 Test: 0.3088140652656782 Train loss: 0.9167442725218978
Epoch 29 training...
Average training loss: 0.9071205397961186
Evaluating...
Train: 0.6032139793334133 Validation: 0.2910244608254864 Test: 0.30848926173557123 Train loss: 0.9071205397961186
Epoch 30 training...
Average training loss: 0.8981166149868685
Evaluating...
Train: 0.6038987081948969 Validation: 0.2893858159098988 Test: 0.3081276632465807 Train loss: 0.8981166149868685
Epoch 31 training...
Average training loss: 0.8781454550331714
Evaluating...
Train: 0.6090427887135342 Validation: 0.29064316617675956 Test: 0.30973271306786887 Train loss: 0.8781454550331714
Epoch 32 training...
Average training loss: 0.8712543700162102
Evaluating...
Train: 0.6144972248078135 Validation: 0.2921143610739088 Test: 0.30925203145678815 Train loss: 0.8712543700162102
Epoch 33 training...
Average training loss: 0.8650797804851158
Evaluating...
Train: 0.6112554918936064 Validation: 0.28891509020798584 Test: 0.3080397110331501 Train loss: 0.8650797804851158
Epoch 34 training...
Average training loss: 0.8591827266450022
Evaluating...
Train: 0.6156370820609087 Validation: 0.2904450752239682 Test: 0.3089032327755674 Train loss: 0.8591827266450022
Epoch 35 training...
Average training loss: 0.8533418792462817
Evaluating...
Train: 0.6176521568666624 Validation: 0.290397867947502 Test: 0.3083965879209181 Train loss: 0.8533418792462817
Epoch 36 training...
Average training loss: 0.8415947189751793
Evaluating...
Train: 0.6235670574742657 Validation: 0.2900766472379743 Test: 0.3080971010440666 Train loss: 0.8415947189751793
Epoch 37 training...
Traceback (most recent call last):
  File "./main.py", line 275, in <module>
    main()
  File "./main.py", line 232, in main
    train_loss = train(model, device, train_loader, optimizer)
  File "./main.py", line 42, in train
    pred_list = model(batch)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/space/github_private/gnnzoo/ogbg/code/model.py", line 82, in forward
    nr = F.dropout(nr, p=self.dropout, training=self.training)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py", line 936, in dropout
    else _VF.dropout(input, p, training))
RuntimeError: CUDA out of memory. Tried to allocate 356.00 MiB (GPU 0; 11.78 GiB total capacity; 8.17 GiB already allocated; 345.69 MiB free; 10.35 GiB reserved in total by PyTorch)
