{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 64, 'epochs': 201, 'learning_rate': 0.0001, 'step_size': 15, 'decay_rate': 0.6}, 'architecture': {'layers': 4, 'hidden': 256, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EB5', 'dropout': 0.4, 'variants': {'BN': 'Y', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '313c4e48e95c178d60dfa44f2a13ef0902f41688', 'time_stamp': '1599096116', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 3.120886879191679
Evaluating...
Train: 0.20526007929919374 Validation: 0.18709801007210833 Test: 0.19867002972525113 Train loss: 3.120886879191679
Epoch 2 training...
Average training loss: 2.503128679780399
Evaluating...
Train: 0.2669215746794449 Validation: 0.2368006791725948 Test: 0.2563130228316122 Train loss: 2.503128679780399
Epoch 3 training...
Average training loss: 2.31199690803827
Evaluating...
Train: 0.30455220941492656 Validation: 0.26771289172568924 Test: 0.286802621623562 Train loss: 2.31199690803827
Epoch 4 training...
Average training loss: 2.1776243490518308
Evaluating...
Train: 0.3217213232070308 Validation: 0.27527568777513994 Test: 0.29287751437150017 Train loss: 2.1776243490518308
Epoch 5 training...
Average training loss: 2.067424576217053
Evaluating...
Train: 0.34019283214745877 Validation: 0.2853732511663002 Test: 0.3053861928930272 Train loss: 2.067424576217053
Epoch 6 training...
Average training loss: 1.9708594862807032
Evaluating...
Train: 0.3538164168781026 Validation: 0.28821647374261655 Test: 0.30776812160765143 Train loss: 1.9708594862807032
Epoch 7 training...
Average training loss: 1.8853741780823352
Evaluating...
Train: 0.3665636717212432 Validation: 0.2934421412201138 Test: 0.31330024515508387 Train loss: 1.8853741780823352
Epoch 8 training...
Average training loss: 1.8059408205069747
Evaluating...
Train: 0.38305195899943717 Validation: 0.29732643143915444 Test: 0.3172720066924551 Train loss: 1.8059408205069747
Epoch 9 training...
Average training loss: 1.733774875715667
Evaluating...
Train: 0.3963844517453902 Validation: 0.29950779718496773 Test: 0.3184951391074956 Train loss: 1.733774875715667
Epoch 10 training...
Average training loss: 1.6667796416189156
Evaluating...
Train: 0.40865408879835935 Validation: 0.2994718976465043 Test: 0.3196282614475616 Train loss: 1.6667796416189156
Epoch 11 training...
Average training loss: 1.602335231958651
Evaluating...
Train: 0.4146496193079725 Validation: 0.3005246208603355 Test: 0.3184123677084311 Train loss: 1.602335231958651
Epoch 12 training...
Average training loss: 1.5428872993880627
Evaluating...
Train: 0.4395224461227712 Validation: 0.30396186332549574 Test: 0.32376596228427834 Train loss: 1.5428872993880627
Epoch 13 training...
Average training loss: 1.4874631383185293
Evaluating...
Train: 0.45443796478014065 Validation: 0.30302807373631757 Test: 0.32314989700172864 Train loss: 1.4874631383185293
Epoch 14 training...
Average training loss: 1.4352684861538456
Evaluating...
Train: 0.4688005667488071 Validation: 0.30370199818637383 Test: 0.32481403511337903 Train loss: 1.4352684861538456
Epoch 15 training...
Average training loss: 1.3854014589646284
Evaluating...
Train: 0.4744613405099073 Validation: 0.30082434232190997 Test: 0.32170839331172846 Train loss: 1.3854014589646284
Epoch 16 training...
Average training loss: 1.282835939949634
Evaluating...
Train: 0.500721363826451 Validation: 0.30433804166547296 Test: 0.32643562469970344 Train loss: 1.282835939949634
Epoch 17 training...
Average training loss: 1.2441762261390685
Evaluating...
Train: 0.5091239389651748 Validation: 0.3036347936685404 Test: 0.32351439035419355 Train loss: 1.2441762261390685
Epoch 18 training...
Average training loss: 1.2119568101097555
Evaluating...
Train: 0.5206328001839564 Validation: 0.303875673444416 Test: 0.32425704825923524 Train loss: 1.2119568101097555
Epoch 19 training...
Average training loss: 1.1818706068525127
Evaluating...
Train: 0.531879067529804 Validation: 0.30275429430007156 Test: 0.3253403512834896 Train loss: 1.1818706068525127
Epoch 20 training...
Average training loss: 1.1545244468427172
Evaluating...
Train: 0.5372741140933838 Validation: 0.30434930926888676 Test: 0.3240397301906323 Train loss: 1.1545244468427172
Epoch 21 training...
Average training loss: 1.126979015752381
Evaluating...
Train: 0.5454976352556203 Validation: 0.3022981428052208 Test: 0.3238790374520282 Train loss: 1.126979015752381
Epoch 22 training...
Average training loss: 1.1024547474337558
Evaluating...
Train: 0.5557363829746977 Validation: 0.3003649569521507 Test: 0.32083418019722015 Train loss: 1.1024547474337558
Epoch 23 training...
Average training loss: 1.0784681072422102
Evaluating...
Train: 0.5614974760369036 Validation: 0.30202523295173517 Test: 0.3240740497984894 Train loss: 1.0784681072422102
Epoch 24 training...
Average training loss: 1.0542042000807967
Evaluating...
Train: 0.5711532531945103 Validation: 0.29891710700756585 Test: 0.32170358851605435 Train loss: 1.0542042000807967
Epoch 25 training...
Average training loss: 1.0324855466823952
Evaluating...
Train: 0.5732859196030923 Validation: 0.29987872640719204 Test: 0.3210564160946884 Train loss: 1.0324855466823952
Epoch 26 training...
Average training loss: 1.010744703133901
Evaluating...
Train: 0.5833496914532436 Validation: 0.29975973586439464 Test: 0.3203676537807211 Train loss: 1.010744703133901
Epoch 27 training...
Average training loss: 0.9914529636700948
Evaluating...
Train: 0.5880634860267546 Validation: 0.29862905790065364 Test: 0.3210936581289233 Train loss: 0.9914529636700948
Epoch 28 training...
Average training loss: 0.9713402158512788
Evaluating...
Train: 0.5981068926520643 Validation: 0.29971455234417055 Test: 0.32034575037582147 Train loss: 0.9713402158512788
Epoch 29 training...
