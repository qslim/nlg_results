{'dataset_name': 'ogbg-code', 'seed': 777, 'num_workers': 0, 'feature': 'full', 'max_seq_len': 5, 'num_vocab': 5000, 'hyperparams': {'batch_size': 64, 'epochs': 201, 'learning_rate': 0.0001, 'step_size': 5, 'decay_rate': 0.6}, 'architecture': {'layers': 4, 'hidden': 512, 'pooling': 'mean', 'JK': 'cat', 'nonlinear_conv': 'EB5', 'dropout': 0.5, 'variants': {'BN': 'Y', 'aggr_mlp': 1, 'fea_activation': 'ReLU'}}, 'commit_id': '313c4e48e95c178d60dfa44f2a13ef0902f41688', 'time_stamp': '1599618488', 'directory': '../../../nlg_results/dc2-Ymq2/ogbg/board/'}
Target seqence less or equal to 5 is 0.9874166466036873%.
Coverage of top 5000 vocabulary:
0.9025832389087423
Epoch 1 training...
Average training loss: 2.9961181203804763
Evaluating...
Train: 0.23504600751642532 Validation: 0.20915786380133136 Test: 0.227356701830458 Train loss: 2.9961181203804763
Epoch 2 training...
Average training loss: 2.382254219728358
Evaluating...
Train: 0.2997873977330551 Validation: 0.26395260400826426 Test: 0.2815813337888242 Train loss: 2.382254219728358
Epoch 3 training...
Average training loss: 2.1583104903838213
Evaluating...
Train: 0.33376288146337163 Validation: 0.2833466679896973 Test: 0.3020595315018497 Train loss: 2.1583104903838213
Epoch 4 training...
Average training loss: 1.9897304871503045
Evaluating...
Train: 0.35696538498474106 Validation: 0.2935080524312238 Test: 0.31305358321487353 Train loss: 1.9897304871503045
Epoch 5 training...
Average training loss: 1.8448092687270221
Evaluating...
Train: 0.3832215085528497 Validation: 0.30057704247124417 Test: 0.3194896549393542 Train loss: 1.8448092687270221
Epoch 6 training...
Average training loss: 1.6686188037348728
Evaluating...
Train: 0.41504881301971613 Validation: 0.30736058169331604 Test: 0.326229434205104 Train loss: 1.6686188037348728
Epoch 7 training...
Average training loss: 1.574873156528847
Evaluating...
Train: 0.4357307442434065 Validation: 0.3111992362090973 Test: 0.3303258410079077 Train loss: 1.574873156528847
Epoch 8 training...
Average training loss: 1.490827163471895
Evaluating...
Train: 0.44981362376180406 Validation: 0.30723782506663694 Test: 0.32616901328629044 Train loss: 1.490827163471895
Epoch 9 training...
Average training loss: 1.4131773311203601
Evaluating...
Train: 0.4707796292784197 Validation: 0.30760524749874796 Test: 0.3286856333124786 Train loss: 1.4131773311203601
Epoch 10 training...
Average training loss: 1.3386623723179687
Evaluating...
Train: 0.4915458577145008 Validation: 0.30849211756430056 Test: 0.3299662586567999 Train loss: 1.3386623723179687
Epoch 11 training...
Average training loss: 1.2222167026575874
Evaluating...
Train: 0.5207740393352353 Validation: 0.31016540349493854 Test: 0.33171914476589165 Train loss: 1.2222167026575874
Epoch 12 training...
Average training loss: 1.168589592924305
Evaluating...
Train: 0.5344930440754491 Validation: 0.3104210323673882 Test: 0.330618527433727 Train loss: 1.168589592924305
Epoch 13 training...
Average training loss: 1.120751299867443
Evaluating...
Train: 0.5535167590323102 Validation: 0.31067526042106397 Test: 0.33131685028213187 Train loss: 1.120751299867443
Epoch 14 training...
Average training loss: 1.0752308179256962
Evaluating...
Train: 0.56392867012071 Validation: 0.3090503264540167 Test: 0.32920973812854626 Train loss: 1.0752308179256962
Epoch 15 training...
Average training loss: 1.0315742395718892
Evaluating...
Train: 0.5750014664478104 Validation: 0.3058073677502174 Test: 0.3265521338512044 Train loss: 1.0315742395718892
Epoch 16 training...
Average training loss: 0.9539695136313345
Evaluating...
Train: 0.596811609119958 Validation: 0.3070997827560916 Test: 0.3277316116845915 Train loss: 0.9539695136313345
Epoch 17 training...
Average training loss: 0.9214492089047152
Evaluating...
Train: 0.6069875482633884 Validation: 0.3060251492188206 Test: 0.3267590748659639 Train loss: 0.9214492089047152
Epoch 18 training...
Average training loss: 0.8928685884008221
Evaluating...
Train: 0.6165009522545927 Validation: 0.30524419749558906 Test: 0.32705671199383607 Train loss: 0.8928685884008221
Epoch 19 training...
Average training loss: 0.8661416817178913
Evaluating...
Train: 0.6287237023091803 Validation: 0.30663023968673264 Test: 0.3283961201607456 Train loss: 0.8661416817178913
Epoch 20 training...
Average training loss: 0.839336584371679
Evaluating...
Train: 0.6396865542817081 Validation: 0.3054819319358917 Test: 0.32542544479395213 Train loss: 0.839336584371679
Epoch 21 training...
Average training loss: 0.7909446403933507
Evaluating...
Train: 0.6482600385388262 Validation: 0.3043801769028574 Test: 0.3252604750007702 Train loss: 0.7909446403933507
Epoch 22 training...
Average training loss: 0.771087077033286
Evaluating...
Train: 0.657450974323168 Validation: 0.30559578403510557 Test: 0.3284069814619295 Train loss: 0.771087077033286
Epoch 23 training...
Average training loss: 0.7540660002091352
Evaluating...
Train: 0.6620748329369586 Validation: 0.3041094267767362 Test: 0.32596310979990584 Train loss: 0.7540660002091352
Epoch 24 training...
Average training loss: 0.7377496793503855
Evaluating...
Train: 0.6696638812325946 Validation: 0.3032583424133584 Test: 0.3260996518719318 Train loss: 0.7377496793503855
Epoch 25 training...
Average training loss: 0.7225244578800949
Evaluating...
Train: 0.6734250290136006 Validation: 0.3041094583979275 Test: 0.3263818747621372 Train loss: 0.7225244578800949
Epoch 26 training...
