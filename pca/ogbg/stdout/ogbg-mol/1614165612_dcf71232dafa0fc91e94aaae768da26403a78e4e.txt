{'dataset_name': 'ogbg-molpcba', 'seed': 666, 'num_workers': 2, 'cov_weight': 0, 'feature': 'full', 'hyperparams': {'batch_size': 128, 'epochs': 501, 'learning_rate': 0.0001, 'step_size': 20, 'decay_rate': 0.8}, 'architecture': {'layers': 5, 'hidden': 512, 'pooling': 'M', 'JK': 'C', 'method': 'penalty', 'dropout': 0.5, 'exps': 2, 'exp_nonlinear': 'Tanh', 'exp_bn': 'N', 'mlp_n': 2, 'mlp_nonlinear': 'ReLU', 'aggr': 'add'}, 'commit_id': 'dcf71232dafa0fc91e94aaae768da26403a78e4e', 'time_stamp': '1614165612', 'directory': '../../../nlg_results/pca/ogbg/board/'}
Downloading https://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/pcba.zip
  0%|          | 0/39 [00:00<?, ?it/s]Downloaded 0.00 GB:   0%|          | 0/39 [00:02<?, ?it/s]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:02<01:44,  2.76s/it]Downloaded 0.00 GB:   3%|▎         | 1/39 [00:03<01:44,  2.76s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:03<01:22,  2.23s/it]Downloaded 0.00 GB:   5%|▌         | 2/39 [00:04<01:22,  2.23s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [00:04<01:02,  1.74s/it]Downloaded 0.00 GB:   8%|▊         | 3/39 [00:04<01:02,  1.74s/it]Downloaded 0.00 GB:  10%|█         | 4/39 [00:04<00:48,  1.39s/it]Downloaded 0.00 GB:  10%|█         | 4/39 [00:05<00:48,  1.39s/it]Downloaded 0.00 GB:  13%|█▎        | 5/39 [00:05<00:37,  1.09s/it]Downloaded 0.01 GB:  13%|█▎        | 5/39 [00:05<00:37,  1.09s/it]Downloaded 0.01 GB:  15%|█▌        | 6/39 [00:05<00:27,  1.21it/s]Downloaded 0.01 GB:  15%|█▌        | 6/39 [00:05<00:27,  1.21it/s]Downloaded 0.01 GB:  18%|█▊        | 7/39 [00:05<00:20,  1.55it/s]Downloaded 0.01 GB:  18%|█▊        | 7/39 [00:06<00:20,  1.55it/s]Downloaded 0.01 GB:  21%|██        | 8/39 [00:06<00:17,  1.80it/s]Downloaded 0.01 GB:  21%|██        | 8/39 [00:06<00:17,  1.80it/s]Downloaded 0.01 GB:  23%|██▎       | 9/39 [00:06<00:13,  2.22it/s]Downloaded 0.01 GB:  23%|██▎       | 9/39 [00:06<00:13,  2.22it/s]Downloaded 0.01 GB:  26%|██▌       | 10/39 [00:06<00:10,  2.67it/s]Downloaded 0.01 GB:  26%|██▌       | 10/39 [00:06<00:10,  2.67it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:06<00:08,  3.11it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:06<00:08,  3.11it/s]Downloaded 0.01 GB:  28%|██▊       | 11/39 [00:06<00:08,  3.11it/s]Downloaded 0.01 GB:  33%|███▎      | 13/39 [00:06<00:06,  3.90it/s]Downloaded 0.01 GB:  33%|███▎      | 13/39 [00:07<00:06,  3.90it/s]Downloaded 0.01 GB:  36%|███▌      | 14/39 [00:07<00:05,  4.21it/s]Downloaded 0.01 GB:  36%|███▌      | 14/39 [00:07<00:05,  4.21it/s]Downloaded 0.01 GB:  38%|███▊      | 15/39 [00:07<00:05,  4.43it/s]Downloaded 0.02 GB:  38%|███▊      | 15/39 [00:07<00:05,  4.43it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:07<00:04,  4.63it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:07<00:04,  4.63it/s]Downloaded 0.02 GB:  41%|████      | 16/39 [00:07<00:04,  4.63it/s]Downloaded 0.02 GB:  46%|████▌     | 18/39 [00:07<00:03,  5.51it/s]Downloaded 0.02 GB:  46%|████▌     | 18/39 [00:07<00:03,  5.51it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:07<00:03,  5.48it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:07<00:03,  5.48it/s]Downloaded 0.02 GB:  49%|████▊     | 19/39 [00:08<00:03,  5.48it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:08<00:02,  6.31it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:08<00:02,  6.31it/s]Downloaded 0.02 GB:  54%|█████▍    | 21/39 [00:08<00:02,  6.31it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:08<00:02,  7.10it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:08<00:02,  7.10it/s]Downloaded 0.02 GB:  59%|█████▉    | 23/39 [00:08<00:02,  7.10it/s]Downloaded 0.02 GB:  64%|██████▍   | 25/39 [00:08<00:01,  7.79it/s]Downloaded 0.03 GB:  64%|██████▍   | 25/39 [00:08<00:01,  7.79it/s]Downloaded 0.03 GB:  64%|██████▍   | 25/39 [00:08<00:01,  7.79it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:08<00:01,  8.40it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:08<00:01,  8.40it/s]Downloaded 0.03 GB:  69%|██████▉   | 27/39 [00:08<00:01,  8.40it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:08<00:01,  8.94it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:08<00:01,  8.94it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:08<00:01,  8.94it/s]Downloaded 0.03 GB:  74%|███████▍  | 29/39 [00:09<00:01,  8.94it/s]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [00:09<00:00, 10.08it/s]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [00:09<00:00, 10.08it/s]Downloaded 0.03 GB:  82%|████████▏ | 32/39 [00:09<00:00, 10.08it/s]Downloaded 0.03 GB:  87%|████████▋ | 34/39 [00:09<00:00, 10.19it/s]Downloaded 0.03 GB:  87%|████████▋ | 34/39 [00:09<00:00, 10.19it/s]Downloaded 0.04 GB:  87%|████████▋ | 34/39 [00:09<00:00, 10.19it/s]Downloaded 0.04 GB:  87%|████████▋ | 34/39 [00:09<00:00, 10.19it/s]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [00:09<00:00, 11.24it/s]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [00:09<00:00, 11.24it/s]Downloaded 0.04 GB:  95%|█████████▍| 37/39 [00:09<00:00, 11.24it/s]Downloaded 0.04 GB: 100%|██████████| 39/39 [00:09<00:00,  4.11it/s]
Extracting dataset/pcba.zip
Processing...
Loading necessary files...
This might take a while.
Processing graphs...
  0%|          | 0/437929 [00:00<?, ?it/s]  1%|          | 3584/437929 [00:00<00:12, 35833.71it/s]  2%|▏         | 7151/437929 [00:00<00:12, 35782.14it/s]  3%|▎         | 11133/437929 [00:00<00:11, 36903.46it/s]  3%|▎         | 15048/437929 [00:00<00:11, 37548.85it/s]  4%|▍         | 19074/437929 [00:00<00:10, 38322.66it/s]  5%|▌         | 23141/437929 [00:00<00:10, 38997.01it/s]  6%|▌         | 27210/437929 [00:00<00:10, 39489.58it/s]  7%|▋         | 31256/437929 [00:00<00:10, 39773.28it/s]  8%|▊         | 35353/437929 [00:00<00:10, 40123.38it/s]  9%|▉         | 39397/437929 [00:01<00:09, 40217.31it/s] 10%|▉         | 43476/437929 [00:01<00:09, 40387.38it/s] 11%|█         | 47504/437929 [00:01<00:09, 40352.89it/s] 12%|█▏        | 51552/437929 [00:01<00:09, 40389.51it/s] 13%|█▎        | 55589/437929 [00:01<00:09, 40349.34it/s] 14%|█▎        | 59628/437929 [00:01<00:09, 40360.53it/s] 15%|█▍        | 63658/437929 [00:01<00:09, 40341.93it/s] 15%|█▌        | 67681/437929 [00:01<00:09, 40285.95it/s] 16%|█▋        | 71702/437929 [00:01<00:09, 39524.94it/s] 17%|█▋        | 75661/437929 [00:01<00:09, 39541.53it/s] 18%|█▊        | 79730/437929 [00:02<00:08, 39876.90it/s] 19%|█▉        | 83751/437929 [00:02<00:08, 39974.19it/s] 20%|██        | 87816/437929 [00:02<00:08, 40173.38it/s] 21%|██        | 91834/437929 [00:02<00:08, 39913.81it/s] 22%|██▏       | 95826/437929 [00:02<00:08, 39882.79it/s] 23%|██▎       | 99815/437929 [00:02<00:08, 38425.21it/s] 24%|██▎       | 103811/437929 [00:02<00:08, 38870.86it/s] 25%|██▍       | 107814/437929 [00:02<00:08, 39210.24it/s] 26%|██▌       | 111852/437929 [00:02<00:08, 39552.67it/s] 26%|██▋       | 115814/437929 [00:02<00:08, 37887.89it/s] 27%|██▋       | 119622/437929 [00:03<00:08, 36443.62it/s] 28%|██▊       | 123292/437929 [00:03<00:08, 35940.16it/s] 29%|██▉       | 126906/437929 [00:03<00:08, 35354.11it/s] 30%|██▉       | 130697/437929 [00:03<00:08, 36081.65it/s] 31%|███       | 134696/437929 [00:03<00:08, 37170.29it/s] 32%|███▏      | 138432/437929 [00:03<00:08, 36438.38it/s] 32%|███▏      | 142180/437929 [00:03<00:08, 36743.46it/s] 33%|███▎      | 145867/437929 [00:03<00:08, 35564.41it/s] 34%|███▍      | 149440/437929 [00:03<00:08, 34214.39it/s] 35%|███▍      | 152993/437929 [00:03<00:08, 34598.28it/s] 36%|███▌      | 156894/437929 [00:04<00:07, 35811.09it/s] 37%|███▋      | 160913/437929 [00:04<00:07, 37019.90it/s] 38%|███▊      | 164642/437929 [00:04<00:07, 36422.24it/s] 38%|███▊      | 168305/437929 [00:04<00:07, 35838.50it/s] 39%|███▉      | 172346/437929 [00:04<00:07, 37097.37it/s] 40%|████      | 176315/437929 [00:04<00:06, 37838.22it/s] 41%|████      | 180219/437929 [00:04<00:06, 38189.75it/s] 42%|████▏     | 184224/437929 [00:04<00:06, 38726.84it/s] 43%|████▎     | 188109/437929 [00:04<00:06, 37245.49it/s] 44%|████▍     | 191855/437929 [00:05<00:06, 36716.30it/s] 45%|████▍     | 195543/437929 [00:05<00:06, 35763.73it/s] 45%|████▌     | 199137/437929 [00:05<00:07, 33245.01it/s] 46%|████▌     | 202509/437929 [00:05<00:07, 32109.12it/s] 47%|████▋     | 206282/437929 [00:05<00:06, 33609.30it/s] 48%|████▊     | 210268/437929 [00:05<00:06, 35266.82it/s] 49%|████▉     | 213850/437929 [00:05<00:06, 35336.28it/s] 50%|████▉     | 217422/437929 [00:05<00:06, 35183.95it/s] 51%|█████     | 221507/437929 [00:05<00:05, 36711.47it/s] 51%|█████▏    | 225290/437929 [00:05<00:05, 37037.49it/s] 52%|█████▏    | 229020/437929 [00:06<00:05, 36639.00it/s] 53%|█████▎    | 233008/437929 [00:06<00:05, 37554.13it/s] 54%|█████▍    | 236963/437929 [00:06<00:05, 38130.59it/s] 55%|█████▌    | 240965/437929 [00:06<00:05, 38675.13it/s] 56%|█████▌    | 245023/437929 [00:06<00:04, 39227.31it/s] 57%|█████▋    | 248957/437929 [00:06<00:05, 36436.40it/s] 58%|█████▊    | 252648/437929 [00:06<00:05, 36350.99it/s] 59%|█████▊    | 256317/437929 [00:06<00:05, 35694.16it/s] 59%|█████▉    | 259926/437929 [00:06<00:04, 35811.43it/s] 60%|██████    | 263526/437929 [00:07<00:05, 34742.45it/s] 61%|██████    | 267531/437929 [00:07<00:04, 36180.27it/s] 62%|██████▏   | 271550/437929 [00:07<00:04, 37294.44it/s] 63%|██████▎   | 275422/437929 [00:07<00:04, 37708.35it/s] 64%|██████▍   | 279325/437929 [00:07<00:04, 38095.23it/s] 65%|██████▍   | 283328/437929 [00:07<00:03, 38655.53it/s] 66%|██████▌   | 287303/437929 [00:07<00:03, 38974.14it/s] 66%|██████▋   | 291211/437929 [00:07<00:03, 38707.38it/s] 67%|██████▋   | 295090/437929 [00:07<00:03, 38434.40it/s] 68%|██████▊   | 299012/437929 [00:07<00:03, 38666.25it/s] 69%|██████▉   | 303022/437929 [00:08<00:03, 39082.97it/s] 70%|███████   | 306935/437929 [00:08<00:03, 37868.11it/s] 71%|███████   | 310733/437929 [00:08<00:03, 35887.11it/s] 72%|███████▏  | 314755/437929 [00:08<00:03, 37083.17it/s] 73%|███████▎  | 318751/437929 [00:08<00:03, 37900.11it/s] 74%|███████▎  | 322798/437929 [00:08<00:02, 38634.65it/s] 75%|███████▍  | 326809/437929 [00:08<00:02, 39063.54it/s] 76%|███████▌  | 330831/437929 [00:08<00:02, 39402.45it/s] 76%|███████▋  | 334784/437929 [00:08<00:02, 39235.32it/s] 77%|███████▋  | 338717/437929 [00:08<00:02, 38952.14it/s] 78%|███████▊  | 342773/437929 [00:09<00:02, 39418.11it/s] 79%|███████▉  | 346841/437929 [00:09<00:02, 39787.09it/s] 80%|████████  | 350883/437929 [00:09<00:02, 39974.54it/s] 81%|████████  | 354935/437929 [00:09<00:02, 40136.02it/s] 82%|████████▏ | 358995/437929 [00:09<00:01, 40272.19it/s] 83%|████████▎ | 363069/437929 [00:09<00:01, 40411.36it/s] 84%|████████▍ | 367112/437929 [00:09<00:01, 40389.67it/s] 85%|████████▍ | 371214/437929 [00:09<00:01, 40576.45it/s] 86%|████████▌ | 375273/437929 [00:09<00:01, 40545.21it/s] 87%|████████▋ | 379329/437929 [00:09<00:01, 38632.87it/s] 88%|████████▊ | 383212/437929 [00:10<00:01, 37234.08it/s] 88%|████████▊ | 387249/437929 [00:10<00:01, 38120.61it/s] 89%|████████▉ | 391377/437929 [00:10<00:01, 39014.56it/s] 90%|█████████ | 395526/437929 [00:10<00:01, 39723.69it/s] 91%|█████████▏| 399636/437929 [00:10<00:00, 40125.42it/s] 92%|█████████▏| 403762/437929 [00:10<00:00, 40456.45it/s] 93%|█████████▎| 407893/437929 [00:10<00:00, 40708.51it/s] 94%|█████████▍| 412054/437929 [00:10<00:00, 40974.32it/s] 95%|█████████▌| 416158/437929 [00:10<00:00, 40636.82it/s] 96%|█████████▌| 420257/437929 [00:11<00:00, 40739.60it/s] 97%|█████████▋| 424335/437929 [00:11<00:00, 40658.23it/s] 98%|█████████▊| 428485/437929 [00:11<00:00, 40904.71it/s] 99%|█████████▉| 432581/437929 [00:11<00:00, 40918.34it/s]100%|█████████▉| 436681/437929 [00:11<00:00, 40941.09it/s]100%|██████████| 437929/437929 [00:11<00:00, 38304.23it/s]
Converting graphs into PyG objects...
  0%|          | 0/437929 [00:00<?, ?it/s]  1%|          | 2201/437929 [00:00<00:46, 9328.72it/s]  2%|▏         | 9170/437929 [00:00<00:34, 12603.65it/s]  3%|▎         | 15308/437929 [00:00<00:25, 16548.74it/s]  4%|▍         | 19599/437929 [00:00<00:20, 20287.66it/s]  5%|▌         | 23296/437929 [00:00<00:20, 20349.85it/s]  7%|▋         | 29748/437929 [00:00<00:15, 25609.18it/s]  8%|▊         | 35990/437929 [00:00<00:12, 31113.28it/s]  9%|▉         | 40787/437929 [00:01<00:14, 27302.50it/s] 11%|█         | 47823/437929 [00:01<00:11, 33441.93it/s] 13%|█▎        | 54770/437929 [00:01<00:09, 39603.42it/s] 14%|█▍        | 61415/437929 [00:01<00:11, 34075.21it/s] 15%|█▌        | 67033/437929 [00:01<00:09, 38635.14it/s] 17%|█▋        | 74082/437929 [00:01<00:08, 44693.78it/s] 19%|█▊        | 81171/437929 [00:01<00:07, 50265.22it/s] 20%|██        | 87861/437929 [00:02<00:06, 54316.97it/s] 21%|██▏       | 94084/437929 [00:02<00:09, 38044.70it/s] 23%|██▎       | 101116/437929 [00:02<00:07, 44119.41it/s] 25%|██▍       | 108142/437929 [00:02<00:06, 49661.83it/s] 26%|██▋       | 115226/437929 [00:02<00:05, 54554.05it/s] 28%|██▊       | 122171/437929 [00:02<00:08, 37508.19it/s] 30%|██▉       | 129205/437929 [00:02<00:07, 43614.61it/s] 31%|███       | 135959/437929 [00:03<00:06, 48800.20it/s] 33%|███▎      | 143086/437929 [00:03<00:05, 53896.46it/s] 34%|███▍      | 149485/437929 [00:03<00:05, 56572.11it/s] 36%|███▌      | 156600/437929 [00:03<00:04, 60275.17it/s] 37%|███▋      | 163728/437929 [00:03<00:04, 63200.95it/s] 39%|███▉      | 170476/437929 [00:03<00:07, 37993.03it/s] 41%|████      | 177607/437929 [00:03<00:05, 44182.04it/s] 42%|████▏     | 184630/437929 [00:04<00:05, 49712.96it/s] 44%|████▍     | 191645/437929 [00:04<00:04, 54473.51it/s] 45%|████▌     | 198742/437929 [00:04<00:04, 58554.69it/s] 47%|████▋     | 205869/437929 [00:04<00:03, 61864.20it/s] 49%|████▊     | 213007/437929 [00:04<00:03, 64439.58it/s] 50%|█████     | 219900/437929 [00:04<00:06, 35528.20it/s] 52%|█████▏    | 227061/437929 [00:04<00:05, 41854.22it/s] 53%|█████▎    | 234237/437929 [00:05<00:04, 47834.68it/s] 55%|█████▌    | 241402/437929 [00:05<00:03, 53132.11it/s] 57%|█████▋    | 248536/437929 [00:05<00:03, 57536.68it/s] 58%|█████▊    | 255486/437929 [00:05<00:03, 60667.79it/s] 60%|█████▉    | 262650/437929 [00:05<00:02, 63588.49it/s] 62%|██████▏   | 269781/437929 [00:05<00:02, 65721.92it/s] 63%|██████▎   | 277005/437929 [00:05<00:02, 67453.79it/s] 65%|██████▍   | 284251/437929 [00:05<00:02, 68880.80it/s] 67%|██████▋   | 291350/437929 [00:06<00:04, 34777.30it/s] 68%|██████▊   | 298387/437929 [00:06<00:03, 40997.97it/s] 70%|██████▉   | 305663/437929 [00:06<00:02, 47175.48it/s] 71%|███████▏  | 312893/437929 [00:06<00:02, 52665.84it/s] 73%|███████▎  | 320139/437929 [00:06<00:02, 57366.37it/s] 75%|███████▍  | 327014/437929 [00:06<00:01, 60363.06it/s] 76%|███████▋  | 334213/437929 [00:06<00:01, 63436.65it/s] 78%|███████▊  | 341296/437929 [00:06<00:01, 65485.47it/s] 80%|███████▉  | 348470/437929 [00:06<00:01, 67243.54it/s] 81%|████████  | 355680/437929 [00:07<00:01, 68629.78it/s] 83%|████████▎ | 362853/437929 [00:07<00:01, 69530.77it/s] 85%|████████▍ | 370110/437929 [00:07<00:00, 70413.93it/s] 86%|████████▌ | 377267/437929 [00:07<00:02, 28759.03it/s] 88%|████████▊ | 384458/437929 [00:07<00:01, 35072.55it/s] 89%|████████▉ | 391558/437929 [00:08<00:01, 41349.52it/s] 91%|█████████ | 398693/437929 [00:08<00:00, 47317.82it/s] 93%|█████████▎| 405770/437929 [00:08<00:00, 52539.53it/s] 94%|█████████▍| 412873/437929 [00:08<00:00, 56989.75it/s] 96%|█████████▌| 420046/437929 [00:08<00:00, 60733.65it/s] 98%|█████████▊| 427003/437929 [00:08<00:00, 63139.42it/s] 99%|█████████▉| 434154/437929 [00:08<00:00, 65436.63it/s]100%|██████████| 437929/437929 [00:08<00:00, 50187.68it/s]
Saving...
Done!
Epoch 1 training...
Evaluating...
Train: 0.11326480706545246 Validation: 0.1118319257886255 Test: 0.11257361527987192 Train loss: 0.1055157631744513 Train cov: 6.357331139750512
Epoch 2 training...
Evaluating...
Train: 0.13403297354614915 Validation: 0.12025006408250506 Test: 0.11953775832853836 Train loss: 0.04349025490797833 Train cov: 6.287103300812125
Epoch 3 training...
Evaluating...
Train: 0.1824009421565961 Validation: 0.15797999034622306 Test: 0.1573582122927835 Train loss: 0.04147442333315893 Train cov: 6.216212589780809
Epoch 4 training...
Evaluating...
Train: 0.20898378642427443 Validation: 0.1721457492549248 Test: 0.16623500087064405 Train loss: 0.040099152330502354 Train cov: 6.151950299609221
Epoch 5 training...
Evaluating...
Train: 0.23945424467079526 Validation: 0.18261170322908382 Test: 0.17703077764663405 Train loss: 0.03883199131767993 Train cov: 6.1025751978050105
Epoch 6 training...
Evaluating...
Train: 0.2711875016429746 Validation: 0.19987801669980232 Test: 0.19347503989114206 Train loss: 0.037784565401374426 Train cov: 6.05709350379041
Epoch 7 training...
Evaluating...
Train: 0.29029986059596863 Validation: 0.2124206447596704 Test: 0.2015128405952422 Train loss: 0.036803860582650755 Train cov: 6.017457641590417
Epoch 8 training...
Evaluating...
Train: 0.3041468551991688 Validation: 0.2107595950341029 Test: 0.2015074311758627 Train loss: 0.035952049959927165 Train cov: 5.984707119867173
Epoch 9 training...
Evaluating...
Train: 0.32521644809493117 Validation: 0.22329804206467932 Test: 0.21460686173227433 Train loss: 0.03523099176188382 Train cov: 5.95259159302694
Epoch 10 training...
Evaluating...
Train: 0.33513988373695375 Validation: 0.223515535994864 Test: 0.2160561638279719 Train loss: 0.03452397686605518 Train cov: 5.923686101194539
Epoch 11 training...
Evaluating...
Train: 0.33736340975331247 Validation: 0.21976795651917327 Test: 0.20704860478024337 Train loss: 0.03384376843129962 Train cov: 5.8974911884463905
Epoch 12 training...
Evaluating...
Train: 0.3615981080860639 Validation: 0.22613356059778578 Test: 0.21665847318510112 Train loss: 0.03341988038062135 Train cov: 5.872449120437254
Epoch 13 training...
Evaluating...
Train: 0.38228948003839275 Validation: 0.23746471892636878 Test: 0.2295372522429061 Train loss: 0.03272807949689986 Train cov: 5.852424170519854
Epoch 14 training...
Evaluating...
Train: 0.3929235296259253 Validation: 0.24051494193158204 Test: 0.22757060073885596 Train loss: 0.03217831808241007 Train cov: 5.834161165075811
Epoch 15 training...
Evaluating...
Train: 0.41807956437049676 Validation: 0.2425594324414921 Test: 0.23137110778830877 Train loss: 0.031682299626236025 Train cov: 5.816739509365174
Epoch 16 training...
Evaluating...
Train: 0.42201618838834914 Validation: 0.2463263980743866 Test: 0.23738352607802665 Train loss: 0.03115089256330029 Train cov: 5.8008975552502475
Epoch 17 training...
Evaluating...
Train: 0.43817589792559175 Validation: 0.2461541532791838 Test: 0.23368697251112955 Train loss: 0.03070114524538409 Train cov: 5.783374086272725
Epoch 18 training...
Evaluating...
Train: 0.44970258433614974 Validation: 0.24958119177002785 Test: 0.23821743238993648 Train loss: 0.030188121494120757 Train cov: 5.769072250522254
Epoch 19 training...
Evaluating...
Train: 0.45236566126664957 Validation: 0.24826276057835286 Test: 0.23380698145542125 Train loss: 0.029762569442459426 Train cov: 5.754888073905182
Epoch 20 training...
Evaluating...
Train: 0.47484847670767194 Validation: 0.24696684556680637 Test: 0.23861281657589045 Train loss: 0.029344686050542173 Train cov: 5.742347715195293
Epoch 21 training...
Evaluating...
Train: 0.4920197162504269 Validation: 0.24893008546521303 Test: 0.24173338860552526 Train loss: 0.028318057690833478 Train cov: 5.73537491132431
Epoch 22 training...
Evaluating...
Train: 0.5037516153159664 Validation: 0.2555011009562978 Test: 0.24396143460777722 Train loss: 0.027833933726366722 Train cov: 5.729218915921219
Epoch 23 training...
Evaluating...
Train: 0.5079018534660474 Validation: 0.24891989661995398 Test: 0.23853570656939724 Train loss: 0.02742697280498971 Train cov: 5.72139576197193
Epoch 24 training...
Evaluating...
Train: 0.5242444900378807 Validation: 0.2481353487034309 Test: 0.23983724728513292 Train loss: 0.026999648350207277 Train cov: 5.714996367497022
Epoch 25 training...
Evaluating...
Train: 0.5420725097699296 Validation: 0.2537837316579994 Test: 0.24587954941330753 Train loss: 0.026614844569102354 Train cov: 5.709207731237195
Epoch 26 training...
Evaluating...
Train: 0.5461212517543422 Validation: 0.24890595816471422 Test: 0.23763978082297588 Train loss: 0.02620868926420209 Train cov: 5.702150597025479
Epoch 27 training...
Evaluating...
Train: 0.5489449933220653 Validation: 0.2451975373666526 Test: 0.2381490223309425 Train loss: 0.025899634811172766 Train cov: 5.694544233485153
Epoch 28 training...
Evaluating...
Train: 0.5625282740415097 Validation: 0.25236567964029605 Test: 0.2434672950223961 Train loss: 0.025589260232204217 Train cov: 5.6884998482801
Epoch 29 training...
Evaluating...
Train: 0.577726564204957 Validation: 0.2550372936626231 Test: 0.2460039059913152 Train loss: 0.025198753611943184 Train cov: 5.6816265224278455
Epoch 30 training...
Evaluating...
Train: 0.5838667876173426 Validation: 0.25655953098570244 Test: 0.24441070767265155 Train loss: 0.024834322058061686 Train cov: 5.676318302565547
Epoch 31 training...
Evaluating...
Train: 0.5923607673276863 Validation: 0.24697756680661465 Test: 0.23915062640112633 Train loss: 0.024473680342480247 Train cov: 5.670852479488855
Epoch 32 training...
Evaluating...
Train: 0.604249210749873 Validation: 0.25186934766251207 Test: 0.23966787830872557 Train loss: 0.024160711368555413 Train cov: 5.664198270237646
Epoch 33 training...
Evaluating...
Train: 0.6112983834763889 Validation: 0.2510923378389616 Test: 0.2447096615747142 Train loss: 0.023840853659717748 Train cov: 5.659361540095661
Epoch 34 training...
Evaluating...
Train: 0.6166403592445607 Validation: 0.253039672734387 Test: 0.24172110069310407 Train loss: 0.023494730550126384 Train cov: 5.652807254874855
Epoch 35 training...
Evaluating...
Train: 0.6243450008706583 Validation: 0.25077999266730355 Test: 0.23871183998324022 Train loss: 0.023219059214643574 Train cov: 5.64684003352074
Epoch 36 training...
Evaluating...
Train: 0.6362903306356053 Validation: 0.24620356788092254 Test: 0.2388461337527849 Train loss: 0.022903242486905256 Train cov: 5.641885837035252
Epoch 37 training...
Evaluating...
Train: 0.6438472653161018 Validation: 0.24838524730188102 Test: 0.2435888861288103 Train loss: 0.022631892813349222 Train cov: 5.637041716265626
Epoch 38 training...
Evaluating...
Train: 0.6480176885790506 Validation: 0.25034322674981574 Test: 0.24049600086061826 Train loss: 0.02236256282810609 Train cov: 5.631533217830672
Epoch 39 training...
Evaluating...
Train: 0.6522935237626597 Validation: 0.2476060687738812 Test: 0.2374337663827231 Train loss: 0.02203796189934848 Train cov: 5.626140843698629
Epoch 40 training...
Evaluating...
Train: 0.6618094998801957 Validation: 0.24920234639140468 Test: 0.23899114374058325 Train loss: 0.021755369619579974 Train cov: 5.621512174606323
Epoch 41 training...
Evaluating...
Train: 0.6885551854224082 Validation: 0.25100363951119403 Test: 0.24097775227050425 Train loss: 0.020872738290920994 Train cov: 5.6178424196403505
Epoch 42 training...
Evaluating...
Train: 0.6964302118031116 Validation: 0.24731326621616012 Test: 0.23725418815975 Train loss: 0.020413636695593596 Train cov: 5.616052787438024
Epoch 43 training...
Evaluating...
Train: 0.7050373075666706 Validation: 0.24794675070619174 Test: 0.2390439745887883 Train loss: 0.020101647315529183 Train cov: 5.612550088660921
Epoch 44 training...
Evaluating...
Train: 0.7053600151073484 Validation: 0.24831809115011502 Test: 0.240848891777402 Train loss: 0.01986878674880073 Train cov: 5.610214461019389
Epoch 45 training...
Evaluating...
Train: 0.7142205743998689 Validation: 0.24455721482466897 Test: 0.23687993983303596 Train loss: 0.019581007033755215 Train cov: 5.6064869997011995
Epoch 46 training...
Evaluating...
Train: 0.7258559894404105 Validation: 0.24590502699644445 Test: 0.2359052965317494 Train loss: 0.019353613652658995 Train cov: 5.6047081771429825
Epoch 47 training...
Evaluating...
Train: 0.7323945507354866 Validation: 0.24486729347992095 Test: 0.238712930450615 Train loss: 0.019064199257304605 Train cov: 5.60200414960623
Epoch 48 training...
Evaluating...
Train: 0.7360145017447322 Validation: 0.24463542436656083 Test: 0.2367604448124127 Train loss: 0.01885790449150119 Train cov: 5.599363998046663
Epoch 49 training...
Evaluating...
Train: 0.7418225017988233 Validation: 0.24599358593932216 Test: 0.23569620680316913 Train loss: 0.018637181548476545 Train cov: 5.595967630646888
Epoch 50 training...
Evaluating...
Train: 0.7480014592370948 Validation: 0.24406527713270537 Test: 0.23473891037045444 Train loss: 0.01839814509943378 Train cov: 5.593316924754854
Epoch 51 training...
Evaluating...
Train: 0.7576974514224268 Validation: 0.24407701268869866 Test: 0.23404190983782325 Train loss: 0.01816217287921825 Train cov: 5.590918093027208
Epoch 52 training...
Evaluating...
Train: 0.7532823053075259 Validation: 0.23956165311674948 Test: 0.23179454388650098 Train loss: 0.017984664766288003 Train cov: 5.587462661560649
Epoch 53 training...
Evaluating...
Train: 0.7601619607040176 Validation: 0.2426212833905144 Test: 0.2297601619356015 Train loss: 0.01777523754598604 Train cov: 5.584638951206138
Epoch 54 training...
Evaluating...
Train: 0.772542039183946 Validation: 0.2427296710971938 Test: 0.23324805715402888 Train loss: 0.01753393196078375 Train cov: 5.582384985149821
Epoch 55 training...
